{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dataset.cifar10 import load_dataset\n",
    "from utils import Bar,Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from sklearn.model_selection import train_test_split\n",
    "from resnet_generator import Generator, Critic\n",
    "import timm\n",
    "import yaml\n",
    "from munch import Munch\n",
    "import logging\n",
    "import PyramidNet as PYRN\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 2: True\n"
     ]
    }
   ],
   "source": [
    "gpu_id = '2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %s:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/c10.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "args = Munch(config)\n",
    "args.prefetcher = not args.no_prefetcher\n",
    "args.distributed = False\n",
    "args.device = 'cuda'\n",
    "args.world_size = 3\n",
    "args.rank = 0\n",
    "logging.info('Training with a single process on %d GPUs.' % args.num_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = './log/' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.mkdir(checkpoint)\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "manual_seed = 7\n",
    "random.seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "# train params\n",
    "epochs = 375\n",
    "batch_size = 150\n",
    "init_lr = 0.1\n",
    "weight_decay = 0.0001\n",
    "labels = 10\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]],\n",
    "                                         std=[x/255.0 for x in [63.0, 62.1, 66.7]])    \n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "    ])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('../data', train=True, download=True, transform=transform_train),\n",
    "        batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('../data', train=False, transform=transform_test),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "numberofclass = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_g = Generator(args, img_size=224, max_conv_dim=256)\n",
    "model_g.load_state_dict(torch.load('model_best.pth.tar')['state_dict'])\n",
    "model_g = model_g.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PYRN.PyramidNet('cifar10', 272, 200, 10, True)\n",
    "model = model.cuda()\n",
    "# model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=init_lr, momentum=momentum, weight_decay=weight_decay, nesterov=True)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "step_lr = torch.optim.lr_scheduler.StepLR(optimizer, 150, gamma=0.1, last_epoch=-1)\n",
    "loss_func = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "# if resume:\n",
    "#     print('==> Resuming from checkpoint..')\n",
    "#     checkpoint = os.path.dirname(resume)\n",
    "# #     checkpoint = torch.load(resume)\n",
    "#     resume = torch.load(resume)\n",
    "#     best_acc = resume['best_acc']\n",
    "#     start_epoch = resume['epoch']\n",
    "#     model.load_state_dict(resume['state_dict'])\n",
    "#     optimizer.load_state_dict(resume['optimizer'])\n",
    "#     logger = Logger(os.path.join(checkpoint, 'log.txt'), resume=True)\n",
    "# else:\n",
    "logger = Logger(os.path.join(checkpoint, 'log.txt'))\n",
    "logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Train top-1 Acc', 'Train top-5 Acc', 'Valid top-1 Acc', 'Valid top-5 Acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/334 [00:00<?, ?it/s]/home/cutz/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bicubic is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "Epoch: 242 / 375, LR:0.002796, Loss: 0.000457, Top1E: 0.00, Top5E: 0.00:  64%|██████▍   | 214/334 [03:05<01:43,  1.16it/s]"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    model_g.eval()\n",
    "    train_loss, train_top1,train_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "    bar = tqdm(total=len(train_loader), leave=False)\n",
    "    for x, t in train_loader:\n",
    "        x, t = x.cuda(), t.cuda()\n",
    "        r = np.random.random(size=x.size(0))\n",
    "        r_batch = x[r < 0.01]\n",
    "        if len(r_batch) > 0:\n",
    "            inputs = F.interpolate(r_batch, size=224, mode='bicubic')\n",
    "            g_out = model_g(inputs)\n",
    "            inputs = inputs + g_out\n",
    "            inputs = F.interpolate(inputs, size=32, mode='bicubic')\n",
    "            x[r < 0.01] = inputs\n",
    "#             x = x.detach()\n",
    "            \n",
    "        y = model(x)\n",
    "        loss = loss_func(y, t)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        err1 = accuracy(y.data, t, topk=(1,))\n",
    "        err5 = accuracy(y.data, t, topk=(5,))\n",
    "        train_loss.update(float(loss.data), x.size(0))\n",
    "        train_top1.update(float(err1[0]), x.size(0))\n",
    "        train_top5.update(float(err5[0]), x.size(0))\n",
    "        bar.set_description(\"Epoch: {:d} / {:d}, LR:{:.6f}, Loss: {:.6f}, Top1E: {:.2f}, Top5E: {:.2f}\".format(e, epochs, \n",
    "            optimizer.param_groups[0][\"lr\"], train_loss.avg, train_top1.avg, train_top5.avg), refresh=True)\n",
    "        bar.update()\n",
    "    bar.close()\n",
    "    scheduler.step()\n",
    "    step_lr.step()\n",
    "    model.eval()\n",
    "    test_loss, test_top1, test_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "    for x, t in tqdm(test_loader, total=len(test_loader), leave=False):\n",
    "        with torch.no_grad():\n",
    "            x, t = Variable(x.cuda()), Variable(t.cuda())\n",
    "            y = model(x)\n",
    "            loss = loss_func(y, t)\n",
    "            err1 = accuracy(y.data, t, topk=(1,))\n",
    "            err5 = accuracy(y.data, t, topk=(5,))\n",
    "            test_loss.update(float(loss.data), x.size(0))\n",
    "            test_top1.update(float(err1[0]), x.size(0))\n",
    "            test_top5.update(float(err5[0]), x.size(0))\n",
    "\n",
    "    if (e + 1) % 100 == 0:\n",
    "        torch.save({\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict()\n",
    "        }, os.path.join(checkpoint, \"{}.tar\".format(e + 1)))\n",
    "\n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "    logger.append([lr, train_loss.avg, test_loss.avg, train_top1.avg, train_top5.avg, test_top1.avg, test_top5.avg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
