{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torchsummary\n",
    "import glob\n",
    "import time\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "from timm.data import Dataset, create_loader, resolve_data_config,  FastCollateMixup, mixup_batch, AugMixDataset\n",
    "from timm.models import create_model, resume_checkpoint, convert_splitbn_model, apply_test_time_pool\n",
    "from timm.utils import *\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy, JsdCrossEntropy\n",
    "from timm.optim import create_optimizer\n",
    "from timm.scheduler import create_scheduler\n",
    "from munch import Munch\n",
    "import yaml\n",
    "import sys\n",
    "from gd import Generator, Discriminator\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from apex import amp\n",
    "# from apex.parallel import DistributedDataParallel as DDP\n",
    "# from apex.parallel import convert_syncbn_model\n",
    "has_apex = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device  True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = '0,1,2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device \" , use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training with a single process on 3 GPUs.\n"
     ]
    }
   ],
   "source": [
    "with open('config/train.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "args = Munch(config)\n",
    "args.prefetcher = not args.no_prefetcher\n",
    "args.distributed = False\n",
    "args.device = 'cuda'\n",
    "args.world_size = 3\n",
    "args.rank = 0\n",
    "logging.info('Training with a single process on %d GPUs.' % args.num_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.distributed:\n",
    "    args.num_gpu = 1\n",
    "    args.device = 'cuda:%d' % args.local_rank\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    torch.distributed.init_process_group(backend='nccl', init_method='env://', rank=args.rank, world_size=args.world_size)\n",
    "    args.world_size = torch.distributed.get_world_size()\n",
    "    args.rank = torch.distributed.get_rank()\n",
    "    assert args.rank >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbb74e01e90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(args.seed + args.rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ns = timm.create_model('tf_efficientnet_b1_ns', pretrained=True)\n",
    "model_ns = model_ns.cuda()\n",
    "model_ns = torch.nn.DataParallel(model_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_raw = timm.create_model('tf_efficientnet_b1', pretrained=True)\n",
    "model_raw = model_raw.cuda()\n",
    "model_raw = torch.nn.DataParallel(model_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_g = Generator(args, img_size=240, max_conv_dim=256)\n",
    "model_g = model_g.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = create_optimizer(args, model_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:NVIDIA APEX not installed. AMP off.\n"
     ]
    }
   ],
   "source": [
    "use_amp = False\n",
    "if has_apex and args.amp:\n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level='O1')\n",
    "    model_raw =  amp.initialize(model_raw)\n",
    "    model_ns = amp.initialize(model_ns)\n",
    "    use_amp = True\n",
    "if args.local_rank == 0:\n",
    "    logging.info('NVIDIA APEX {}. AMP {}.'.format(\n",
    "        'installed' if has_apex else 'not installed', 'on' if use_amp else 'off'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded checkpoint './output/train/20200625-003932-tf_efficientnet_b1-240/checkpoint-0.pth.tar' (epoch 0)\n",
      "INFO:root:Restoring Optimizer state from checkpoint\n"
     ]
    }
   ],
   "source": [
    "# optionally resume from a checkpoint\n",
    "resume_state = {}\n",
    "resume_epoch = None\n",
    "if args.resume:\n",
    "    resume_state, resume_epoch = resume_checkpoint(model_g, args.resume)\n",
    "if resume_state and not args.no_resume_opt:\n",
    "    if 'optimizer' in resume_state:\n",
    "        if args.local_rank == 0:\n",
    "            logging.info('Restoring Optimizer state from checkpoint')\n",
    "        optimizer.load_state_dict(resume_state['optimizer'])\n",
    "    if use_amp and 'amp' in resume_state and 'load_state_dict' in amp.__dict__:\n",
    "        if args.local_rank == 0:\n",
    "            logging.info('Restoring NVIDIA AMP state from checkpoint')\n",
    "        amp.load_state_dict(resume_state['amp'])\n",
    "del resume_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_g = torch.nn.DataParallel(model_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Data processing configuration for current model + dataset:\n",
      "INFO:root:\tinput_size: (3, 240, 240)\n",
      "INFO:root:\tinterpolation: bicubic\n",
      "INFO:root:\tmean: (0.485, 0.456, 0.406)\n",
      "INFO:root:\tstd: (0.229, 0.224, 0.225)\n",
      "INFO:root:\tcrop_pct: 0.882\n"
     ]
    }
   ],
   "source": [
    "train_dir = '/home/data/imagenet/train'\n",
    "val_dir = '/home/data/imagenet/val'\n",
    "data_config = resolve_data_config(vars(args), model=model_g, verbose=args.local_rank == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_aug_splits = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.distributed:\n",
    "    if args.sync_bn:\n",
    "        assert not args.split_bn\n",
    "        try:\n",
    "            if has_apex:\n",
    "                model = convert_syncbn_model(model)\n",
    "            else:\n",
    "                model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "            if args.local_rank == 0:\n",
    "                logging.info(\n",
    "                    'Converted model to use Synchronized BatchNorm. WARNING: You may have issues if using '\n",
    "                    'zero initialized BN layers (enabled by default for ResNets) while sync-bn enabled.')\n",
    "        except Exception as e:\n",
    "            logging.error('Failed to enable Synchronized BatchNorm. Install Apex or Torch >= 1.1')\n",
    "    if has_apex:\n",
    "        model = DDP(model, delay_allreduce=True)\n",
    "    else:\n",
    "        if args.local_rank == 0:\n",
    "            logging.info(\"Using torch DistributedDataParallel. Install NVIDIA Apex for Apex DDP.\")\n",
    "        model = DDP(model, device_ids=[args.local_rank])  # can use device str in Torch >= 1.1\n",
    "    # NOTE: EMA model does not need to be wrapped by DDP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler, num_epochs = create_scheduler(args, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_state = {}\n",
    "resume_epoch = None\n",
    "start_epoch = 0\n",
    "if args.start_epoch is not None:\n",
    "    # a specified start_epoch will always override the resume epoch\n",
    "    start_epoch = args.start_epoch\n",
    "elif resume_epoch is not None:\n",
    "    start_epoch = resume_epoch\n",
    "if lr_scheduler is not None and start_epoch > 0:\n",
    "    lr_scheduler.step(start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Scheduled epochs: 200\n"
     ]
    }
   ],
   "source": [
    "if args.local_rank == 0:\n",
    "    logging.info('Scheduled epochs: {}'.format(num_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_dir)\n",
    "val_dataset = Dataset(val_dir, load_bytes=False, class_map='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model created, param count: 4192780\n"
     ]
    }
   ],
   "source": [
    "param_count = sum([m.numel() for m in model_g.parameters()])\n",
    "logging.info('Model created, param count: %d' % (param_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collate_fn = None\n",
    "if args.prefetcher and args.mixup > 0:\n",
    "    assert not num_aug_splits  # collate conflict (need to support deinterleaving in collate mixup)\n",
    "    collate_fn = FastCollateMixup(args.mixup, args.smoothing, args.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_raw, test_time_pool = apply_test_time_pool(model_raw, data_config, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_loader(\n",
    "        train_dataset,\n",
    "        input_size=data_config['input_size'],\n",
    "        batch_size=args.batch_size,\n",
    "        is_training=True,\n",
    "        use_prefetcher=args.prefetcher,\n",
    "        re_prob=args.reprob,\n",
    "        re_mode=args.remode,\n",
    "        re_count=args.recount,\n",
    "        re_split=args.resplit,\n",
    "        color_jitter=args.color_jitter,\n",
    "        auto_augment=args.aa,\n",
    "        num_aug_splits=num_aug_splits,\n",
    "        interpolation=args.train_interpolation,\n",
    "        mean=data_config['mean'],\n",
    "        std=data_config['std'],\n",
    "        num_workers=args.workers,\n",
    "        distributed=args.distributed,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=args.pin_mem,\n",
    "        use_multi_epochs_loader=args.use_multi_epochs_loader\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_pct = 1.0 if test_time_pool else data_config['crop_pct']\n",
    "val_loader = create_loader(\n",
    "    val_dataset,\n",
    "    input_size=data_config['input_size'],\n",
    "    batch_size=args.batch_size,\n",
    "    is_training=False,\n",
    "    use_prefetcher=args.prefetcher,\n",
    "    interpolation=data_config['interpolation'],\n",
    "    mean=data_config['mean'],\n",
    "    std=data_config['std'],\n",
    "    num_workers=args.workers,\n",
    "    crop_pct=crop_pct,\n",
    "    pin_memory=args.pin_mem,\n",
    "    tf_preprocessing=args.tf_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.jsd:\n",
    "    assert num_aug_splits > 1  # JSD only valid with aug splits set\n",
    "    train_loss_fn = JsdCrossEntropy(num_splits=num_aug_splits, smoothing=args.smoothing)\n",
    "    validate_loss_fn = nn.CrossEntropyLoss()\n",
    "elif args.mixup > 0.:\n",
    "    # smoothing is handled with mixup label transform\n",
    "    train_loss_fn = SoftTargetCrossEntropy()\n",
    "    validate_loss_fn = nn.CrossEntropyLoss()\n",
    "elif args.smoothing:\n",
    "    train_loss_fn = LabelSmoothingCrossEntropy(smoothing=args.smoothing)\n",
    "    validate_loss_fn = nn.CrossEntropyLoss()\n",
    "else:\n",
    "    train_loss_fn = nn.CrossEntropyLoss()\n",
    "    validate_loss_fn = train_loss_fn\n",
    "\n",
    "gan_loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric = args.eval_metric\n",
    "best_metric = None\n",
    "best_epoch = None\n",
    "saver = None\n",
    "output_dir = ''\n",
    "if args.local_rank == 0:\n",
    "    output_base = args.output if args.output else './output'\n",
    "    exp_name = '-'.join([\n",
    "        datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    "        args.model,\n",
    "        str(data_config['input_size'][-1])\n",
    "    ])\n",
    "    output_dir = get_outdir(output_base, 'train', exp_name)\n",
    "    decreasing = True if eval_metric == 'loss' else False\n",
    "    saver = CheckpointSaver(checkpoint_dir=output_dir, decreasing=decreasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ema = None\n",
    "if args.model_ema:\n",
    "    # Important to create EMA model after cuda(), DP wrapper, and AMP but before SyncBN and DDP wrapper\n",
    "    model_ema = ModelEma(\n",
    "        model,\n",
    "        decay=args.model_ema_decay,\n",
    "        device='cpu' if args.model_ema_force_cpu else '',\n",
    "        resume=args.resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(epoch, model_g, model_raw, model_ns, loader, optimizer, loss_fn, gan_loss_fn, args,\n",
    "               lr_scheduler=None, saver=None, output_dir='', use_amp=False, model_ema=None):\n",
    "\n",
    "    batch_time_m = AverageMeter()\n",
    "    data_time_m = AverageMeter()\n",
    "    losses_m = AverageMeter()\n",
    "    losses_g = AverageMeter()\n",
    "    losses_ce = AverageMeter()\n",
    "    losses_kd = AverageMeter()\n",
    "    \n",
    "    model_g.train()\n",
    "    model_ns.eval()\n",
    "    model_raw.eval()\n",
    "\n",
    "    real, fake = 1, 0\n",
    "    \n",
    "    end = time.time()\n",
    "    last_idx = len(loader) - 1\n",
    "    num_updates = epoch * len(loader)\n",
    "    for batch_idx, (inputs, target) in enumerate(loader):\n",
    "        last_batch = batch_idx == last_idx\n",
    "        data_time_m.update(time.time() - end)\n",
    "        z = torch.randn(args.batch_size, 1, 15, 15, device='cuda')\n",
    "        g_out = model_g(z)\n",
    "        \n",
    "        # G train\n",
    "        model_g.zero_grad()\n",
    "#         label.fill_(real)\n",
    "#         g_d_out = model_d(inputs+g_out)\n",
    "#         loss_g = gan_loss_fn(g_d_out, label)\n",
    "        \n",
    "        # KD train\n",
    "        inputs_z = inputs + g_out\n",
    "        output, traj_raw = model_raw(inputs_z)\n",
    "        with torch.no_grad():\n",
    "            out_ns, traj_ns = model_ns(inputs)\n",
    "            out_ns = out_ns.detach()\n",
    "            \n",
    "        p_s = F.log_softmax(output/args.T, dim=1)\n",
    "        p_t = F.softmax(out_ns/args.T, dim=1)\n",
    "        loss_kd = F.kl_div(p_s, p_t, size_average=False) * (args.T ** 2) / output.shape[0]\n",
    "        \n",
    "        # CE train\n",
    "        loss_ce = loss_fn(output, target)\n",
    "        \n",
    "        # overall loss\n",
    "        loss = args.lambda_kd * loss_kd + args.lambda_ce * loss_ce\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if not args.distributed:\n",
    "#             losses_d.update(loss_d.item(), inputs.size(0))\n",
    "#             losses_g.update(loss_g.item(), inputs.size(0))\n",
    "            losses_kd.update(loss_kd.item(), inputs.size(0))\n",
    "            losses_ce.update(loss_ce.item(), inputs.size(0))\n",
    "            losses_m.update(loss.item(), inputs.size(0))\n",
    "\n",
    "        if model_ema is not None:\n",
    "            model_ema.update(model)\n",
    "        num_updates += 1\n",
    "\n",
    "        batch_time_m.update(time.time() - end)\n",
    "        if last_batch or batch_idx % args.log_interval == 0:\n",
    "            lrl = [param_group['lr'] for param_group in optimizer.param_groups]\n",
    "            lr = sum(lrl) / len(lrl)\n",
    "\n",
    "            if args.distributed:\n",
    "                reduced_loss = reduce_tensor(loss.data, args.world_size)\n",
    "                losses_m.update(reduced_loss.item(), inputs.size(0))\n",
    "\n",
    "            if args.local_rank == 0:\n",
    "                logging.info(\n",
    "                    'Train: {} [{:>4d}/{} ({:>3.0f}%)]  '\n",
    "                    'Loss: {loss.val:>9.6f} ({loss.avg:>6.4f})  '\n",
    "#                     'Loss_d: {loss_d.val:>9.6f} ({loss_d.avg:>6.4f})  '\n",
    "#                     'Loss_g: {loss_g.val:>9.6f} ({loss_g.avg:>6.4f})  '\n",
    "                    'Loss_kd: {loss_kd.val:>9.6f} ({loss_kd.avg:>6.4f})  '\n",
    "                    'Loss_ce: {loss_ce.val:>9.6f} ({loss_ce.avg:>6.4f})  '\n",
    "                    'Time: {batch_time.val:.3f}s, {rate:>7.2f}/s  '\n",
    "                    '({batch_time.avg:.3f}s, {rate_avg:>7.2f}/s)  '\n",
    "                    'LR: {lr:.3e}  '\n",
    "                    'Data: {data_time.val:.3f} ({data_time.avg:.3f})'.format(\n",
    "                        epoch,\n",
    "                        batch_idx, len(loader),\n",
    "                        100. * batch_idx / last_idx,\n",
    "                        loss=losses_m,\n",
    "#                         loss_d=losses_d,\n",
    "#                         loss_g=losses_g,\n",
    "                        loss_kd=losses_kd,\n",
    "                        loss_ce=losses_ce,\n",
    "                        batch_time=batch_time_m,\n",
    "                        rate=inputs.size(0) * args.world_size / batch_time_m.val,\n",
    "                        rate_avg=inputs.size(0) * args.world_size / batch_time_m.avg,\n",
    "                        lr=lr,\n",
    "                        data_time=data_time_m))\n",
    "\n",
    "                if args.save_images and output_dir:\n",
    "                    torchvision.utils.save_image(\n",
    "                        inputs_z,\n",
    "                        os.path.join(output_dir, 'train-batch-%d.jpg' % batch_idx),\n",
    "                        padding=0,\n",
    "                        normalize=True)\n",
    "\n",
    "        if saver is not None and args.recovery_interval and (\n",
    "                last_batch or (batch_idx + 1) % args.recovery_interval == 0):\n",
    "            saver.save_recovery(\n",
    "                model, optimizer, args, epoch, model_ema=model_ema, use_amp=use_amp, batch_idx=batch_idx)\n",
    "\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step_update(num_updates=num_updates, metric=losses_m.avg)\n",
    "\n",
    "        end = time.time()\n",
    "        # end for\n",
    "\n",
    "    if hasattr(optimizer, 'sync_lookahead'):\n",
    "        optimizer.sync_lookahead()\n",
    "\n",
    "    return OrderedDict([('loss', losses_m.avg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_epoch(model_raw, model, val_loader, criterion, args):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    model_raw.eval()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # warmup, reduce variability of first batch time, especially for comparing torchscript vs non\n",
    "        end = time.time()\n",
    "        for i, (inputs, target) in enumerate(val_loader):\n",
    "            if args.no_prefetcher:\n",
    "                target = target.cuda()\n",
    "                inputs = inputs.cuda()\n",
    "            z = torch.randn(inputs.shape[0], 1, 15, 15, device='cuda')\n",
    "            \n",
    "            out = model(z)\n",
    "            # synthesizing input + generator\n",
    "            inputs_out = inputs + out\n",
    "            # compute output\n",
    "            output, foward_list = model_raw(inputs_out)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output.data, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), inputs.size(0))\n",
    "            top1.update(acc1.item(), inputs.size(0))\n",
    "            top5.update(acc5.item(), inputs.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % args.log_freq == 0:\n",
    "                logging.info(\n",
    "                    'Test: [{0:>4d}/{1}]  '\n",
    "                    'Time: {batch_time.val:.3f}s ({batch_time.avg:.3f}s, {rate_avg:>7.2f}/s)  '\n",
    "                    'Loss: {loss.val:>7.4f} ({loss.avg:>6.4f})  '\n",
    "                    'Acc@1: {top1.val:>7.3f} ({top1.avg:>7.3f})  '\n",
    "                    'Acc@5: {top5.val:>7.3f} ({top5.avg:>7.3f})'.format(\n",
    "                        i, len(val_loader), batch_time=batch_time,\n",
    "                        rate_avg=inputs.size(0) / batch_time.avg,\n",
    "                        loss=losses, top1=top1, top5=top5))\n",
    "\n",
    "    results = OrderedDict(\n",
    "        top1=round(top1.avg, 4), top1_err=round(100 - top1.avg, 4),\n",
    "        top5=round(top5.avg, 4), top5_err=round(100 - top5.avg, 4),\n",
    "        param_count=round(param_count / 1e6, 2),\n",
    "        img_size=data_config['input_size'][-1],\n",
    "        cropt_pct=crop_pct,\n",
    "        interpolation=data_config['interpolation'])\n",
    "\n",
    "    logging.info(' * Acc@1 {:.3f} ({:.3f}) Acc@5 {:.3f} ({:.3f})'.format(\n",
    "       results['top1'], results['top1_err'], results['top5'], results['top5_err']))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cutz/anaconda3/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "INFO:root:Train: 1 [   0/6100 (  0%)]  Loss:  5.276267 (5.2763)  Loss_kd:  0.348140 (0.3481)  Loss_ce:  1.794868 (1.7949)  Time: 20.053s,   31.42/s  (20.053s,   31.42/s)  LR: 1.000e-04  Data: 4.200 (4.200)\n",
      "INFO:root:Train: 1 [  50/6100 (  1%)]  Loss:  5.252110 (5.2731)  Loss_kd:  0.347956 (0.3543)  Loss_ce:  1.772553 (1.7303)  Time: 1.112s,  566.35/s  (1.578s,  399.28/s)  LR: 1.000e-04  Data: 0.001 (0.084)\n",
      "INFO:root:Train: 1 [ 100/6100 (  2%)]  Loss:  5.275858 (5.2804)  Loss_kd:  0.353982 (0.3544)  Loss_ce:  1.736035 (1.7361)  Time: 1.110s,  567.72/s  (1.347s,  467.61/s)  LR: 1.000e-04  Data: 0.001 (0.043)\n",
      "INFO:root:Train: 1 [ 150/6100 (  2%)]  Loss:  5.347467 (5.2629)  Loss_kd:  0.356035 (0.3531)  Loss_ce:  1.787115 (1.7315)  Time: 1.111s,  566.88/s  (1.270s,  496.12/s)  LR: 1.000e-04  Data: 0.001 (0.029)\n",
      "INFO:root:Train: 1 [ 200/6100 (  3%)]  Loss:  5.375351 (5.2611)  Loss_kd:  0.359040 (0.3529)  Loss_ce:  1.784950 (1.7323)  Time: 1.113s,  566.28/s  (1.231s,  511.90/s)  LR: 1.000e-04  Data: 0.001 (0.022)\n",
      "INFO:root:Train: 1 [ 250/6100 (  4%)]  Loss:  5.350311 (5.2596)  Loss_kd:  0.353371 (0.3527)  Loss_ce:  1.816602 (1.7325)  Time: 1.113s,  566.01/s  (1.207s,  521.87/s)  LR: 1.000e-04  Data: 0.002 (0.018)\n",
      "INFO:root:Train: 1 [ 300/6100 (  5%)]  Loss:  5.083258 (5.2564)  Loss_kd:  0.340139 (0.3526)  Loss_ce:  1.681864 (1.7302)  Time: 1.112s,  566.49/s  (1.192s,  528.70/s)  LR: 1.000e-04  Data: 0.001 (0.015)\n",
      "INFO:root:Train: 1 [ 350/6100 (  6%)]  Loss:  5.309671 (5.2573)  Loss_kd:  0.354703 (0.3528)  Loss_ce:  1.762644 (1.7297)  Time: 1.112s,  566.59/s  (1.181s,  533.66/s)  LR: 1.000e-04  Data: 0.001 (0.013)\n",
      "INFO:root:Train: 1 [ 400/6100 (  7%)]  Loss:  5.076871 (5.2570)  Loss_kd:  0.350210 (0.3526)  Loss_ce:  1.574776 (1.7305)  Time: 1.113s,  566.21/s  (1.172s,  537.53/s)  LR: 1.000e-04  Data: 0.001 (0.012)\n",
      "INFO:root:Train: 1 [ 450/6100 (  7%)]  Loss:  5.261547 (5.2575)  Loss_kd:  0.345601 (0.3525)  Loss_ce:  1.805538 (1.7320)  Time: 1.111s,  566.87/s  (1.165s,  540.62/s)  LR: 1.000e-04  Data: 0.001 (0.010)\n",
      "INFO:root:Train: 1 [ 500/6100 (  8%)]  Loss:  5.084877 (5.2549)  Loss_kd:  0.343999 (0.3524)  Loss_ce:  1.644888 (1.7309)  Time: 1.109s,  567.83/s  (1.160s,  543.05/s)  LR: 1.000e-04  Data: 0.001 (0.009)\n",
      "INFO:root:Train: 1 [ 550/6100 (  9%)]  Loss:  5.404126 (5.2584)  Loss_kd:  0.356124 (0.3527)  Loss_ce:  1.842882 (1.7317)  Time: 1.113s,  565.87/s  (1.156s,  545.11/s)  LR: 1.000e-04  Data: 0.001 (0.009)\n",
      "INFO:root:Train: 1 [ 600/6100 ( 10%)]  Loss:  5.420307 (5.2588)  Loss_kd:  0.346156 (0.3527)  Loss_ce:  1.958742 (1.7323)  Time: 1.113s,  566.06/s  (1.152s,  546.80/s)  LR: 1.000e-04  Data: 0.001 (0.008)\n",
      "INFO:root:Train: 1 [ 650/6100 ( 11%)]  Loss:  5.290703 (5.2597)  Loss_kd:  0.351046 (0.3527)  Loss_ce:  1.780241 (1.7322)  Time: 1.114s,  565.55/s  (1.149s,  548.27/s)  LR: 1.000e-04  Data: 0.001 (0.007)\n",
      "INFO:root:Train: 1 [ 700/6100 ( 11%)]  Loss:  5.253068 (5.2621)  Loss_kd:  0.349715 (0.3529)  Loss_ce:  1.755921 (1.7333)  Time: 1.108s,  568.39/s  (1.146s,  549.52/s)  LR: 1.000e-04  Data: 0.001 (0.007)\n",
      "INFO:root:Train: 1 [ 750/6100 ( 12%)]  Loss:  4.947840 (5.2646)  Loss_kd:  0.335339 (0.3529)  Loss_ce:  1.594453 (1.7353)  Time: 1.113s,  566.22/s  (1.144s,  550.62/s)  LR: 1.000e-04  Data: 0.001 (0.007)\n",
      "INFO:root:Train: 1 [ 800/6100 ( 13%)]  Loss:  5.332715 (5.2635)  Loss_kd:  0.359363 (0.3529)  Loss_ce:  1.739086 (1.7348)  Time: 1.112s,  566.41/s  (1.142s,  551.56/s)  LR: 1.000e-04  Data: 0.001 (0.006)\n",
      "INFO:root:Train: 1 [ 850/6100 ( 14%)]  Loss:  5.325326 (5.2635)  Loss_kd:  0.360679 (0.3530)  Loss_ce:  1.718532 (1.7339)  Time: 1.112s,  566.46/s  (1.141s,  552.36/s)  LR: 1.000e-04  Data: 0.001 (0.006)\n",
      "INFO:root:Train: 1 [ 900/6100 ( 15%)]  Loss:  5.317809 (5.2632)  Loss_kd:  0.351029 (0.3530)  Loss_ce:  1.807519 (1.7333)  Time: 1.112s,  566.56/s  (1.139s,  553.10/s)  LR: 1.000e-04  Data: 0.001 (0.006)\n",
      "INFO:root:Train: 1 [ 950/6100 ( 16%)]  Loss:  5.412984 (5.2648)  Loss_kd:  0.363205 (0.3530)  Loss_ce:  1.780929 (1.7345)  Time: 1.111s,  567.01/s  (1.138s,  553.79/s)  LR: 1.000e-04  Data: 0.001 (0.005)\n",
      "INFO:root:Train: 1 [1000/6100 ( 16%)]  Loss:  5.395475 (5.2647)  Loss_kd:  0.362738 (0.3530)  Loss_ce:  1.768095 (1.7345)  Time: 1.111s,  566.98/s  (1.136s,  554.41/s)  LR: 1.000e-04  Data: 0.001 (0.005)\n",
      "INFO:root:Train: 1 [1050/6100 ( 17%)]  Loss:  5.134870 (5.2658)  Loss_kd:  0.348662 (0.3531)  Loss_ce:  1.648255 (1.7348)  Time: 1.115s,  565.15/s  (1.135s,  554.96/s)  LR: 1.000e-04  Data: 0.003 (0.005)\n",
      "INFO:root:Train: 1 [1100/6100 ( 18%)]  Loss:  5.180948 (5.2652)  Loss_kd:  0.348681 (0.3531)  Loss_ce:  1.694138 (1.7343)  Time: 1.112s,  566.37/s  (1.134s,  555.46/s)  LR: 1.000e-04  Data: 0.001 (0.005)\n",
      "/home/cutz/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "INFO:root:Train: 1 [1150/6100 ( 19%)]  Loss:  5.269763 (5.2638)  Loss_kd:  0.348149 (0.3530)  Loss_ce:  1.788273 (1.7333)  Time: 1.118s,  563.73/s  (1.133s,  555.90/s)  LR: 1.000e-04  Data: 0.005 (0.005)\n",
      "INFO:root:Train: 1 [1200/6100 ( 20%)]  Loss:  5.168962 (5.2635)  Loss_kd:  0.345133 (0.3530)  Loss_ce:  1.717635 (1.7335)  Time: 1.112s,  566.59/s  (1.132s,  556.32/s)  LR: 1.000e-04  Data: 0.001 (0.005)\n",
      "INFO:root:Train: 1 [1250/6100 ( 20%)]  Loss:  5.180990 (5.2639)  Loss_kd:  0.345520 (0.3530)  Loss_ce:  1.725795 (1.7336)  Time: 1.114s,  565.67/s  (1.132s,  556.71/s)  LR: 1.000e-04  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 1 [1300/6100 ( 21%)]  Loss:  5.258718 (5.2629)  Loss_kd:  0.357934 (0.3529)  Loss_ce:  1.679382 (1.7334)  Time: 1.114s,  565.36/s  (1.131s,  557.07/s)  LR: 1.000e-04  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 1 [1350/6100 ( 22%)]  Loss:  5.245116 (5.2609)  Loss_kd:  0.355705 (0.3528)  Loss_ce:  1.688064 (1.7329)  Time: 1.112s,  566.60/s  (1.130s,  557.40/s)  LR: 1.000e-04  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 1 [1400/6100 ( 23%)]  Loss:  5.274315 (5.2614)  Loss_kd:  0.352138 (0.3528)  Loss_ce:  1.752937 (1.7330)  Time: 1.112s,  566.46/s  (1.130s,  557.69/s)  LR: 1.000e-04  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 1 [1450/6100 ( 24%)]  Loss:  5.268794 (5.2601)  Loss_kd:  0.348307 (0.3528)  Loss_ce:  1.785721 (1.7323)  Time: 1.113s,  565.95/s  (1.129s,  557.98/s)  LR: 1.000e-04  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 1 [1500/6100 ( 25%)]  Loss:  5.534124 (5.2599)  Loss_kd:  0.371101 (0.3528)  Loss_ce:  1.823113 (1.7320)  Time: 1.113s,  566.15/s  (1.129s,  558.24/s)  LR: 1.000e-04  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 1 [1550/6100 ( 25%)]  Loss:  5.435474 (5.2586)  Loss_kd:  0.370810 (0.3527)  Loss_ce:  1.727372 (1.7315)  Time: 1.112s,  566.70/s  (1.128s,  558.49/s)  LR: 1.000e-04  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 1 [1600/6100 ( 26%)]  Loss:  5.288796 (5.2584)  Loss_kd:  0.351337 (0.3527)  Loss_ce:  1.775429 (1.7312)  Time: 1.113s,  566.24/s  (1.128s,  558.72/s)  LR: 1.000e-04  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 1 [1650/6100 ( 27%)]  Loss:  5.018963 (5.2592)  Loss_kd:  0.331655 (0.3528)  Loss_ce:  1.702409 (1.7317)  Time: 1.112s,  566.78/s  (1.127s,  558.91/s)  LR: 1.000e-04  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 1 [1700/6100 ( 28%)]  Loss:  5.346643 (5.2600)  Loss_kd:  0.353674 (0.3528)  Loss_ce:  1.809907 (1.7320)  Time: 1.113s,  566.17/s  (1.127s,  559.12/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 1 [1750/6100 ( 29%)]  Loss:  5.368499 (5.2601)  Loss_kd:  0.350778 (0.3528)  Loss_ce:  1.860721 (1.7317)  Time: 1.114s,  565.44/s  (1.126s,  559.32/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 1 [1800/6100 ( 30%)]  Loss:  5.474782 (5.2600)  Loss_kd:  0.362718 (0.3529)  Loss_ce:  1.847602 (1.7313)  Time: 1.112s,  566.80/s  (1.126s,  559.50/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 1 [1850/6100 ( 30%)]  Loss:  4.940888 (5.2591)  Loss_kd:  0.340686 (0.3528)  Loss_ce:  1.534028 (1.7310)  Time: 1.113s,  565.96/s  (1.126s,  559.66/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 1 [1900/6100 ( 31%)]  Loss:  5.266012 (5.2585)  Loss_kd:  0.346126 (0.3528)  Loss_ce:  1.804755 (1.7307)  Time: 1.112s,  566.46/s  (1.125s,  559.83/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train: 1 [1950/6100 ( 32%)]  Loss:  5.210876 (5.2574)  Loss_kd:  0.344078 (0.3527)  Loss_ce:  1.770100 (1.7301)  Time: 1.113s,  566.14/s  (1.125s,  560.00/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 1 [2000/6100 ( 33%)]  Loss:  5.489964 (5.2572)  Loss_kd:  0.369536 (0.3527)  Loss_ce:  1.794599 (1.7302)  Time: 1.112s,  566.40/s  (1.125s,  560.14/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 1 [2050/6100 ( 34%)]  Loss:  5.243854 (5.2565)  Loss_kd:  0.354922 (0.3526)  Loss_ce:  1.694637 (1.7301)  Time: 1.113s,  565.99/s  (1.124s,  560.28/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 1 [2100/6100 ( 34%)]  Loss:  5.288067 (5.2564)  Loss_kd:  0.349567 (0.3527)  Loss_ce:  1.792400 (1.7299)  Time: 1.114s,  565.78/s  (1.124s,  560.42/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 1 [2150/6100 ( 35%)]  Loss:  5.417606 (5.2562)  Loss_kd:  0.365958 (0.3526)  Loss_ce:  1.758026 (1.7298)  Time: 1.109s,  568.02/s  (1.124s,  560.56/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 1 [2200/6100 ( 36%)]  Loss:  5.337467 (5.2569)  Loss_kd:  0.350407 (0.3527)  Loss_ce:  1.833400 (1.7301)  Time: 1.121s,  562.17/s  (1.124s,  560.68/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 1 [2250/6100 ( 37%)]  Loss:  5.214485 (5.2561)  Loss_kd:  0.344878 (0.3526)  Loss_ce:  1.765701 (1.7300)  Time: 1.112s,  566.32/s  (1.123s,  560.80/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 1 [2300/6100 ( 38%)]  Loss:  5.154771 (5.2560)  Loss_kd:  0.340504 (0.3526)  Loss_ce:  1.749732 (1.7299)  Time: 1.113s,  566.08/s  (1.123s,  560.91/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'IHDR' 16 13\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'sRGB' 41 1\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'gAMA' 54 4\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'cHRM' 70 32\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'pHYs' 114 9\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'IDAT' 135 65401\n",
      "INFO:root:Train: 1 [2350/6100 ( 39%)]  Loss:  5.281657 (5.2558)  Loss_kd:  0.354492 (0.3526)  Loss_ce:  1.736738 (1.7297)  Time: 1.113s,  565.83/s  (1.123s,  561.02/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 1 [2400/6100 ( 39%)]  Loss:  5.463510 (5.2551)  Loss_kd:  0.356776 (0.3526)  Loss_ce:  1.895751 (1.7293)  Time: 1.112s,  566.56/s  (1.123s,  561.12/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 1 [2450/6100 ( 40%)]  Loss:  4.978136 (5.2542)  Loss_kd:  0.335339 (0.3525)  Loss_ce:  1.624745 (1.7292)  Time: 1.110s,  567.56/s  (1.123s,  561.22/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 1 [2500/6100 ( 41%)]  Loss:  5.291010 (5.2550)  Loss_kd:  0.346125 (0.3526)  Loss_ce:  1.829765 (1.7293)  Time: 1.114s,  565.36/s  (1.122s,  561.32/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 1 [2550/6100 ( 42%)]  Loss:  5.168184 (5.2552)  Loss_kd:  0.353094 (0.3526)  Loss_ce:  1.637243 (1.7293)  Time: 1.113s,  566.27/s  (1.122s,  561.41/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 1 [2600/6100 ( 43%)]  Loss:  5.078630 (5.2555)  Loss_kd:  0.349367 (0.3526)  Loss_ce:  1.584959 (1.7290)  Time: 1.135s,  555.09/s  (1.122s,  561.50/s)  LR: 1.000e-04  Data: 0.013 (0.003)\n",
      "INFO:root:Train: 1 [2650/6100 ( 43%)]  Loss:  5.139656 (5.2557)  Loss_kd:  0.347687 (0.3527)  Loss_ce:  1.662787 (1.7290)  Time: 1.114s,  565.42/s  (1.122s,  561.58/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 1 [2700/6100 ( 44%)]  Loss:  5.071623 (5.2555)  Loss_kd:  0.354458 (0.3526)  Loss_ce:  1.527045 (1.7291)  Time: 1.113s,  566.00/s  (1.122s,  561.65/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 1 [2750/6100 ( 45%)]  Loss:  5.120701 (5.2553)  Loss_kd:  0.345077 (0.3526)  Loss_ce:  1.669935 (1.7292)  Time: 1.113s,  566.19/s  (1.122s,  561.73/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 1 [2800/6100 ( 46%)]  Loss:  5.215764 (5.2549)  Loss_kd:  0.345910 (0.3526)  Loss_ce:  1.756665 (1.7291)  Time: 1.113s,  566.17/s  (1.121s,  561.79/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 1 [2850/6100 ( 47%)]  Loss:  5.445732 (5.2547)  Loss_kd:  0.368480 (0.3526)  Loss_ce:  1.760931 (1.7290)  Time: 1.113s,  565.96/s  (1.121s,  561.87/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [2900/6100 ( 48%)]  Loss:  5.309165 (5.2551)  Loss_kd:  0.354253 (0.3526)  Loss_ce:  1.766639 (1.7293)  Time: 1.117s,  564.13/s  (1.121s,  561.94/s)  LR: 1.000e-04  Data: 0.005 (0.002)\n",
      "INFO:root:Train: 1 [2950/6100 ( 48%)]  Loss:  5.573194 (5.2552)  Loss_kd:  0.362445 (0.3526)  Loss_ce:  1.948747 (1.7294)  Time: 1.115s,  565.06/s  (1.121s,  561.99/s)  LR: 1.000e-04  Data: 0.002 (0.002)\n",
      "INFO:root:Train: 1 [3000/6100 ( 49%)]  Loss:  5.385511 (5.2554)  Loss_kd:  0.366236 (0.3526)  Loss_ce:  1.723156 (1.7296)  Time: 1.111s,  566.92/s  (1.121s,  562.06/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [3050/6100 ( 50%)]  Loss:  5.642126 (5.2556)  Loss_kd:  0.368092 (0.3526)  Loss_ce:  1.961208 (1.7298)  Time: 1.115s,  565.26/s  (1.121s,  562.12/s)  LR: 1.000e-04  Data: 0.003 (0.002)\n",
      "INFO:root:Train: 1 [3100/6100 ( 51%)]  Loss:  5.005820 (5.2551)  Loss_kd:  0.338880 (0.3526)  Loss_ce:  1.617023 (1.7296)  Time: 1.112s,  566.57/s  (1.121s,  562.18/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [3150/6100 ( 52%)]  Loss:  5.125292 (5.2548)  Loss_kd:  0.346380 (0.3526)  Loss_ce:  1.661495 (1.7293)  Time: 1.109s,  567.83/s  (1.121s,  562.24/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [3200/6100 ( 52%)]  Loss:  5.349456 (5.2552)  Loss_kd:  0.356839 (0.3526)  Loss_ce:  1.781065 (1.7296)  Time: 1.112s,  566.50/s  (1.120s,  562.30/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [3250/6100 ( 53%)]  Loss:  5.385219 (5.2558)  Loss_kd:  0.343812 (0.3526)  Loss_ce:  1.947095 (1.7298)  Time: 1.110s,  567.37/s  (1.120s,  562.36/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [3300/6100 ( 54%)]  Loss:  5.246648 (5.2556)  Loss_kd:  0.351840 (0.3526)  Loss_ce:  1.728247 (1.7297)  Time: 1.116s,  564.34/s  (1.120s,  562.40/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [3350/6100 ( 55%)]  Loss:  5.163737 (5.2549)  Loss_kd:  0.348752 (0.3526)  Loss_ce:  1.676214 (1.7293)  Time: 1.112s,  566.34/s  (1.120s,  562.46/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [3400/6100 ( 56%)]  Loss:  5.155761 (5.2551)  Loss_kd:  0.348555 (0.3526)  Loss_ce:  1.670210 (1.7293)  Time: 1.112s,  566.66/s  (1.120s,  562.51/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [3450/6100 ( 57%)]  Loss:  5.485568 (5.2549)  Loss_kd:  0.356041 (0.3526)  Loss_ce:  1.925159 (1.7293)  Time: 1.114s,  565.62/s  (1.120s,  562.56/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [3500/6100 ( 57%)]  Loss:  5.350235 (5.2547)  Loss_kd:  0.357837 (0.3526)  Loss_ce:  1.771862 (1.7290)  Time: 1.113s,  566.28/s  (1.120s,  562.60/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [3550/6100 ( 58%)]  Loss:  5.146723 (5.2547)  Loss_kd:  0.346313 (0.3526)  Loss_ce:  1.683591 (1.7290)  Time: 1.113s,  566.29/s  (1.120s,  562.65/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [3600/6100 ( 59%)]  Loss:  5.289391 (5.2549)  Loss_kd:  0.355407 (0.3526)  Loss_ce:  1.735317 (1.7291)  Time: 1.111s,  567.30/s  (1.120s,  562.70/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [3650/6100 ( 60%)]  Loss:  5.256007 (5.2549)  Loss_kd:  0.360702 (0.3526)  Loss_ce:  1.648982 (1.7290)  Time: 1.112s,  566.38/s  (1.120s,  562.75/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [3700/6100 ( 61%)]  Loss:  5.289477 (5.2548)  Loss_kd:  0.350645 (0.3526)  Loss_ce:  1.783027 (1.7289)  Time: 1.116s,  564.65/s  (1.119s,  562.78/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [3750/6100 ( 61%)]  Loss:  5.402377 (5.2553)  Loss_kd:  0.361651 (0.3526)  Loss_ce:  1.785867 (1.7293)  Time: 1.118s,  563.53/s  (1.119s,  562.82/s)  LR: 1.000e-04  Data: 0.006 (0.002)\n",
      "INFO:root:Train: 1 [3800/6100 ( 62%)]  Loss:  5.357683 (5.2554)  Loss_kd:  0.359820 (0.3526)  Loss_ce:  1.759479 (1.7294)  Time: 1.112s,  566.35/s  (1.119s,  562.86/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [3850/6100 ( 63%)]  Loss:  5.233996 (5.2555)  Loss_kd:  0.351146 (0.3526)  Loss_ce:  1.722537 (1.7296)  Time: 1.112s,  566.51/s  (1.119s,  562.90/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train: 1 [3900/6100 ( 64%)]  Loss:  5.341830 (5.2552)  Loss_kd:  0.360665 (0.3526)  Loss_ce:  1.735178 (1.7294)  Time: 1.112s,  566.64/s  (1.119s,  562.93/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [3950/6100 ( 65%)]  Loss:  5.245465 (5.2552)  Loss_kd:  0.349749 (0.3526)  Loss_ce:  1.747975 (1.7294)  Time: 1.113s,  566.28/s  (1.119s,  562.97/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [4000/6100 ( 66%)]  Loss:  5.018976 (5.2552)  Loss_kd:  0.345294 (0.3526)  Loss_ce:  1.566032 (1.7295)  Time: 1.112s,  566.33/s  (1.119s,  563.00/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [4050/6100 ( 66%)]  Loss:  5.527436 (5.2557)  Loss_kd:  0.373173 (0.3526)  Loss_ce:  1.795704 (1.7298)  Time: 1.112s,  566.50/s  (1.119s,  563.04/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [4100/6100 ( 67%)]  Loss:  5.132126 (5.2553)  Loss_kd:  0.341636 (0.3526)  Loss_ce:  1.715763 (1.7297)  Time: 1.112s,  566.34/s  (1.119s,  563.07/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [4150/6100 ( 68%)]  Loss:  5.097013 (5.2555)  Loss_kd:  0.339044 (0.3526)  Loss_ce:  1.706571 (1.7300)  Time: 1.112s,  566.58/s  (1.119s,  563.10/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [4200/6100 ( 69%)]  Loss:  5.224981 (5.2551)  Loss_kd:  0.347911 (0.3525)  Loss_ce:  1.745873 (1.7297)  Time: 1.112s,  566.37/s  (1.119s,  563.14/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [4250/6100 ( 70%)]  Loss:  5.359478 (5.2549)  Loss_kd:  0.363569 (0.3525)  Loss_ce:  1.723784 (1.7296)  Time: 1.114s,  565.65/s  (1.119s,  563.17/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [4300/6100 ( 71%)]  Loss:  5.073153 (5.2542)  Loss_kd:  0.346401 (0.3525)  Loss_ce:  1.609139 (1.7293)  Time: 1.111s,  566.99/s  (1.119s,  563.20/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [4350/6100 ( 71%)]  Loss:  5.233511 (5.2539)  Loss_kd:  0.351264 (0.3525)  Loss_ce:  1.720870 (1.7291)  Time: 1.112s,  566.38/s  (1.119s,  563.23/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [4400/6100 ( 72%)]  Loss:  5.103574 (5.2537)  Loss_kd:  0.336573 (0.3525)  Loss_ce:  1.737844 (1.7289)  Time: 1.113s,  565.81/s  (1.119s,  563.25/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [4450/6100 ( 73%)]  Loss:  5.058679 (5.2533)  Loss_kd:  0.337806 (0.3525)  Loss_ce:  1.680623 (1.7287)  Time: 1.113s,  566.09/s  (1.118s,  563.28/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [4500/6100 ( 74%)]  Loss:  5.270680 (5.2534)  Loss_kd:  0.349915 (0.3524)  Loss_ce:  1.771525 (1.7289)  Time: 1.112s,  566.70/s  (1.118s,  563.31/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [4550/6100 ( 75%)]  Loss:  5.198202 (5.2533)  Loss_kd:  0.355889 (0.3524)  Loss_ce:  1.639314 (1.7288)  Time: 1.114s,  565.73/s  (1.118s,  563.33/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [4600/6100 ( 75%)]  Loss:  5.251590 (5.2536)  Loss_kd:  0.362243 (0.3524)  Loss_ce:  1.629159 (1.7291)  Time: 1.110s,  567.49/s  (1.118s,  563.36/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [4650/6100 ( 76%)]  Loss:  5.257680 (5.2535)  Loss_kd:  0.340814 (0.3524)  Loss_ce:  1.849542 (1.7291)  Time: 1.112s,  566.55/s  (1.118s,  563.38/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [4700/6100 ( 77%)]  Loss:  5.354084 (5.2536)  Loss_kd:  0.361055 (0.3524)  Loss_ce:  1.743536 (1.7292)  Time: 1.113s,  565.95/s  (1.118s,  563.40/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [4750/6100 ( 78%)]  Loss:  5.229972 (5.2534)  Loss_kd:  0.350186 (0.3524)  Loss_ce:  1.728111 (1.7291)  Time: 1.111s,  567.03/s  (1.118s,  563.43/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [4800/6100 ( 79%)]  Loss:  5.311452 (5.2536)  Loss_kd:  0.359022 (0.3524)  Loss_ce:  1.721232 (1.7292)  Time: 1.114s,  565.48/s  (1.118s,  563.45/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [4850/6100 ( 80%)]  Loss:  5.069668 (5.2537)  Loss_kd:  0.342761 (0.3525)  Loss_ce:  1.642055 (1.7291)  Time: 1.113s,  566.29/s  (1.118s,  563.48/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [4900/6100 ( 80%)]  Loss:  5.564386 (5.2542)  Loss_kd:  0.372324 (0.3525)  Loss_ce:  1.841147 (1.7294)  Time: 1.119s,  562.98/s  (1.118s,  563.50/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [4950/6100 ( 81%)]  Loss:  5.150201 (5.2544)  Loss_kd:  0.338890 (0.3525)  Loss_ce:  1.761301 (1.7295)  Time: 1.113s,  565.91/s  (1.118s,  563.53/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [5000/6100 ( 82%)]  Loss:  5.083829 (5.2542)  Loss_kd:  0.339769 (0.3525)  Loss_ce:  1.686135 (1.7293)  Time: 1.109s,  568.08/s  (1.118s,  563.55/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [5050/6100 ( 83%)]  Loss:  5.417594 (5.2545)  Loss_kd:  0.358744 (0.3525)  Loss_ce:  1.830154 (1.7295)  Time: 1.113s,  566.18/s  (1.118s,  563.57/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [5100/6100 ( 84%)]  Loss:  5.438483 (5.2544)  Loss_kd:  0.359861 (0.3525)  Loss_ce:  1.839877 (1.7295)  Time: 1.112s,  566.60/s  (1.118s,  563.59/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [5150/6100 ( 84%)]  Loss:  5.349748 (5.2547)  Loss_kd:  0.361806 (0.3525)  Loss_ce:  1.731693 (1.7296)  Time: 1.114s,  565.35/s  (1.118s,  563.62/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [5200/6100 ( 85%)]  Loss:  5.025105 (5.2548)  Loss_kd:  0.336583 (0.3525)  Loss_ce:  1.659272 (1.7297)  Time: 1.116s,  564.71/s  (1.118s,  563.64/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [5250/6100 ( 86%)]  Loss:  5.322136 (5.2548)  Loss_kd:  0.353460 (0.3525)  Loss_ce:  1.787539 (1.7296)  Time: 1.113s,  566.17/s  (1.118s,  563.66/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [5300/6100 ( 87%)]  Loss:  5.071207 (5.2548)  Loss_kd:  0.347240 (0.3525)  Loss_ce:  1.598804 (1.7296)  Time: 1.114s,  565.63/s  (1.118s,  563.68/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [5350/6100 ( 88%)]  Loss:  5.329281 (5.2548)  Loss_kd:  0.351741 (0.3525)  Loss_ce:  1.811867 (1.7297)  Time: 1.113s,  566.05/s  (1.118s,  563.70/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [5400/6100 ( 89%)]  Loss:  5.312825 (5.2550)  Loss_kd:  0.363357 (0.3525)  Loss_ce:  1.679256 (1.7299)  Time: 1.113s,  566.19/s  (1.118s,  563.71/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [5450/6100 ( 89%)]  Loss:  5.207290 (5.2552)  Loss_kd:  0.343497 (0.3525)  Loss_ce:  1.772325 (1.7300)  Time: 1.115s,  565.17/s  (1.118s,  563.73/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [5500/6100 ( 90%)]  Loss:  5.118176 (5.2552)  Loss_kd:  0.342204 (0.3525)  Loss_ce:  1.696137 (1.7301)  Time: 1.113s,  566.17/s  (1.118s,  563.75/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [5550/6100 ( 91%)]  Loss:  5.136555 (5.2552)  Loss_kd:  0.343086 (0.3525)  Loss_ce:  1.705693 (1.7301)  Time: 1.112s,  566.36/s  (1.117s,  563.77/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [5600/6100 ( 92%)]  Loss:  5.089604 (5.2550)  Loss_kd:  0.340370 (0.3525)  Loss_ce:  1.685908 (1.7300)  Time: 1.113s,  566.09/s  (1.117s,  563.79/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [5650/6100 ( 93%)]  Loss:  5.153236 (5.2553)  Loss_kd:  0.358166 (0.3525)  Loss_ce:  1.571577 (1.7302)  Time: 1.113s,  566.17/s  (1.117s,  563.80/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [5700/6100 ( 93%)]  Loss:  5.234819 (5.2551)  Loss_kd:  0.351875 (0.3525)  Loss_ce:  1.716068 (1.7301)  Time: 1.113s,  566.13/s  (1.117s,  563.82/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [5750/6100 ( 94%)]  Loss:  5.255536 (5.2553)  Loss_kd:  0.350733 (0.3525)  Loss_ce:  1.748204 (1.7301)  Time: 1.112s,  566.79/s  (1.117s,  563.84/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [5800/6100 ( 95%)]  Loss:  5.420710 (5.2552)  Loss_kd:  0.363529 (0.3525)  Loss_ce:  1.785415 (1.7299)  Time: 1.112s,  566.31/s  (1.117s,  563.86/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [5850/6100 ( 96%)]  Loss:  5.266694 (5.2551)  Loss_kd:  0.357886 (0.3525)  Loss_ce:  1.687835 (1.7300)  Time: 1.112s,  566.44/s  (1.117s,  563.87/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [5900/6100 ( 97%)]  Loss:  5.128388 (5.2550)  Loss_kd:  0.349300 (0.3525)  Loss_ce:  1.635390 (1.7298)  Time: 1.113s,  565.96/s  (1.117s,  563.89/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train: 1 [5950/6100 ( 98%)]  Loss:  5.344646 (5.2548)  Loss_kd:  0.366044 (0.3525)  Loss_ce:  1.684207 (1.7296)  Time: 1.111s,  566.88/s  (1.117s,  563.90/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [6000/6100 ( 98%)]  Loss:  5.366744 (5.2548)  Loss_kd:  0.364773 (0.3525)  Loss_ce:  1.719016 (1.7296)  Time: 1.112s,  566.33/s  (1.117s,  563.92/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [6050/6100 ( 99%)]  Loss:  5.186093 (5.2548)  Loss_kd:  0.344458 (0.3525)  Loss_ce:  1.741510 (1.7298)  Time: 1.113s,  566.15/s  (1.117s,  563.93/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 1 [6099/6100 (100%)]  Loss:  5.276394 (5.2548)  Loss_kd:  0.344298 (0.3525)  Loss_ce:  1.833411 (1.7298)  Time: 1.364s,  462.01/s  (1.117s,  563.93/s)  LR: 1.000e-04  Data: 0.256 (0.002)\n",
      "INFO:root:Test: [   0/239]  Time: 5.281s (5.281s,   39.76/s)  Loss:  0.5095 (0.5095)  Acc@1:  88.095 ( 88.095)  Acc@5:  97.619 ( 97.619)\n",
      "INFO:root:Test: [  10/239]  Time: 0.326s (0.789s,  266.00/s)  Loss:  0.9716 (0.6208)  Acc@1:  77.619 ( 85.584)  Acc@5:  93.333 ( 97.143)\n",
      "INFO:root:Test: [  20/239]  Time: 0.327s (0.570s,  368.49/s)  Loss:  0.4691 (0.7224)  Acc@1:  90.952 ( 82.608)  Acc@5:  97.143 ( 96.327)\n",
      "INFO:root:Test: [  30/239]  Time: 0.325s (0.492s,  427.13/s)  Loss:  0.5344 (0.6752)  Acc@1:  88.571 ( 84.163)  Acc@5:  95.714 ( 96.375)\n",
      "INFO:root:Test: [  40/239]  Time: 0.331s (0.452s,  464.68/s)  Loss:  0.7856 (0.6633)  Acc@1:  82.857 ( 84.506)  Acc@5:  94.762 ( 96.458)\n",
      "INFO:root:Test: [  50/239]  Time: 0.323s (0.428s,  490.36/s)  Loss:  0.6504 (0.6785)  Acc@1:  83.333 ( 84.006)  Acc@5:  96.190 ( 96.536)\n",
      "INFO:root:Test: [  60/239]  Time: 0.327s (0.412s,  510.12/s)  Loss:  0.3491 (0.6817)  Acc@1:  93.333 ( 83.692)  Acc@5:  99.048 ( 96.667)\n",
      "INFO:root:Test: [  70/239]  Time: 0.327s (0.406s,  516.83/s)  Loss:  0.6535 (0.6862)  Acc@1:  87.143 ( 83.628)  Acc@5:  95.238 ( 96.680)\n",
      "INFO:root:Test: [  80/239]  Time: 0.326s (0.397s,  529.39/s)  Loss:  0.4856 (0.6702)  Acc@1:  91.429 ( 84.151)  Acc@5:  97.143 ( 96.778)\n",
      "INFO:root:Test: [  90/239]  Time: 0.326s (0.389s,  539.87/s)  Loss:  1.0435 (0.6744)  Acc@1:  73.333 ( 83.998)  Acc@5:  94.286 ( 96.787)\n",
      "INFO:root:Test: [ 100/239]  Time: 0.334s (0.383s,  548.37/s)  Loss:  0.9210 (0.6960)  Acc@1:  78.571 ( 83.527)  Acc@5:  93.810 ( 96.525)\n",
      "INFO:root:Test: [ 110/239]  Time: 0.327s (0.378s,  555.38/s)  Loss:  1.7354 (0.7311)  Acc@1:  60.000 ( 82.686)  Acc@5:  82.857 ( 96.088)\n",
      "INFO:root:Test: [ 120/239]  Time: 0.326s (0.374s,  561.48/s)  Loss:  1.3924 (0.7705)  Acc@1:  63.810 ( 81.716)  Acc@5:  90.000 ( 95.655)\n",
      "INFO:root:Test: [ 130/239]  Time: 0.326s (0.370s,  566.95/s)  Loss:  0.8564 (0.7892)  Acc@1:  79.524 ( 81.265)  Acc@5:  95.714 ( 95.474)\n",
      "INFO:root:Test: [ 140/239]  Time: 0.339s (0.367s,  571.58/s)  Loss:  1.2158 (0.7963)  Acc@1:  74.286 ( 81.189)  Acc@5:  90.476 ( 95.387)\n",
      "INFO:root:Test: [ 150/239]  Time: 0.328s (0.365s,  575.48/s)  Loss:  1.6460 (0.8166)  Acc@1:  66.667 ( 80.823)  Acc@5:  84.286 ( 95.080)\n",
      "INFO:root:Test: [ 160/239]  Time: 0.328s (0.363s,  579.01/s)  Loss:  1.1548 (0.8311)  Acc@1:  70.476 ( 80.417)  Acc@5:  91.429 ( 94.969)\n",
      "INFO:root:Test: [ 170/239]  Time: 0.326s (0.361s,  581.95/s)  Loss:  0.9432 (0.8434)  Acc@1:  77.619 ( 80.201)  Acc@5:  93.810 ( 94.876)\n",
      "INFO:root:Test: [ 180/239]  Time: 0.324s (0.359s,  584.94/s)  Loss:  0.8995 (0.8544)  Acc@1:  81.905 ( 79.958)  Acc@5:  93.810 ( 94.725)\n",
      "INFO:root:Test: [ 190/239]  Time: 0.337s (0.358s,  587.39/s)  Loss:  1.0362 (0.8645)  Acc@1:  78.571 ( 79.771)  Acc@5:  90.476 ( 94.560)\n",
      "INFO:root:Test: [ 200/239]  Time: 0.328s (0.356s,  589.86/s)  Loss:  1.1493 (0.8809)  Acc@1:  74.286 ( 79.351)  Acc@5:  92.381 ( 94.378)\n",
      "INFO:root:Test: [ 210/239]  Time: 0.325s (0.355s,  591.98/s)  Loss:  1.7351 (0.8899)  Acc@1:  59.524 ( 79.109)  Acc@5:  83.333 ( 94.272)\n",
      "INFO:root:Test: [ 220/239]  Time: 0.324s (0.353s,  594.29/s)  Loss:  0.6909 (0.8973)  Acc@1:  81.905 ( 78.940)  Acc@5:  97.143 ( 94.228)\n",
      "INFO:root:Test: [ 230/239]  Time: 0.324s (0.352s,  596.46/s)  Loss:  1.8947 (0.8974)  Acc@1:  55.714 ( 78.916)  Acc@5:  85.714 ( 94.244)\n",
      "INFO:root: * Acc@1 78.926 (21.074) Acc@5 94.294 (5.706)\n",
      "INFO:root:Current checkpoints:\n",
      " ('./output/train/20200625-133839-tf_efficientnet_b1-240/checkpoint-1.pth.tar', 78.926)\n",
      "\n",
      "INFO:root:Train: 2 [   0/6100 (  0%)]  Loss:  5.238651 (5.2387)  Loss_kd:  0.349034 (0.3490)  Loss_ce:  1.748306 (1.7483)  Time: 8.660s,   72.75/s  (8.660s,   72.75/s)  LR: 1.000e-04  Data: 4.741 (4.741)\n",
      "INFO:root:Train: 2 [  50/6100 (  1%)]  Loss:  4.940588 (5.2132)  Loss_kd:  0.331206 (0.3516)  Loss_ce:  1.628531 (1.6970)  Time: 1.112s,  566.44/s  (1.263s,  498.89/s)  LR: 1.000e-04  Data: 0.001 (0.094)\n",
      "INFO:root:Train: 2 [ 100/6100 (  2%)]  Loss:  5.454104 (5.2572)  Loss_kd:  0.359202 (0.3534)  Loss_ce:  1.862082 (1.7233)  Time: 1.113s,  566.14/s  (1.189s,  529.84/s)  LR: 1.000e-04  Data: 0.001 (0.048)\n",
      "INFO:root:Train: 2 [ 150/6100 (  2%)]  Loss:  5.250720 (5.2499)  Loss_kd:  0.349086 (0.3524)  Loss_ce:  1.759856 (1.7255)  Time: 1.113s,  565.87/s  (1.164s,  541.33/s)  LR: 1.000e-04  Data: 0.004 (0.033)\n",
      "INFO:root:Train: 2 [ 200/6100 (  3%)]  Loss:  4.992258 (5.2504)  Loss_kd:  0.341798 (0.3520)  Loss_ce:  1.574275 (1.7306)  Time: 1.110s,  567.74/s  (1.151s,  547.21/s)  LR: 1.000e-04  Data: 0.000 (0.025)\n",
      "INFO:root:Train: 2 [ 250/6100 (  4%)]  Loss:  5.480140 (5.2552)  Loss_kd:  0.357469 (0.3524)  Loss_ce:  1.905446 (1.7314)  Time: 1.113s,  566.00/s  (1.144s,  550.85/s)  LR: 1.000e-04  Data: 0.001 (0.020)\n",
      "INFO:root:Train: 2 [ 300/6100 (  5%)]  Loss:  5.180884 (5.2493)  Loss_kd:  0.337698 (0.3520)  Loss_ce:  1.803900 (1.7294)  Time: 1.112s,  566.50/s  (1.139s,  553.29/s)  LR: 1.000e-04  Data: 0.001 (0.017)\n",
      "INFO:root:Train: 2 [ 350/6100 (  6%)]  Loss:  5.185589 (5.2494)  Loss_kd:  0.350751 (0.3519)  Loss_ce:  1.678079 (1.7306)  Time: 1.113s,  566.06/s  (1.135s,  555.07/s)  LR: 1.000e-04  Data: 0.001 (0.015)\n",
      "INFO:root:Train: 2 [ 400/6100 (  7%)]  Loss:  5.279435 (5.2511)  Loss_kd:  0.361120 (0.3521)  Loss_ce:  1.668231 (1.7304)  Time: 1.113s,  565.84/s  (1.132s,  556.43/s)  LR: 1.000e-04  Data: 0.001 (0.013)\n",
      "INFO:root:Train: 2 [ 450/6100 (  7%)]  Loss:  5.358493 (5.2487)  Loss_kd:  0.351471 (0.3519)  Loss_ce:  1.843780 (1.7300)  Time: 1.112s,  566.41/s  (1.130s,  557.50/s)  LR: 1.000e-04  Data: 0.001 (0.012)\n",
      "INFO:root:Train: 2 [ 500/6100 (  8%)]  Loss:  5.399711 (5.2479)  Loss_kd:  0.354122 (0.3519)  Loss_ce:  1.858491 (1.7291)  Time: 1.113s,  566.05/s  (1.128s,  558.33/s)  LR: 1.000e-04  Data: 0.001 (0.011)\n",
      "INFO:root:Train: 2 [ 550/6100 (  9%)]  Loss:  5.364088 (5.2493)  Loss_kd:  0.359321 (0.3519)  Loss_ce:  1.770880 (1.7299)  Time: 1.115s,  565.21/s  (1.127s,  559.02/s)  LR: 1.000e-04  Data: 0.001 (0.010)\n",
      "INFO:root:Train: 2 [ 600/6100 ( 10%)]  Loss:  5.197789 (5.2483)  Loss_kd:  0.356276 (0.3520)  Loss_ce:  1.635034 (1.7280)  Time: 1.113s,  566.17/s  (1.126s,  559.57/s)  LR: 1.000e-04  Data: 0.001 (0.009)\n",
      "INFO:root:Train: 2 [ 650/6100 ( 11%)]  Loss:  5.157244 (5.2471)  Loss_kd:  0.356810 (0.3519)  Loss_ce:  1.589142 (1.7280)  Time: 1.113s,  565.83/s  (1.125s,  560.08/s)  LR: 1.000e-04  Data: 0.001 (0.008)\n",
      "INFO:root:Train: 2 [ 700/6100 ( 11%)]  Loss:  4.910888 (5.2451)  Loss_kd:  0.319034 (0.3518)  Loss_ce:  1.720543 (1.7267)  Time: 1.112s,  566.32/s  (1.124s,  560.52/s)  LR: 1.000e-04  Data: 0.001 (0.008)\n",
      "INFO:root:Train: 2 [ 750/6100 ( 12%)]  Loss:  5.439123 (5.2455)  Loss_kd:  0.362202 (0.3518)  Loss_ce:  1.817101 (1.7274)  Time: 1.109s,  568.29/s  (1.123s,  560.86/s)  LR: 1.000e-04  Data: 0.001 (0.007)\n",
      "INFO:root:Train: 2 [ 800/6100 ( 13%)]  Loss:  5.074397 (5.2452)  Loss_kd:  0.342805 (0.3518)  Loss_ce:  1.646348 (1.7276)  Time: 1.114s,  565.72/s  (1.123s,  561.15/s)  LR: 1.000e-04  Data: 0.001 (0.007)\n",
      "INFO:root:Train: 2 [ 850/6100 ( 14%)]  Loss:  5.026216 (5.2458)  Loss_kd:  0.332666 (0.3518)  Loss_ce:  1.699552 (1.7275)  Time: 1.115s,  564.86/s  (1.122s,  561.44/s)  LR: 1.000e-04  Data: 0.001 (0.007)\n",
      "INFO:root:Train: 2 [ 900/6100 ( 15%)]  Loss:  5.156082 (5.2461)  Loss_kd:  0.347939 (0.3518)  Loss_ce:  1.676696 (1.7278)  Time: 1.111s,  567.13/s  (1.122s,  561.73/s)  LR: 1.000e-04  Data: 0.001 (0.006)\n",
      "INFO:root:Train: 2 [ 950/6100 ( 16%)]  Loss:  5.371079 (5.2454)  Loss_kd:  0.364298 (0.3518)  Loss_ce:  1.728100 (1.7277)  Time: 1.110s,  567.53/s  (1.121s,  561.95/s)  LR: 1.000e-04  Data: 0.001 (0.006)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train: 2 [1000/6100 ( 16%)]  Loss:  5.187089 (5.2464)  Loss_kd:  0.354365 (0.3519)  Loss_ce:  1.643439 (1.7278)  Time: 1.112s,  566.67/s  (1.121s,  562.16/s)  LR: 1.000e-04  Data: 0.001 (0.006)\n",
      "INFO:root:Train: 2 [1050/6100 ( 17%)]  Loss:  4.944619 (5.2441)  Loss_kd:  0.331376 (0.3517)  Loss_ce:  1.630859 (1.7270)  Time: 1.114s,  565.78/s  (1.120s,  562.34/s)  LR: 1.000e-04  Data: 0.001 (0.006)\n",
      "INFO:root:Train: 2 [1100/6100 ( 18%)]  Loss:  5.311405 (5.2441)  Loss_kd:  0.357476 (0.3517)  Loss_ce:  1.736647 (1.7272)  Time: 1.115s,  565.09/s  (1.120s,  562.49/s)  LR: 1.000e-04  Data: 0.001 (0.005)\n",
      "INFO:root:Train: 2 [1150/6100 ( 19%)]  Loss:  5.279851 (5.2440)  Loss_kd:  0.357943 (0.3517)  Loss_ce:  1.700418 (1.7271)  Time: 1.113s,  566.11/s  (1.120s,  562.63/s)  LR: 1.000e-04  Data: 0.001 (0.005)\n",
      "INFO:root:Train: 2 [1200/6100 ( 20%)]  Loss:  5.453130 (5.2438)  Loss_kd:  0.366625 (0.3517)  Loss_ce:  1.786884 (1.7270)  Time: 1.113s,  566.00/s  (1.119s,  562.76/s)  LR: 1.000e-04  Data: 0.001 (0.005)\n",
      "INFO:root:Train: 2 [1250/6100 ( 20%)]  Loss:  5.259165 (5.2440)  Loss_kd:  0.359025 (0.3518)  Loss_ce:  1.668918 (1.7262)  Time: 1.108s,  568.43/s  (1.119s,  562.89/s)  LR: 1.000e-04  Data: 0.001 (0.005)\n",
      "INFO:root:Train: 2 [1300/6100 ( 21%)]  Loss:  5.336457 (5.2446)  Loss_kd:  0.362233 (0.3518)  Loss_ce:  1.714132 (1.7265)  Time: 1.117s,  564.10/s  (1.119s,  563.00/s)  LR: 1.000e-04  Data: 0.003 (0.005)\n",
      "INFO:root:Train: 2 [1350/6100 ( 22%)]  Loss:  5.137709 (5.2448)  Loss_kd:  0.355954 (0.3518)  Loss_ce:  1.578169 (1.7266)  Time: 1.110s,  567.47/s  (1.119s,  563.10/s)  LR: 1.000e-04  Data: 0.001 (0.005)\n",
      "INFO:root:Train: 2 [1400/6100 ( 23%)]  Loss:  5.219807 (5.2453)  Loss_kd:  0.351973 (0.3519)  Loss_ce:  1.700077 (1.7268)  Time: 1.112s,  566.44/s  (1.119s,  563.19/s)  LR: 1.000e-04  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 2 [1450/6100 ( 24%)]  Loss:  5.169386 (5.2451)  Loss_kd:  0.352120 (0.3519)  Loss_ce:  1.648191 (1.7264)  Time: 1.113s,  566.10/s  (1.118s,  563.29/s)  LR: 1.000e-04  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 2 [1500/6100 ( 25%)]  Loss:  5.014362 (5.2450)  Loss_kd:  0.338875 (0.3519)  Loss_ce:  1.625610 (1.7260)  Time: 1.114s,  565.63/s  (1.118s,  563.38/s)  LR: 1.000e-04  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 2 [1550/6100 ( 25%)]  Loss:  5.405092 (5.2444)  Loss_kd:  0.360345 (0.3519)  Loss_ce:  1.801645 (1.7256)  Time: 1.112s,  566.80/s  (1.118s,  563.47/s)  LR: 1.000e-04  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 2 [1600/6100 ( 26%)]  Loss:  5.279886 (5.2450)  Loss_kd:  0.349395 (0.3519)  Loss_ce:  1.785935 (1.7256)  Time: 1.112s,  566.74/s  (1.118s,  563.56/s)  LR: 1.000e-04  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 2 [1650/6100 ( 27%)]  Loss:  5.217323 (5.2452)  Loss_kd:  0.351655 (0.3519)  Loss_ce:  1.700771 (1.7258)  Time: 1.113s,  565.95/s  (1.118s,  563.64/s)  LR: 1.000e-04  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 2 [1700/6100 ( 28%)]  Loss:  5.469609 (5.2458)  Loss_kd:  0.363020 (0.3520)  Loss_ce:  1.839407 (1.7260)  Time: 1.113s,  565.97/s  (1.118s,  563.72/s)  LR: 1.000e-04  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 2 [1750/6100 ( 29%)]  Loss:  5.420178 (5.2467)  Loss_kd:  0.356998 (0.3520)  Loss_ce:  1.850199 (1.7265)  Time: 1.113s,  565.96/s  (1.117s,  563.79/s)  LR: 1.000e-04  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 2 [1800/6100 ( 30%)]  Loss:  5.425261 (5.2468)  Loss_kd:  0.366079 (0.3520)  Loss_ce:  1.764472 (1.7266)  Time: 1.111s,  567.19/s  (1.117s,  563.85/s)  LR: 1.000e-04  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 2 [1850/6100 ( 30%)]  Loss:  5.187939 (5.2465)  Loss_kd:  0.353356 (0.3520)  Loss_ce:  1.654375 (1.7265)  Time: 1.112s,  566.46/s  (1.117s,  563.90/s)  LR: 1.000e-04  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 2 [1900/6100 ( 31%)]  Loss:  4.975543 (5.2464)  Loss_kd:  0.333079 (0.3520)  Loss_ce:  1.644750 (1.7265)  Time: 1.112s,  566.35/s  (1.117s,  563.96/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 2 [1950/6100 ( 32%)]  Loss:  5.676105 (5.2474)  Loss_kd:  0.379131 (0.3520)  Loss_ce:  1.884794 (1.7269)  Time: 1.111s,  566.86/s  (1.117s,  564.02/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 2 [2000/6100 ( 33%)]  Loss:  5.292111 (5.2479)  Loss_kd:  0.358107 (0.3521)  Loss_ce:  1.711043 (1.7270)  Time: 1.113s,  566.14/s  (1.117s,  564.07/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 2 [2050/6100 ( 34%)]  Loss:  5.498672 (5.2471)  Loss_kd:  0.368535 (0.3520)  Loss_ce:  1.813319 (1.7267)  Time: 1.109s,  567.91/s  (1.117s,  564.11/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 2 [2100/6100 ( 34%)]  Loss:  5.482249 (5.2472)  Loss_kd:  0.360083 (0.3521)  Loss_ce:  1.881423 (1.7265)  Time: 1.114s,  565.75/s  (1.117s,  564.14/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 2 [2150/6100 ( 35%)]  Loss:  5.198812 (5.2471)  Loss_kd:  0.349935 (0.3521)  Loss_ce:  1.699463 (1.7264)  Time: 1.112s,  566.54/s  (1.117s,  564.19/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 2 [2200/6100 ( 36%)]  Loss:  5.316877 (5.2473)  Loss_kd:  0.349390 (0.3521)  Loss_ce:  1.822975 (1.7267)  Time: 1.113s,  565.98/s  (1.117s,  564.23/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 2 [2250/6100 ( 37%)]  Loss:  5.107055 (5.2474)  Loss_kd:  0.343234 (0.3521)  Loss_ce:  1.674710 (1.7268)  Time: 1.110s,  567.43/s  (1.116s,  564.28/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 2 [2300/6100 ( 38%)]  Loss:  5.035234 (5.2470)  Loss_kd:  0.338104 (0.3521)  Loss_ce:  1.654198 (1.7263)  Time: 1.113s,  566.00/s  (1.116s,  564.33/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 2 [2350/6100 ( 39%)]  Loss:  5.307225 (5.2473)  Loss_kd:  0.362791 (0.3521)  Loss_ce:  1.679316 (1.7262)  Time: 1.114s,  565.54/s  (1.116s,  564.37/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 2 [2400/6100 ( 39%)]  Loss:  5.369865 (5.2477)  Loss_kd:  0.362345 (0.3521)  Loss_ce:  1.746416 (1.7264)  Time: 1.112s,  566.73/s  (1.116s,  564.40/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 2 [2450/6100 ( 40%)]  Loss:  4.957002 (5.2482)  Loss_kd:  0.330158 (0.3521)  Loss_ce:  1.655421 (1.7269)  Time: 1.108s,  568.77/s  (1.116s,  564.44/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 2 [2500/6100 ( 41%)]  Loss:  5.177457 (5.2477)  Loss_kd:  0.355100 (0.3521)  Loss_ce:  1.626454 (1.7267)  Time: 1.115s,  564.80/s  (1.116s,  564.47/s)  LR: 1.000e-04  Data: 0.004 (0.003)\n",
      "INFO:root:Train: 2 [2550/6100 ( 42%)]  Loss:  5.162172 (5.2479)  Loss_kd:  0.346890 (0.3521)  Loss_ce:  1.693268 (1.7268)  Time: 1.110s,  567.76/s  (1.116s,  564.50/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 2 [2600/6100 ( 43%)]  Loss:  5.367464 (5.2476)  Loss_kd:  0.353960 (0.3521)  Loss_ce:  1.827861 (1.7266)  Time: 1.113s,  566.12/s  (1.116s,  564.53/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 2 [2650/6100 ( 43%)]  Loss:  5.177254 (5.2475)  Loss_kd:  0.343093 (0.3521)  Loss_ce:  1.746319 (1.7264)  Time: 1.112s,  566.40/s  (1.116s,  564.56/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 2 [2700/6100 ( 44%)]  Loss:  5.050713 (5.2479)  Loss_kd:  0.340655 (0.3521)  Loss_ce:  1.644162 (1.7271)  Time: 1.113s,  565.82/s  (1.116s,  564.57/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 2 [2750/6100 ( 45%)]  Loss:  5.417695 (5.2479)  Loss_kd:  0.360673 (0.3521)  Loss_ce:  1.810969 (1.7273)  Time: 1.111s,  566.93/s  (1.116s,  564.58/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 2 [2800/6100 ( 46%)]  Loss:  5.119884 (5.2473)  Loss_kd:  0.348734 (0.3520)  Loss_ce:  1.632543 (1.7269)  Time: 1.109s,  568.22/s  (1.116s,  564.60/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 2 [2850/6100 ( 47%)]  Loss:  5.205670 (5.2471)  Loss_kd:  0.348954 (0.3520)  Loss_ce:  1.716131 (1.7266)  Time: 1.113s,  566.21/s  (1.116s,  564.63/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "/home/cutz/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "INFO:root:Train: 2 [2900/6100 ( 48%)]  Loss:  5.474965 (5.2473)  Loss_kd:  0.366381 (0.3521)  Loss_ce:  1.811153 (1.7266)  Time: 1.113s,  566.12/s  (1.116s,  564.66/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 2 [2950/6100 ( 48%)]  Loss:  5.385737 (5.2475)  Loss_kd:  0.358946 (0.3521)  Loss_ce:  1.796274 (1.7268)  Time: 1.114s,  565.75/s  (1.116s,  564.67/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train: 2 [3000/6100 ( 49%)]  Loss:  5.289898 (5.2479)  Loss_kd:  0.351095 (0.3521)  Loss_ce:  1.778950 (1.7271)  Time: 1.113s,  566.03/s  (1.116s,  564.69/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 2 [3050/6100 ( 50%)]  Loss:  5.108087 (5.2479)  Loss_kd:  0.345850 (0.3521)  Loss_ce:  1.649588 (1.7271)  Time: 1.112s,  566.79/s  (1.116s,  564.71/s)  LR: 1.000e-04  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 2 [3100/6100 ( 51%)]  Loss:  5.390748 (5.2479)  Loss_kd:  0.353114 (0.3521)  Loss_ce:  1.859609 (1.7271)  Time: 1.114s,  565.69/s  (1.116s,  564.73/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [3150/6100 ( 52%)]  Loss:  5.167998 (5.2479)  Loss_kd:  0.349502 (0.3521)  Loss_ce:  1.672977 (1.7272)  Time: 1.112s,  566.38/s  (1.116s,  564.75/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [3200/6100 ( 52%)]  Loss:  5.396461 (5.2484)  Loss_kd:  0.357724 (0.3521)  Loss_ce:  1.819219 (1.7274)  Time: 1.109s,  568.02/s  (1.115s,  564.77/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [3250/6100 ( 53%)]  Loss:  5.528651 (5.2482)  Loss_kd:  0.360713 (0.3521)  Loss_ce:  1.921519 (1.7274)  Time: 1.108s,  568.53/s  (1.115s,  564.79/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [3300/6100 ( 54%)]  Loss:  5.517433 (5.2482)  Loss_kd:  0.364687 (0.3521)  Loss_ce:  1.870564 (1.7275)  Time: 1.111s,  567.12/s  (1.115s,  564.81/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [3350/6100 ( 55%)]  Loss:  5.187708 (5.2486)  Loss_kd:  0.342136 (0.3521)  Loss_ce:  1.766347 (1.7276)  Time: 1.113s,  566.08/s  (1.115s,  564.82/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [3400/6100 ( 56%)]  Loss:  5.083353 (5.2489)  Loss_kd:  0.346633 (0.3521)  Loss_ce:  1.617020 (1.7277)  Time: 1.114s,  565.49/s  (1.115s,  564.84/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [3450/6100 ( 57%)]  Loss:  5.117488 (5.2486)  Loss_kd:  0.338633 (0.3521)  Loss_ce:  1.731157 (1.7275)  Time: 1.113s,  565.85/s  (1.115s,  564.86/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [3500/6100 ( 57%)]  Loss:  5.446110 (5.2483)  Loss_kd:  0.358252 (0.3521)  Loss_ce:  1.863586 (1.7272)  Time: 1.113s,  566.27/s  (1.115s,  564.87/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [3550/6100 ( 58%)]  Loss:  5.383282 (5.2484)  Loss_kd:  0.360149 (0.3521)  Loss_ce:  1.781795 (1.7273)  Time: 1.116s,  564.34/s  (1.115s,  564.88/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [3600/6100 ( 59%)]  Loss:  5.224235 (5.2487)  Loss_kd:  0.358212 (0.3521)  Loss_ce:  1.642119 (1.7275)  Time: 1.116s,  564.74/s  (1.115s,  564.88/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [3650/6100 ( 60%)]  Loss:  5.175047 (5.2485)  Loss_kd:  0.350147 (0.3521)  Loss_ce:  1.673580 (1.7272)  Time: 1.113s,  565.78/s  (1.115s,  564.90/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [3700/6100 ( 61%)]  Loss:  5.051930 (5.2484)  Loss_kd:  0.348122 (0.3521)  Loss_ce:  1.570708 (1.7271)  Time: 1.112s,  566.56/s  (1.115s,  564.92/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [3750/6100 ( 61%)]  Loss:  5.406631 (5.2485)  Loss_kd:  0.365082 (0.3521)  Loss_ce:  1.755815 (1.7272)  Time: 1.113s,  566.10/s  (1.115s,  564.93/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [3800/6100 ( 62%)]  Loss:  5.428739 (5.2486)  Loss_kd:  0.368429 (0.3521)  Loss_ce:  1.744452 (1.7273)  Time: 1.114s,  565.73/s  (1.115s,  564.94/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [3850/6100 ( 63%)]  Loss:  5.185730 (5.2487)  Loss_kd:  0.349380 (0.3521)  Loss_ce:  1.691928 (1.7273)  Time: 1.112s,  566.70/s  (1.115s,  564.95/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [3900/6100 ( 64%)]  Loss:  5.129441 (5.2487)  Loss_kd:  0.343199 (0.3521)  Loss_ce:  1.697446 (1.7274)  Time: 1.113s,  566.09/s  (1.115s,  564.97/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [3950/6100 ( 65%)]  Loss:  5.309172 (5.2484)  Loss_kd:  0.358896 (0.3521)  Loss_ce:  1.720208 (1.7271)  Time: 1.113s,  565.82/s  (1.115s,  564.98/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [4000/6100 ( 66%)]  Loss:  5.291231 (5.2482)  Loss_kd:  0.362751 (0.3521)  Loss_ce:  1.663723 (1.7270)  Time: 1.109s,  567.87/s  (1.115s,  564.98/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [4050/6100 ( 66%)]  Loss:  5.280021 (5.2483)  Loss_kd:  0.363861 (0.3521)  Loss_ce:  1.641412 (1.7271)  Time: 1.112s,  566.60/s  (1.115s,  564.99/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [4100/6100 ( 67%)]  Loss:  5.329387 (5.2484)  Loss_kd:  0.353343 (0.3521)  Loss_ce:  1.795959 (1.7270)  Time: 1.113s,  566.27/s  (1.115s,  565.01/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [4150/6100 ( 68%)]  Loss:  5.471670 (5.2483)  Loss_kd:  0.366190 (0.3521)  Loss_ce:  1.809769 (1.7270)  Time: 1.115s,  565.06/s  (1.115s,  565.02/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [4200/6100 ( 69%)]  Loss:  5.131004 (5.2480)  Loss_kd:  0.342579 (0.3521)  Loss_ce:  1.705213 (1.7270)  Time: 1.113s,  566.06/s  (1.115s,  565.02/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [4250/6100 ( 70%)]  Loss:  5.220743 (5.2482)  Loss_kd:  0.341594 (0.3521)  Loss_ce:  1.804800 (1.7271)  Time: 1.111s,  566.97/s  (1.115s,  565.04/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [4300/6100 ( 71%)]  Loss:  5.181174 (5.2482)  Loss_kd:  0.344595 (0.3521)  Loss_ce:  1.735227 (1.7271)  Time: 1.110s,  567.69/s  (1.115s,  565.05/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [4350/6100 ( 71%)]  Loss:  5.114119 (5.2481)  Loss_kd:  0.343309 (0.3521)  Loss_ce:  1.681030 (1.7271)  Time: 1.113s,  566.23/s  (1.115s,  565.06/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [4400/6100 ( 72%)]  Loss:  5.190000 (5.2482)  Loss_kd:  0.339171 (0.3521)  Loss_ce:  1.798293 (1.7271)  Time: 1.113s,  565.96/s  (1.115s,  565.06/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [4450/6100 ( 73%)]  Loss:  5.339330 (5.2485)  Loss_kd:  0.359761 (0.3521)  Loss_ce:  1.741723 (1.7272)  Time: 1.113s,  566.16/s  (1.115s,  565.07/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'IHDR' 16 13\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'sRGB' 41 1\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'gAMA' 54 4\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'cHRM' 70 32\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'pHYs' 114 9\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'IDAT' 135 65401\n",
      "INFO:root:Train: 2 [4500/6100 ( 74%)]  Loss:  5.078282 (5.2479)  Loss_kd:  0.345763 (0.3521)  Loss_ce:  1.620654 (1.7270)  Time: 1.113s,  566.26/s  (1.115s,  565.07/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [4550/6100 ( 75%)]  Loss:  5.290989 (5.2478)  Loss_kd:  0.357284 (0.3521)  Loss_ce:  1.718154 (1.7270)  Time: 1.114s,  565.44/s  (1.115s,  565.08/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [4600/6100 ( 75%)]  Loss:  5.053120 (5.2476)  Loss_kd:  0.346443 (0.3521)  Loss_ce:  1.588693 (1.7269)  Time: 1.113s,  566.08/s  (1.115s,  565.09/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [4650/6100 ( 76%)]  Loss:  5.210716 (5.2481)  Loss_kd:  0.350783 (0.3521)  Loss_ce:  1.702881 (1.7269)  Time: 1.113s,  566.18/s  (1.115s,  565.10/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [4700/6100 ( 77%)]  Loss:  5.295386 (5.2483)  Loss_kd:  0.355127 (0.3521)  Loss_ce:  1.744116 (1.7270)  Time: 1.113s,  566.17/s  (1.115s,  565.10/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [4750/6100 ( 78%)]  Loss:  5.088758 (5.2484)  Loss_kd:  0.345757 (0.3521)  Loss_ce:  1.631192 (1.7271)  Time: 1.112s,  566.44/s  (1.115s,  565.11/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [4800/6100 ( 79%)]  Loss:  5.254980 (5.2485)  Loss_kd:  0.344547 (0.3521)  Loss_ce:  1.809509 (1.7271)  Time: 1.112s,  566.58/s  (1.115s,  565.12/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [4850/6100 ( 80%)]  Loss:  5.299679 (5.2482)  Loss_kd:  0.352609 (0.3521)  Loss_ce:  1.773591 (1.7270)  Time: 1.122s,  561.56/s  (1.115s,  565.12/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [4900/6100 ( 80%)]  Loss:  5.428323 (5.2482)  Loss_kd:  0.364916 (0.3521)  Loss_ce:  1.779166 (1.7270)  Time: 1.116s,  564.70/s  (1.115s,  565.12/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train: 2 [4950/6100 ( 81%)]  Loss:  5.296818 (5.2484)  Loss_kd:  0.350971 (0.3521)  Loss_ce:  1.787105 (1.7270)  Time: 1.113s,  566.10/s  (1.115s,  565.13/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [5000/6100 ( 82%)]  Loss:  5.087842 (5.2487)  Loss_kd:  0.349373 (0.3522)  Loss_ce:  1.594108 (1.7271)  Time: 1.116s,  564.41/s  (1.115s,  565.13/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [5050/6100 ( 83%)]  Loss:  5.130976 (5.2485)  Loss_kd:  0.345501 (0.3522)  Loss_ce:  1.675970 (1.7270)  Time: 1.113s,  565.97/s  (1.115s,  565.13/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [5100/6100 ( 84%)]  Loss:  5.290452 (5.2492)  Loss_kd:  0.362970 (0.3522)  Loss_ce:  1.660750 (1.7273)  Time: 1.113s,  566.19/s  (1.115s,  565.14/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [5150/6100 ( 84%)]  Loss:  5.178459 (5.2493)  Loss_kd:  0.346632 (0.3522)  Loss_ce:  1.712135 (1.7272)  Time: 1.114s,  565.62/s  (1.115s,  565.14/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [5200/6100 ( 85%)]  Loss:  5.057925 (5.2493)  Loss_kd:  0.338804 (0.3522)  Loss_ce:  1.669887 (1.7271)  Time: 1.116s,  564.41/s  (1.115s,  565.15/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [5250/6100 ( 86%)]  Loss:  5.092056 (5.2494)  Loss_kd:  0.343266 (0.3522)  Loss_ce:  1.659396 (1.7272)  Time: 1.114s,  565.48/s  (1.115s,  565.15/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [5300/6100 ( 87%)]  Loss:  5.019908 (5.2495)  Loss_kd:  0.340641 (0.3522)  Loss_ce:  1.613496 (1.7272)  Time: 1.112s,  566.79/s  (1.115s,  565.16/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [5350/6100 ( 88%)]  Loss:  5.242185 (5.2495)  Loss_kd:  0.345790 (0.3522)  Loss_ce:  1.784284 (1.7271)  Time: 1.112s,  566.38/s  (1.115s,  565.16/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [5400/6100 ( 89%)]  Loss:  5.271529 (5.2494)  Loss_kd:  0.355846 (0.3522)  Loss_ce:  1.713071 (1.7271)  Time: 1.126s,  559.56/s  (1.115s,  565.16/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [5450/6100 ( 89%)]  Loss:  5.179222 (5.2496)  Loss_kd:  0.354668 (0.3522)  Loss_ce:  1.632545 (1.7273)  Time: 1.114s,  565.54/s  (1.115s,  565.17/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [5500/6100 ( 90%)]  Loss:  5.370339 (5.2500)  Loss_kd:  0.357574 (0.3522)  Loss_ce:  1.794595 (1.7275)  Time: 1.110s,  567.37/s  (1.115s,  565.17/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [5550/6100 ( 91%)]  Loss:  5.322728 (5.2498)  Loss_kd:  0.364083 (0.3522)  Loss_ce:  1.681893 (1.7275)  Time: 1.113s,  566.18/s  (1.115s,  565.17/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [5600/6100 ( 92%)]  Loss:  5.382360 (5.2499)  Loss_kd:  0.366396 (0.3522)  Loss_ce:  1.718403 (1.7277)  Time: 1.114s,  565.53/s  (1.115s,  565.17/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [5650/6100 ( 93%)]  Loss:  5.015539 (5.2496)  Loss_kd:  0.343791 (0.3522)  Loss_ce:  1.577625 (1.7275)  Time: 1.112s,  566.30/s  (1.115s,  565.17/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [5700/6100 ( 93%)]  Loss:  5.450332 (5.2498)  Loss_kd:  0.368747 (0.3522)  Loss_ce:  1.762865 (1.7277)  Time: 1.113s,  565.82/s  (1.115s,  565.18/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [5750/6100 ( 94%)]  Loss:  5.162078 (5.2500)  Loss_kd:  0.346124 (0.3522)  Loss_ce:  1.700836 (1.7278)  Time: 1.113s,  566.08/s  (1.115s,  565.18/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [5800/6100 ( 95%)]  Loss:  5.268974 (5.2498)  Loss_kd:  0.347211 (0.3522)  Loss_ce:  1.796860 (1.7278)  Time: 1.114s,  565.38/s  (1.115s,  565.19/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [5850/6100 ( 96%)]  Loss:  5.154264 (5.2496)  Loss_kd:  0.344829 (0.3522)  Loss_ce:  1.705971 (1.7276)  Time: 1.113s,  566.17/s  (1.115s,  565.19/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [5900/6100 ( 97%)]  Loss:  5.214845 (5.2499)  Loss_kd:  0.349265 (0.3522)  Loss_ce:  1.722197 (1.7276)  Time: 1.113s,  565.87/s  (1.115s,  565.19/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [5950/6100 ( 98%)]  Loss:  5.024486 (5.2500)  Loss_kd:  0.339046 (0.3522)  Loss_ce:  1.634022 (1.7276)  Time: 1.114s,  565.47/s  (1.115s,  565.20/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [6000/6100 ( 98%)]  Loss:  5.259339 (5.2501)  Loss_kd:  0.355623 (0.3522)  Loss_ce:  1.703111 (1.7277)  Time: 1.112s,  566.65/s  (1.115s,  565.20/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [6050/6100 ( 99%)]  Loss:  5.290253 (5.2502)  Loss_kd:  0.357048 (0.3522)  Loss_ce:  1.719772 (1.7277)  Time: 1.109s,  567.84/s  (1.115s,  565.20/s)  LR: 1.000e-04  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 2 [6099/6100 (100%)]  Loss:  5.281173 (5.2503)  Loss_kd:  0.351764 (0.3523)  Loss_ce:  1.763531 (1.7277)  Time: 1.452s,  434.02/s  (1.115s,  565.18/s)  LR: 1.000e-04  Data: 0.344 (0.002)\n",
      "INFO:root:Test: [   0/239]  Time: 5.175s (5.175s,   40.58/s)  Loss:  0.5108 (0.5108)  Acc@1:  88.095 ( 88.095)  Acc@5:  97.619 ( 97.619)\n",
      "INFO:root:Test: [  10/239]  Time: 0.331s (0.775s,  270.99/s)  Loss:  0.9671 (0.6212)  Acc@1:  77.619 ( 85.455)  Acc@5:  93.810 ( 97.143)\n",
      "INFO:root:Test: [  20/239]  Time: 0.349s (0.564s,  372.22/s)  Loss:  0.4680 (0.7232)  Acc@1:  90.952 ( 82.744)  Acc@5:  98.095 ( 96.372)\n",
      "INFO:root:Test: [  30/239]  Time: 0.324s (0.488s,  430.25/s)  Loss:  0.5364 (0.6754)  Acc@1:  88.571 ( 84.286)  Acc@5:  95.714 ( 96.406)\n",
      "INFO:root:Test: [  40/239]  Time: 0.327s (0.449s,  467.34/s)  Loss:  0.7853 (0.6639)  Acc@1:  82.857 ( 84.599)  Acc@5:  94.286 ( 96.446)\n",
      "INFO:root:Test: [  50/239]  Time: 0.324s (0.426s,  493.31/s)  Loss:  0.6604 (0.6796)  Acc@1:  83.810 ( 84.118)  Acc@5:  96.190 ( 96.517)\n",
      "INFO:root:Test: [  60/239]  Time: 0.325s (0.410s,  512.72/s)  Loss:  0.3534 (0.6828)  Acc@1:  93.333 ( 83.833)  Acc@5:  99.048 ( 96.628)\n",
      "INFO:root:Test: [  70/239]  Time: 0.327s (0.398s,  527.02/s)  Loss:  0.6531 (0.6874)  Acc@1:  87.143 ( 83.776)  Acc@5:  95.238 ( 96.667)\n",
      "INFO:root:Test: [  80/239]  Time: 0.328s (0.390s,  538.34/s)  Loss:  0.4876 (0.6713)  Acc@1:  91.429 ( 84.286)  Acc@5:  97.143 ( 96.767)\n",
      "INFO:root:Test: [  90/239]  Time: 0.343s (0.384s,  546.50/s)  Loss:  1.0534 (0.6757)  Acc@1:  72.857 ( 84.129)  Acc@5:  93.810 ( 96.766)\n",
      "INFO:root:Test: [ 100/239]  Time: 0.327s (0.379s,  554.51/s)  Loss:  0.9182 (0.6972)  Acc@1:  78.571 ( 83.607)  Acc@5:  93.810 ( 96.511)\n",
      "INFO:root:Test: [ 110/239]  Time: 0.327s (0.374s,  560.84/s)  Loss:  1.7389 (0.7323)  Acc@1:  60.000 ( 82.754)  Acc@5:  82.381 ( 96.096)\n",
      "INFO:root:Test: [ 120/239]  Time: 0.331s (0.371s,  566.66/s)  Loss:  1.3899 (0.7716)  Acc@1:  64.286 ( 81.767)  Acc@5:  90.000 ( 95.675)\n",
      "INFO:root:Test: [ 130/239]  Time: 0.327s (0.368s,  571.36/s)  Loss:  0.8644 (0.7902)  Acc@1:  79.048 ( 81.294)  Acc@5:  96.190 ( 95.493)\n",
      "INFO:root:Test: [ 140/239]  Time: 0.330s (0.365s,  575.44/s)  Loss:  1.2174 (0.7973)  Acc@1:  75.238 ( 81.243)  Acc@5:  90.476 ( 95.393)\n",
      "INFO:root:Test: [ 150/239]  Time: 0.325s (0.363s,  579.18/s)  Loss:  1.6411 (0.8173)  Acc@1:  67.619 ( 80.892)  Acc@5:  84.286 ( 95.093)\n",
      "INFO:root:Test: [ 160/239]  Time: 0.327s (0.360s,  582.68/s)  Loss:  1.1461 (0.8318)  Acc@1:  70.476 ( 80.458)  Acc@5:  91.429 ( 94.966)\n",
      "INFO:root:Test: [ 170/239]  Time: 0.329s (0.359s,  585.60/s)  Loss:  0.9507 (0.8442)  Acc@1:  78.095 ( 80.228)  Acc@5:  93.810 ( 94.868)\n",
      "INFO:root:Test: [ 180/239]  Time: 0.326s (0.357s,  588.30/s)  Loss:  0.8983 (0.8552)  Acc@1:  82.381 ( 79.997)  Acc@5:  93.333 ( 94.725)\n",
      "INFO:root:Test: [ 190/239]  Time: 0.327s (0.355s,  590.82/s)  Loss:  1.0284 (0.8652)  Acc@1:  78.571 ( 79.788)  Acc@5:  90.952 ( 94.557)\n",
      "INFO:root:Test: [ 200/239]  Time: 0.333s (0.354s,  593.15/s)  Loss:  1.1510 (0.8817)  Acc@1:  74.286 ( 79.365)  Acc@5:  92.381 ( 94.376)\n",
      "INFO:root:Test: [ 210/239]  Time: 0.325s (0.353s,  595.31/s)  Loss:  1.7359 (0.8907)  Acc@1:  59.524 ( 79.127)  Acc@5:  82.857 ( 94.272)\n",
      "INFO:root:Test: [ 220/239]  Time: 0.326s (0.352s,  597.40/s)  Loss:  0.6871 (0.8981)  Acc@1:  81.429 ( 78.951)  Acc@5:  97.619 ( 94.238)\n",
      "INFO:root:Test: [ 230/239]  Time: 0.324s (0.350s,  599.42/s)  Loss:  1.8845 (0.8983)  Acc@1:  55.238 ( 78.905)  Acc@5:  85.238 ( 94.249)\n",
      "INFO:root: * Acc@1 78.916 (21.084) Acc@5 94.298 (5.702)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Current checkpoints:\n",
      " ('./output/train/20200625-133839-tf_efficientnet_b1-240/checkpoint-1.pth.tar', 78.926)\n",
      " ('./output/train/20200625-133839-tf_efficientnet_b1-240/checkpoint-2.pth.tar', 78.916)\n",
      "\n",
      "INFO:root:Train: 3 [   0/6100 (  0%)]  Loss:  5.239568 (5.2396)  Loss_kd:  0.351320 (0.3513)  Loss_ce:  1.726368 (1.7264)  Time: 6.045s,  104.21/s  (6.045s,  104.21/s)  LR: 1.000e-05  Data: 4.913 (4.913)\n",
      "INFO:root:Train: 3 [  50/6100 (  1%)]  Loss:  5.193676 (5.2402)  Loss_kd:  0.347939 (0.3530)  Loss_ce:  1.714291 (1.7101)  Time: 1.112s,  566.40/s  (1.209s,  520.99/s)  LR: 1.000e-05  Data: 0.001 (0.097)\n",
      "INFO:root:Train: 3 [ 100/6100 (  2%)]  Loss:  5.349276 (5.2313)  Loss_kd:  0.358258 (0.3524)  Loss_ce:  1.766695 (1.7077)  Time: 1.113s,  566.21/s  (1.161s,  542.54/s)  LR: 1.000e-05  Data: 0.001 (0.049)\n",
      "INFO:root:Train: 3 [ 150/6100 (  2%)]  Loss:  5.341178 (5.2278)  Loss_kd:  0.355093 (0.3523)  Loss_ce:  1.790247 (1.7051)  Time: 1.114s,  565.38/s  (1.145s,  550.26/s)  LR: 1.000e-05  Data: 0.001 (0.033)\n",
      "INFO:root:Train: 3 [ 200/6100 (  3%)]  Loss:  5.331103 (5.2434)  Loss_kd:  0.353084 (0.3530)  Loss_ce:  1.800265 (1.7136)  Time: 1.112s,  566.69/s  (1.137s,  554.12/s)  LR: 1.000e-05  Data: 0.001 (0.025)\n",
      "INFO:root:Train: 3 [ 250/6100 (  4%)]  Loss:  5.271539 (5.2438)  Loss_kd:  0.343277 (0.3526)  Loss_ce:  1.838765 (1.7175)  Time: 1.116s,  564.36/s  (1.132s,  556.47/s)  LR: 1.000e-05  Data: 0.005 (0.021)\n",
      "INFO:root:Train: 3 [ 300/6100 (  5%)]  Loss:  5.319585 (5.2444)  Loss_kd:  0.358890 (0.3525)  Loss_ce:  1.730680 (1.7191)  Time: 1.118s,  563.44/s  (1.129s,  557.99/s)  LR: 1.000e-05  Data: 0.001 (0.017)\n",
      "INFO:root:Train: 3 [ 350/6100 (  6%)]  Loss:  5.095048 (5.2415)  Loss_kd:  0.343474 (0.3521)  Loss_ce:  1.660311 (1.7209)  Time: 1.113s,  565.92/s  (1.127s,  559.09/s)  LR: 1.000e-05  Data: 0.001 (0.015)\n",
      "INFO:root:Train: 3 [ 400/6100 (  7%)]  Loss:  5.273703 (5.2403)  Loss_kd:  0.366674 (0.3519)  Loss_ce:  1.606962 (1.7217)  Time: 1.112s,  566.34/s  (1.125s,  559.98/s)  LR: 1.000e-05  Data: 0.001 (0.013)\n",
      "INFO:root:Train: 3 [ 450/6100 (  7%)]  Loss:  5.132191 (5.2421)  Loss_kd:  0.348277 (0.3520)  Loss_ce:  1.649419 (1.7218)  Time: 1.112s,  566.47/s  (1.124s,  560.70/s)  LR: 1.000e-05  Data: 0.001 (0.012)\n",
      "INFO:root:Train: 3 [ 500/6100 (  8%)]  Loss:  5.419869 (5.2412)  Loss_kd:  0.360457 (0.3519)  Loss_ce:  1.815296 (1.7226)  Time: 1.114s,  565.77/s  (1.123s,  561.24/s)  LR: 1.000e-05  Data: 0.001 (0.011)\n",
      "INFO:root:Train: 3 [ 550/6100 (  9%)]  Loss:  5.208443 (5.2407)  Loss_kd:  0.348756 (0.3518)  Loss_ce:  1.720885 (1.7228)  Time: 1.109s,  567.85/s  (1.122s,  561.70/s)  LR: 1.000e-05  Data: 0.001 (0.010)\n",
      "INFO:root:Train: 3 [ 600/6100 ( 10%)]  Loss:  5.405766 (5.2430)  Loss_kd:  0.365984 (0.3520)  Loss_ce:  1.745925 (1.7231)  Time: 1.113s,  565.94/s  (1.121s,  562.07/s)  LR: 1.000e-05  Data: 0.001 (0.009)\n",
      "INFO:root:Train: 3 [ 650/6100 ( 11%)]  Loss:  5.159083 (5.2441)  Loss_kd:  0.345935 (0.3521)  Loss_ce:  1.699733 (1.7232)  Time: 1.112s,  566.48/s  (1.120s,  562.37/s)  LR: 1.000e-05  Data: 0.001 (0.008)\n",
      "INFO:root:Train: 3 [ 700/6100 ( 11%)]  Loss:  5.256209 (5.2450)  Loss_kd:  0.359318 (0.3520)  Loss_ce:  1.663032 (1.7245)  Time: 1.113s,  565.99/s  (1.120s,  562.63/s)  LR: 1.000e-05  Data: 0.001 (0.008)\n",
      "INFO:root:Train: 3 [ 750/6100 ( 12%)]  Loss:  5.206264 (5.2449)  Loss_kd:  0.348661 (0.3520)  Loss_ce:  1.719652 (1.7248)  Time: 1.113s,  566.11/s  (1.119s,  562.89/s)  LR: 1.000e-05  Data: 0.001 (0.007)\n",
      "INFO:root:Train: 3 [ 800/6100 ( 13%)]  Loss:  5.560699 (5.2446)  Loss_kd:  0.377106 (0.3520)  Loss_ce:  1.789638 (1.7248)  Time: 1.114s,  565.73/s  (1.119s,  563.09/s)  LR: 1.000e-05  Data: 0.002 (0.007)\n",
      "INFO:root:Train: 3 [ 850/6100 ( 14%)]  Loss:  5.438832 (5.2430)  Loss_kd:  0.369823 (0.3519)  Loss_ce:  1.740600 (1.7243)  Time: 1.111s,  567.19/s  (1.118s,  563.25/s)  LR: 1.000e-05  Data: 0.001 (0.007)\n",
      "INFO:root:Train: 3 [ 900/6100 ( 15%)]  Loss:  5.217096 (5.2444)  Loss_kd:  0.342539 (0.3519)  Loss_ce:  1.791706 (1.7257)  Time: 1.112s,  566.57/s  (1.118s,  563.39/s)  LR: 1.000e-05  Data: 0.001 (0.006)\n",
      "INFO:root:Train: 3 [ 950/6100 ( 16%)]  Loss:  5.054993 (5.2433)  Loss_kd:  0.337358 (0.3518)  Loss_ce:  1.681418 (1.7251)  Time: 1.112s,  566.33/s  (1.118s,  563.53/s)  LR: 1.000e-05  Data: 0.001 (0.006)\n",
      "INFO:root:Train: 3 [1000/6100 ( 16%)]  Loss:  5.376877 (5.2429)  Loss_kd:  0.360533 (0.3518)  Loss_ce:  1.771544 (1.7244)  Time: 1.109s,  567.96/s  (1.118s,  563.66/s)  LR: 1.000e-05  Data: 0.001 (0.006)\n",
      "INFO:root:Train: 3 [1050/6100 ( 17%)]  Loss:  5.495750 (5.2430)  Loss_kd:  0.358418 (0.3518)  Loss_ce:  1.911571 (1.7249)  Time: 1.113s,  565.96/s  (1.117s,  563.78/s)  LR: 1.000e-05  Data: 0.001 (0.006)\n",
      "INFO:root:Train: 3 [1100/6100 ( 18%)]  Loss:  5.335402 (5.2432)  Loss_kd:  0.365219 (0.3518)  Loss_ce:  1.683217 (1.7248)  Time: 1.112s,  566.65/s  (1.117s,  563.89/s)  LR: 1.000e-05  Data: 0.001 (0.005)\n",
      "INFO:root:Train: 3 [1150/6100 ( 19%)]  Loss:  5.261784 (5.2427)  Loss_kd:  0.365067 (0.3518)  Loss_ce:  1.611118 (1.7244)  Time: 1.113s,  565.84/s  (1.117s,  563.98/s)  LR: 1.000e-05  Data: 0.001 (0.005)\n",
      "INFO:root:Train: 3 [1200/6100 ( 20%)]  Loss:  5.261315 (5.2420)  Loss_kd:  0.357485 (0.3518)  Loss_ce:  1.686467 (1.7240)  Time: 1.112s,  566.50/s  (1.117s,  564.04/s)  LR: 1.000e-05  Data: 0.001 (0.005)\n",
      "INFO:root:Train: 3 [1250/6100 ( 20%)]  Loss:  5.030561 (5.2434)  Loss_kd:  0.334927 (0.3519)  Loss_ce:  1.681295 (1.7246)  Time: 1.112s,  566.40/s  (1.117s,  564.11/s)  LR: 1.000e-05  Data: 0.001 (0.005)\n",
      "INFO:root:Train: 3 [1300/6100 ( 21%)]  Loss:  5.267856 (5.2430)  Loss_kd:  0.348376 (0.3518)  Loss_ce:  1.784100 (1.7245)  Time: 1.115s,  564.93/s  (1.117s,  564.18/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
      "INFO:root:Train: 3 [1350/6100 ( 22%)]  Loss:  5.303390 (5.2431)  Loss_kd:  0.357566 (0.3518)  Loss_ce:  1.727730 (1.7247)  Time: 1.115s,  565.19/s  (1.117s,  564.23/s)  LR: 1.000e-05  Data: 0.002 (0.005)\n",
      "INFO:root:Train: 3 [1400/6100 ( 23%)]  Loss:  5.367609 (5.2437)  Loss_kd:  0.353521 (0.3519)  Loss_ce:  1.832400 (1.7251)  Time: 1.114s,  565.71/s  (1.117s,  564.26/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 3 [1450/6100 ( 24%)]  Loss:  5.420697 (5.2440)  Loss_kd:  0.361033 (0.3519)  Loss_ce:  1.810365 (1.7248)  Time: 1.113s,  566.10/s  (1.116s,  564.32/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 3 [1500/6100 ( 25%)]  Loss:  5.359510 (5.2455)  Loss_kd:  0.362256 (0.3520)  Loss_ce:  1.736953 (1.7252)  Time: 1.115s,  564.90/s  (1.116s,  564.36/s)  LR: 1.000e-05  Data: 0.003 (0.004)\n",
      "INFO:root:Train: 3 [1550/6100 ( 25%)]  Loss:  5.230165 (5.2464)  Loss_kd:  0.354445 (0.3521)  Loss_ce:  1.685717 (1.7256)  Time: 1.112s,  566.41/s  (1.116s,  564.40/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 3 [1600/6100 ( 26%)]  Loss:  5.019489 (5.2470)  Loss_kd:  0.340136 (0.3521)  Loss_ce:  1.618131 (1.7257)  Time: 1.113s,  566.08/s  (1.116s,  564.46/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 3 [1650/6100 ( 27%)]  Loss:  4.955070 (5.2461)  Loss_kd:  0.332085 (0.3521)  Loss_ce:  1.634223 (1.7255)  Time: 1.112s,  566.73/s  (1.116s,  564.53/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 3 [1700/6100 ( 28%)]  Loss:  5.196366 (5.2473)  Loss_kd:  0.355053 (0.3522)  Loss_ce:  1.645837 (1.7255)  Time: 1.115s,  565.07/s  (1.116s,  564.57/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 3 [1750/6100 ( 29%)]  Loss:  5.317302 (5.2479)  Loss_kd:  0.360690 (0.3522)  Loss_ce:  1.710403 (1.7255)  Time: 1.132s,  556.37/s  (1.116s,  564.61/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 3 [1800/6100 ( 30%)]  Loss:  5.452968 (5.2477)  Loss_kd:  0.374783 (0.3522)  Loss_ce:  1.705135 (1.7256)  Time: 1.113s,  565.80/s  (1.116s,  564.65/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 3 [1850/6100 ( 30%)]  Loss:  5.154793 (5.2488)  Loss_kd:  0.354101 (0.3522)  Loss_ce:  1.613784 (1.7263)  Time: 1.113s,  566.20/s  (1.116s,  564.68/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 3 [1900/6100 ( 31%)]  Loss:  5.279060 (5.2496)  Loss_kd:  0.364435 (0.3523)  Loss_ce:  1.634706 (1.7268)  Time: 1.112s,  566.66/s  (1.116s,  564.72/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "/home/cutz/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train: 3 [1950/6100 ( 32%)]  Loss:  5.133302 (5.2493)  Loss_kd:  0.343084 (0.3523)  Loss_ce:  1.702465 (1.7267)  Time: 1.110s,  567.68/s  (1.116s,  564.76/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 3 [2000/6100 ( 33%)]  Loss:  5.112205 (5.2487)  Loss_kd:  0.341074 (0.3522)  Loss_ce:  1.701463 (1.7263)  Time: 1.112s,  566.76/s  (1.115s,  564.80/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 3 [2050/6100 ( 34%)]  Loss:  4.932044 (5.2492)  Loss_kd:  0.334024 (0.3523)  Loss_ce:  1.591801 (1.7264)  Time: 1.113s,  566.05/s  (1.115s,  564.84/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 3 [2100/6100 ( 34%)]  Loss:  5.416288 (5.2490)  Loss_kd:  0.363799 (0.3522)  Loss_ce:  1.778294 (1.7265)  Time: 1.117s,  563.85/s  (1.115s,  564.86/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 3 [2150/6100 ( 35%)]  Loss:  5.447340 (5.2486)  Loss_kd:  0.357973 (0.3523)  Loss_ce:  1.867614 (1.7260)  Time: 1.112s,  566.56/s  (1.115s,  564.86/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 3 [2200/6100 ( 36%)]  Loss:  5.195131 (5.2487)  Loss_kd:  0.348461 (0.3523)  Loss_ce:  1.710517 (1.7261)  Time: 1.109s,  567.97/s  (1.115s,  564.89/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 3 [2250/6100 ( 37%)]  Loss:  5.414799 (5.2486)  Loss_kd:  0.366268 (0.3522)  Loss_ce:  1.752124 (1.7263)  Time: 1.113s,  566.20/s  (1.115s,  564.92/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 3 [2300/6100 ( 38%)]  Loss:  5.293945 (5.2479)  Loss_kd:  0.353568 (0.3522)  Loss_ce:  1.758268 (1.7261)  Time: 1.112s,  566.79/s  (1.115s,  564.95/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 3 [2350/6100 ( 39%)]  Loss:  5.542677 (5.2477)  Loss_kd:  0.368948 (0.3522)  Loss_ce:  1.853198 (1.7260)  Time: 1.113s,  566.17/s  (1.115s,  564.97/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 3 [2400/6100 ( 39%)]  Loss:  4.922840 (5.2476)  Loss_kd:  0.339064 (0.3521)  Loss_ce:  1.532200 (1.7262)  Time: 1.127s,  559.24/s  (1.115s,  564.98/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 3 [2450/6100 ( 40%)]  Loss:  5.407974 (5.2470)  Loss_kd:  0.359420 (0.3521)  Loss_ce:  1.813775 (1.7259)  Time: 1.110s,  567.55/s  (1.115s,  565.00/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 3 [2500/6100 ( 41%)]  Loss:  4.992562 (5.2466)  Loss_kd:  0.337455 (0.3521)  Loss_ce:  1.618017 (1.7259)  Time: 1.113s,  566.22/s  (1.115s,  565.02/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 3 [2550/6100 ( 42%)]  Loss:  5.136704 (5.2463)  Loss_kd:  0.351534 (0.3520)  Loss_ce:  1.621359 (1.7259)  Time: 1.110s,  567.64/s  (1.115s,  565.05/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 3 [2600/6100 ( 43%)]  Loss:  5.205930 (5.2466)  Loss_kd:  0.346168 (0.3521)  Loss_ce:  1.744247 (1.7260)  Time: 1.113s,  565.98/s  (1.115s,  565.06/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 3 [2650/6100 ( 43%)]  Loss:  5.273764 (5.2473)  Loss_kd:  0.358247 (0.3521)  Loss_ce:  1.691289 (1.7265)  Time: 1.115s,  565.19/s  (1.115s,  565.07/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 3 [2700/6100 ( 44%)]  Loss:  5.491544 (5.2476)  Loss_kd:  0.366347 (0.3521)  Loss_ce:  1.828072 (1.7264)  Time: 1.114s,  565.45/s  (1.115s,  565.09/s)  LR: 1.000e-05  Data: 0.002 (0.003)\n",
      "INFO:root:Train: 3 [2750/6100 ( 45%)]  Loss:  5.421789 (5.2477)  Loss_kd:  0.356699 (0.3521)  Loss_ce:  1.854801 (1.7264)  Time: 1.109s,  567.98/s  (1.115s,  565.11/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 3 [2800/6100 ( 46%)]  Loss:  5.246705 (5.2477)  Loss_kd:  0.352503 (0.3521)  Loss_ce:  1.721678 (1.7265)  Time: 1.114s,  565.58/s  (1.115s,  565.13/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 3 [2850/6100 ( 47%)]  Loss:  4.932531 (5.2476)  Loss_kd:  0.329712 (0.3521)  Loss_ce:  1.635408 (1.7266)  Time: 1.134s,  555.55/s  (1.115s,  565.13/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 3 [2900/6100 ( 48%)]  Loss:  5.261350 (5.2471)  Loss_kd:  0.356293 (0.3521)  Loss_ce:  1.698424 (1.7263)  Time: 1.113s,  565.98/s  (1.115s,  565.15/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 3 [2950/6100 ( 48%)]  Loss:  5.140079 (5.2463)  Loss_kd:  0.347821 (0.3520)  Loss_ce:  1.661869 (1.7258)  Time: 1.112s,  566.59/s  (1.115s,  565.17/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 3 [3000/6100 ( 49%)]  Loss:  5.176040 (5.2469)  Loss_kd:  0.348961 (0.3521)  Loss_ce:  1.686428 (1.7263)  Time: 1.111s,  567.30/s  (1.115s,  565.18/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 3 [3050/6100 ( 50%)]  Loss:  5.109896 (5.2466)  Loss_kd:  0.357907 (0.3520)  Loss_ce:  1.530825 (1.7262)  Time: 1.118s,  563.50/s  (1.115s,  565.19/s)  LR: 1.000e-05  Data: 0.005 (0.003)\n",
      "INFO:root:Train: 3 [3100/6100 ( 51%)]  Loss:  5.049832 (5.2466)  Loss_kd:  0.345502 (0.3521)  Loss_ce:  1.594809 (1.7259)  Time: 1.112s,  566.30/s  (1.115s,  565.21/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 3 [3150/6100 ( 52%)]  Loss:  4.950374 (5.2469)  Loss_kd:  0.333364 (0.3521)  Loss_ce:  1.616733 (1.7261)  Time: 1.113s,  566.10/s  (1.115s,  565.22/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 3 [3200/6100 ( 52%)]  Loss:  5.396557 (5.2467)  Loss_kd:  0.366526 (0.3521)  Loss_ce:  1.731298 (1.7261)  Time: 1.113s,  566.21/s  (1.115s,  565.23/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [3250/6100 ( 53%)]  Loss:  5.164344 (5.2470)  Loss_kd:  0.351234 (0.3521)  Loss_ce:  1.652008 (1.7264)  Time: 1.113s,  565.98/s  (1.115s,  565.24/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [3300/6100 ( 54%)]  Loss:  5.406793 (5.2474)  Loss_kd:  0.359958 (0.3521)  Loss_ce:  1.807214 (1.7267)  Time: 1.110s,  567.67/s  (1.115s,  565.26/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [3350/6100 ( 55%)]  Loss:  5.441328 (5.2473)  Loss_kd:  0.360300 (0.3521)  Loss_ce:  1.838331 (1.7267)  Time: 1.112s,  566.31/s  (1.115s,  565.27/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [3400/6100 ( 56%)]  Loss:  5.003400 (5.2469)  Loss_kd:  0.334518 (0.3521)  Loss_ce:  1.658215 (1.7264)  Time: 1.110s,  567.37/s  (1.114s,  565.28/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [3450/6100 ( 57%)]  Loss:  5.385499 (5.2466)  Loss_kd:  0.356575 (0.3520)  Loss_ce:  1.819751 (1.7262)  Time: 1.113s,  565.95/s  (1.114s,  565.29/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [3500/6100 ( 57%)]  Loss:  4.932078 (5.2464)  Loss_kd:  0.337525 (0.3520)  Loss_ce:  1.556831 (1.7261)  Time: 1.113s,  566.14/s  (1.114s,  565.29/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [3550/6100 ( 58%)]  Loss:  5.196496 (5.2467)  Loss_kd:  0.340274 (0.3520)  Loss_ce:  1.793759 (1.7264)  Time: 1.112s,  566.50/s  (1.114s,  565.30/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [3600/6100 ( 59%)]  Loss:  5.255126 (5.2468)  Loss_kd:  0.349175 (0.3520)  Loss_ce:  1.763379 (1.7265)  Time: 1.116s,  564.59/s  (1.114s,  565.31/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [3650/6100 ( 60%)]  Loss:  5.065220 (5.2467)  Loss_kd:  0.331098 (0.3520)  Loss_ce:  1.754239 (1.7265)  Time: 1.113s,  566.12/s  (1.114s,  565.31/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [3700/6100 ( 61%)]  Loss:  5.597573 (5.2465)  Loss_kd:  0.370164 (0.3520)  Loss_ce:  1.895938 (1.7264)  Time: 1.113s,  566.28/s  (1.114s,  565.33/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [3750/6100 ( 61%)]  Loss:  5.518831 (5.2469)  Loss_kd:  0.357422 (0.3520)  Loss_ce:  1.944607 (1.7267)  Time: 1.115s,  565.28/s  (1.114s,  565.34/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [3800/6100 ( 62%)]  Loss:  5.468092 (5.2467)  Loss_kd:  0.358092 (0.3520)  Loss_ce:  1.887174 (1.7267)  Time: 1.115s,  565.22/s  (1.114s,  565.35/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'IHDR' 16 13\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'sRGB' 41 1\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'gAMA' 54 4\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'cHRM' 70 32\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'pHYs' 114 9\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'IDAT' 135 65401\n",
      "INFO:root:Train: 3 [3850/6100 ( 63%)]  Loss:  5.249248 (5.2468)  Loss_kd:  0.352094 (0.3520)  Loss_ce:  1.728309 (1.7266)  Time: 1.114s,  565.75/s  (1.114s,  565.36/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train: 3 [3900/6100 ( 64%)]  Loss:  5.164217 (5.2464)  Loss_kd:  0.343563 (0.3520)  Loss_ce:  1.728586 (1.7265)  Time: 1.113s,  565.82/s  (1.114s,  565.36/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [3950/6100 ( 65%)]  Loss:  5.269735 (5.2469)  Loss_kd:  0.355438 (0.3520)  Loss_ce:  1.715352 (1.7268)  Time: 1.112s,  566.56/s  (1.114s,  565.37/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [4000/6100 ( 66%)]  Loss:  5.324423 (5.2466)  Loss_kd:  0.361752 (0.3520)  Loss_ce:  1.706904 (1.7265)  Time: 1.116s,  564.66/s  (1.114s,  565.38/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [4050/6100 ( 66%)]  Loss:  5.096722 (5.2464)  Loss_kd:  0.343444 (0.3520)  Loss_ce:  1.662284 (1.7264)  Time: 1.116s,  564.64/s  (1.114s,  565.38/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [4100/6100 ( 67%)]  Loss:  5.240931 (5.2464)  Loss_kd:  0.353233 (0.3520)  Loss_ce:  1.708600 (1.7265)  Time: 1.114s,  565.72/s  (1.114s,  565.38/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [4150/6100 ( 68%)]  Loss:  5.143680 (5.2468)  Loss_kd:  0.346516 (0.3520)  Loss_ce:  1.678523 (1.7267)  Time: 1.114s,  565.58/s  (1.114s,  565.39/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [4200/6100 ( 69%)]  Loss:  5.234943 (5.2468)  Loss_kd:  0.350567 (0.3520)  Loss_ce:  1.729269 (1.7268)  Time: 1.113s,  566.07/s  (1.114s,  565.39/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [4250/6100 ( 70%)]  Loss:  5.651061 (5.2469)  Loss_kd:  0.370390 (0.3520)  Loss_ce:  1.947160 (1.7269)  Time: 1.112s,  566.72/s  (1.114s,  565.40/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [4300/6100 ( 71%)]  Loss:  5.259108 (5.2470)  Loss_kd:  0.357644 (0.3520)  Loss_ce:  1.682672 (1.7269)  Time: 1.116s,  564.26/s  (1.114s,  565.40/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [4350/6100 ( 71%)]  Loss:  5.138945 (5.2472)  Loss_kd:  0.349737 (0.3520)  Loss_ce:  1.641572 (1.7269)  Time: 1.108s,  568.36/s  (1.114s,  565.40/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [4400/6100 ( 72%)]  Loss:  5.205967 (5.2473)  Loss_kd:  0.347098 (0.3520)  Loss_ce:  1.734984 (1.7271)  Time: 1.111s,  567.08/s  (1.114s,  565.40/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [4450/6100 ( 73%)]  Loss:  5.425797 (5.2469)  Loss_kd:  0.357619 (0.3520)  Loss_ce:  1.849605 (1.7270)  Time: 1.110s,  567.42/s  (1.114s,  565.40/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [4500/6100 ( 74%)]  Loss:  5.140518 (5.2467)  Loss_kd:  0.346788 (0.3520)  Loss_ce:  1.672637 (1.7268)  Time: 1.113s,  565.89/s  (1.114s,  565.40/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [4550/6100 ( 75%)]  Loss:  5.324572 (5.2471)  Loss_kd:  0.354747 (0.3520)  Loss_ce:  1.777105 (1.7268)  Time: 1.113s,  566.07/s  (1.114s,  565.41/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [4600/6100 ( 75%)]  Loss:  5.331483 (5.2472)  Loss_kd:  0.352136 (0.3520)  Loss_ce:  1.810123 (1.7268)  Time: 1.109s,  567.83/s  (1.114s,  565.41/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [4650/6100 ( 76%)]  Loss:  5.293745 (5.2472)  Loss_kd:  0.353156 (0.3520)  Loss_ce:  1.762180 (1.7269)  Time: 1.110s,  567.77/s  (1.114s,  565.41/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [4700/6100 ( 77%)]  Loss:  5.265978 (5.2472)  Loss_kd:  0.357153 (0.3520)  Loss_ce:  1.694449 (1.7268)  Time: 1.113s,  565.91/s  (1.114s,  565.41/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [4750/6100 ( 78%)]  Loss:  5.163456 (5.2474)  Loss_kd:  0.343883 (0.3520)  Loss_ce:  1.724626 (1.7270)  Time: 1.112s,  566.56/s  (1.114s,  565.42/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [4800/6100 ( 79%)]  Loss:  5.178527 (5.2478)  Loss_kd:  0.345966 (0.3520)  Loss_ce:  1.718870 (1.7273)  Time: 1.113s,  566.14/s  (1.114s,  565.42/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [4850/6100 ( 80%)]  Loss:  5.321618 (5.2478)  Loss_kd:  0.361194 (0.3520)  Loss_ce:  1.709681 (1.7274)  Time: 1.113s,  566.11/s  (1.114s,  565.42/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [4900/6100 ( 80%)]  Loss:  5.259174 (5.2473)  Loss_kd:  0.355862 (0.3520)  Loss_ce:  1.700553 (1.7271)  Time: 1.113s,  566.12/s  (1.114s,  565.42/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [4950/6100 ( 81%)]  Loss:  5.307629 (5.2471)  Loss_kd:  0.353343 (0.3520)  Loss_ce:  1.774202 (1.7271)  Time: 1.114s,  565.45/s  (1.114s,  565.42/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [5000/6100 ( 82%)]  Loss:  5.068044 (5.2469)  Loss_kd:  0.349993 (0.3520)  Loss_ce:  1.568112 (1.7269)  Time: 1.115s,  564.82/s  (1.114s,  565.42/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [5050/6100 ( 83%)]  Loss:  5.292674 (5.2472)  Loss_kd:  0.345452 (0.3520)  Loss_ce:  1.838154 (1.7271)  Time: 1.110s,  567.50/s  (1.114s,  565.42/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [5100/6100 ( 84%)]  Loss:  5.106337 (5.2471)  Loss_kd:  0.343683 (0.3520)  Loss_ce:  1.669511 (1.7272)  Time: 1.112s,  566.58/s  (1.114s,  565.42/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [5150/6100 ( 84%)]  Loss:  5.274846 (5.2471)  Loss_kd:  0.362312 (0.3520)  Loss_ce:  1.651729 (1.7272)  Time: 1.119s,  563.15/s  (1.114s,  565.42/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [5200/6100 ( 85%)]  Loss:  4.942448 (5.2473)  Loss_kd:  0.335532 (0.3520)  Loss_ce:  1.587127 (1.7272)  Time: 1.114s,  565.75/s  (1.114s,  565.42/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [5250/6100 ( 86%)]  Loss:  5.057725 (5.2472)  Loss_kd:  0.341226 (0.3520)  Loss_ce:  1.645467 (1.7271)  Time: 1.112s,  566.78/s  (1.114s,  565.43/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [5300/6100 ( 87%)]  Loss:  5.195028 (5.2472)  Loss_kd:  0.348026 (0.3520)  Loss_ce:  1.714769 (1.7272)  Time: 1.116s,  564.64/s  (1.114s,  565.43/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [5350/6100 ( 88%)]  Loss:  5.495610 (5.2472)  Loss_kd:  0.366177 (0.3520)  Loss_ce:  1.833842 (1.7273)  Time: 1.114s,  565.32/s  (1.114s,  565.43/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [5400/6100 ( 89%)]  Loss:  5.120779 (5.2469)  Loss_kd:  0.349432 (0.3520)  Loss_ce:  1.626457 (1.7273)  Time: 1.114s,  565.39/s  (1.114s,  565.44/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [5450/6100 ( 89%)]  Loss:  5.247438 (5.2469)  Loss_kd:  0.349152 (0.3520)  Loss_ce:  1.755921 (1.7273)  Time: 1.112s,  566.30/s  (1.114s,  565.44/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [5500/6100 ( 90%)]  Loss:  5.101241 (5.2471)  Loss_kd:  0.340355 (0.3520)  Loss_ce:  1.697691 (1.7273)  Time: 1.131s,  556.87/s  (1.114s,  565.44/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [5550/6100 ( 91%)]  Loss:  5.162726 (5.2470)  Loss_kd:  0.355906 (0.3520)  Loss_ce:  1.603664 (1.7272)  Time: 1.112s,  566.78/s  (1.114s,  565.44/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [5600/6100 ( 92%)]  Loss:  5.328874 (5.2468)  Loss_kd:  0.360701 (0.3520)  Loss_ce:  1.721867 (1.7271)  Time: 1.112s,  566.35/s  (1.114s,  565.45/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [5650/6100 ( 93%)]  Loss:  5.278904 (5.2469)  Loss_kd:  0.347226 (0.3520)  Loss_ce:  1.806641 (1.7272)  Time: 1.113s,  565.99/s  (1.114s,  565.45/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [5700/6100 ( 93%)]  Loss:  5.066359 (5.2466)  Loss_kd:  0.333287 (0.3520)  Loss_ce:  1.733487 (1.7269)  Time: 1.114s,  565.53/s  (1.114s,  565.45/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [5750/6100 ( 94%)]  Loss:  5.351957 (5.2465)  Loss_kd:  0.358398 (0.3520)  Loss_ce:  1.767975 (1.7269)  Time: 1.114s,  565.54/s  (1.114s,  565.45/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [5800/6100 ( 95%)]  Loss:  5.429707 (5.2465)  Loss_kd:  0.356722 (0.3520)  Loss_ce:  1.862484 (1.7269)  Time: 1.116s,  564.54/s  (1.114s,  565.45/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [5850/6100 ( 96%)]  Loss:  5.136323 (5.2467)  Loss_kd:  0.351699 (0.3520)  Loss_ce:  1.619334 (1.7271)  Time: 1.114s,  565.32/s  (1.114s,  565.45/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [5900/6100 ( 97%)]  Loss:  5.437488 (5.2470)  Loss_kd:  0.358197 (0.3520)  Loss_ce:  1.855521 (1.7272)  Time: 1.112s,  566.39/s  (1.114s,  565.45/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train: 3 [5950/6100 ( 98%)]  Loss:  5.302429 (5.2471)  Loss_kd:  0.361264 (0.3520)  Loss_ce:  1.689790 (1.7272)  Time: 1.117s,  563.95/s  (1.114s,  565.45/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [6000/6100 ( 98%)]  Loss:  5.066303 (5.2471)  Loss_kd:  0.342077 (0.3520)  Loss_ce:  1.645528 (1.7272)  Time: 1.113s,  565.80/s  (1.114s,  565.45/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [6050/6100 ( 99%)]  Loss:  5.187104 (5.2471)  Loss_kd:  0.354751 (0.3520)  Loss_ce:  1.639595 (1.7272)  Time: 1.113s,  565.95/s  (1.114s,  565.45/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 3 [6099/6100 (100%)]  Loss:  5.102500 (5.2471)  Loss_kd:  0.345320 (0.3520)  Loss_ce:  1.649302 (1.7271)  Time: 1.451s,  434.27/s  (1.114s,  565.43/s)  LR: 1.000e-05  Data: 0.343 (0.002)\n",
      "INFO:root:Test: [   0/239]  Time: 5.742s (5.742s,   36.57/s)  Loss:  0.5127 (0.5127)  Acc@1:  88.095 ( 88.095)  Acc@5:  97.619 ( 97.619)\n",
      "INFO:root:Test: [  10/239]  Time: 0.331s (0.833s,  252.10/s)  Loss:  0.9687 (0.6200)  Acc@1:  77.143 ( 85.541)  Acc@5:  93.810 ( 97.186)\n",
      "INFO:root:Test: [  20/239]  Time: 0.327s (0.593s,  354.19/s)  Loss:  0.4722 (0.7219)  Acc@1:  90.952 ( 82.562)  Acc@5:  97.619 ( 96.417)\n",
      "INFO:root:Test: [  30/239]  Time: 0.333s (0.508s,  413.41/s)  Loss:  0.5297 (0.6745)  Acc@1:  89.524 ( 84.178)  Acc@5:  96.190 ( 96.452)\n",
      "INFO:root:Test: [  40/239]  Time: 0.331s (0.465s,  451.97/s)  Loss:  0.7802 (0.6627)  Acc@1:  82.857 ( 84.541)  Acc@5:  94.762 ( 96.469)\n",
      "INFO:root:Test: [  50/239]  Time: 0.332s (0.438s,  479.18/s)  Loss:  0.6532 (0.6781)  Acc@1:  83.810 ( 84.052)  Acc@5:  96.190 ( 96.527)\n",
      "INFO:root:Test: [  60/239]  Time: 0.328s (0.420s,  499.54/s)  Loss:  0.3479 (0.6813)  Acc@1:  93.810 ( 83.794)  Acc@5:  99.048 ( 96.651)\n",
      "INFO:root:Test: [  70/239]  Time: 0.341s (0.407s,  515.34/s)  Loss:  0.6528 (0.6859)  Acc@1:  87.143 ( 83.709)  Acc@5:  95.714 ( 96.680)\n",
      "INFO:root:Test: [  80/239]  Time: 0.326s (0.398s,  528.01/s)  Loss:  0.4864 (0.6698)  Acc@1:  91.429 ( 84.221)  Acc@5:  97.143 ( 96.778)\n",
      "INFO:root:Test: [  90/239]  Time: 0.327s (0.390s,  538.19/s)  Loss:  1.0478 (0.6741)  Acc@1:  73.810 ( 84.103)  Acc@5:  94.762 ( 96.797)\n",
      "INFO:root:Test: [ 100/239]  Time: 0.327s (0.384s,  546.67/s)  Loss:  0.9209 (0.6957)  Acc@1:  77.619 ( 83.588)  Acc@5:  93.810 ( 96.539)\n",
      "INFO:root:Test: [ 110/239]  Time: 0.325s (0.379s,  553.98/s)  Loss:  1.7285 (0.7305)  Acc@1:  60.476 ( 82.741)  Acc@5:  83.333 ( 96.113)\n",
      "INFO:root:Test: [ 120/239]  Time: 0.332s (0.375s,  559.93/s)  Loss:  1.3872 (0.7698)  Acc@1:  64.762 ( 81.771)  Acc@5:  90.000 ( 95.675)\n",
      "INFO:root:Test: [ 130/239]  Time: 0.324s (0.372s,  565.21/s)  Loss:  0.8589 (0.7886)  Acc@1:  79.048 ( 81.309)  Acc@5:  96.190 ( 95.474)\n",
      "INFO:root:Test: [ 140/239]  Time: 0.326s (0.369s,  569.76/s)  Loss:  1.2134 (0.7957)  Acc@1:  75.238 ( 81.243)  Acc@5:  90.476 ( 95.383)\n",
      "INFO:root:Test: [ 150/239]  Time: 0.327s (0.366s,  573.95/s)  Loss:  1.6497 (0.8159)  Acc@1:  66.667 ( 80.877)  Acc@5:  84.286 ( 95.084)\n",
      "INFO:root:Test: [ 160/239]  Time: 0.332s (0.364s,  577.46/s)  Loss:  1.1586 (0.8303)  Acc@1:  71.429 ( 80.461)  Acc@5:  91.429 ( 94.978)\n",
      "INFO:root:Test: [ 170/239]  Time: 0.326s (0.362s,  580.80/s)  Loss:  0.9425 (0.8426)  Acc@1:  78.095 ( 80.226)  Acc@5:  93.810 ( 94.879)\n",
      "INFO:root:Test: [ 180/239]  Time: 0.327s (0.360s,  583.79/s)  Loss:  0.9018 (0.8535)  Acc@1:  81.429 ( 79.987)  Acc@5:  93.810 ( 94.738)\n",
      "INFO:root:Test: [ 190/239]  Time: 0.324s (0.358s,  586.63/s)  Loss:  1.0353 (0.8636)  Acc@1:  78.095 ( 79.803)  Acc@5:  90.952 ( 94.567)\n",
      "INFO:root:Test: [ 200/239]  Time: 0.327s (0.356s,  589.12/s)  Loss:  1.1460 (0.8801)  Acc@1:  74.286 ( 79.391)  Acc@5:  92.381 ( 94.373)\n",
      "INFO:root:Test: [ 210/239]  Time: 0.323s (0.355s,  591.36/s)  Loss:  1.7323 (0.8891)  Acc@1:  59.048 ( 79.149)  Acc@5:  83.333 ( 94.265)\n",
      "INFO:root:Test: [ 220/239]  Time: 0.325s (0.354s,  593.66/s)  Loss:  0.6905 (0.8966)  Acc@1:  82.857 ( 78.983)  Acc@5:  97.143 ( 94.223)\n",
      "INFO:root:Test: [ 230/239]  Time: 0.325s (0.352s,  595.82/s)  Loss:  1.8918 (0.8967)  Acc@1:  55.714 ( 78.951)  Acc@5:  85.714 ( 94.244)\n",
      "INFO:root: * Acc@1 78.962 (21.038) Acc@5 94.292 (5.708)\n",
      "INFO:root:Current checkpoints:\n",
      " ('./output/train/20200625-133839-tf_efficientnet_b1-240/checkpoint-3.pth.tar', 78.962)\n",
      " ('./output/train/20200625-133839-tf_efficientnet_b1-240/checkpoint-1.pth.tar', 78.926)\n",
      " ('./output/train/20200625-133839-tf_efficientnet_b1-240/checkpoint-2.pth.tar', 78.916)\n",
      "\n",
      "INFO:root:Train: 4 [   0/6100 (  0%)]  Loss:  5.372612 (5.3726)  Loss_kd:  0.356542 (0.3565)  Loss_ce:  1.807192 (1.8072)  Time: 5.881s,  107.13/s  (5.881s,  107.13/s)  LR: 1.000e-05  Data: 4.739 (4.739)\n",
      "INFO:root:Train: 4 [  50/6100 (  1%)]  Loss:  5.381972 (5.2223)  Loss_kd:  0.357167 (0.3497)  Loss_ce:  1.810299 (1.7250)  Time: 1.114s,  565.63/s  (1.207s,  522.06/s)  LR: 1.000e-05  Data: 0.001 (0.094)\n",
      "INFO:root:Train: 4 [ 100/6100 (  2%)]  Loss:  5.177252 (5.2432)  Loss_kd:  0.350318 (0.3514)  Loss_ce:  1.674074 (1.7291)  Time: 1.116s,  564.72/s  (1.160s,  543.03/s)  LR: 1.000e-05  Data: 0.001 (0.048)\n",
      "INFO:root:Train: 4 [ 150/6100 (  2%)]  Loss:  5.304771 (5.2451)  Loss_kd:  0.348746 (0.3519)  Loss_ce:  1.817312 (1.7263)  Time: 1.112s,  566.77/s  (1.145s,  550.36/s)  LR: 1.000e-05  Data: 0.001 (0.032)\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'IHDR' 16 13\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'sRGB' 41 1\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'gAMA' 54 4\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'cHRM' 70 32\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'pHYs' 114 9\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'IDAT' 135 65401\n",
      "INFO:root:Train: 4 [ 200/6100 (  3%)]  Loss:  5.348438 (5.2482)  Loss_kd:  0.358984 (0.3524)  Loss_ce:  1.758599 (1.7247)  Time: 1.114s,  565.30/s  (1.137s,  554.15/s)  LR: 1.000e-05  Data: 0.002 (0.025)\n",
      "INFO:root:Train: 4 [ 250/6100 (  4%)]  Loss:  5.107092 (5.2538)  Loss_kd:  0.340602 (0.3526)  Loss_ce:  1.701067 (1.7280)  Time: 1.114s,  565.49/s  (1.132s,  556.52/s)  LR: 1.000e-05  Data: 0.001 (0.020)\n",
      "INFO:root:Train: 4 [ 300/6100 (  5%)]  Loss:  5.210373 (5.2487)  Loss_kd:  0.343705 (0.3522)  Loss_ce:  1.773320 (1.7265)  Time: 1.110s,  567.56/s  (1.129s,  558.04/s)  LR: 1.000e-05  Data: 0.001 (0.017)\n",
      "INFO:root:Train: 4 [ 350/6100 (  6%)]  Loss:  5.307255 (5.2509)  Loss_kd:  0.356626 (0.3522)  Loss_ce:  1.740998 (1.7293)  Time: 1.113s,  565.88/s  (1.127s,  559.21/s)  LR: 1.000e-05  Data: 0.001 (0.014)\n",
      "INFO:root:Train: 4 [ 400/6100 (  7%)]  Loss:  5.428900 (5.2511)  Loss_kd:  0.373867 (0.3521)  Loss_ce:  1.690228 (1.7305)  Time: 1.114s,  565.63/s  (1.125s,  560.04/s)  LR: 1.000e-05  Data: 0.001 (0.013)\n",
      "INFO:root:Train: 4 [ 450/6100 (  7%)]  Loss:  5.228996 (5.2516)  Loss_kd:  0.351011 (0.3521)  Loss_ce:  1.718891 (1.7307)  Time: 1.112s,  566.39/s  (1.124s,  560.70/s)  LR: 1.000e-05  Data: 0.001 (0.011)\n",
      "INFO:root:Train: 4 [ 500/6100 (  8%)]  Loss:  5.188244 (5.2501)  Loss_kd:  0.354248 (0.3520)  Loss_ce:  1.645766 (1.7298)  Time: 1.112s,  566.37/s  (1.123s,  561.22/s)  LR: 1.000e-05  Data: 0.002 (0.010)\n",
      "INFO:root:Train: 4 [ 550/6100 (  9%)]  Loss:  5.154725 (5.2496)  Loss_kd:  0.348668 (0.3520)  Loss_ce:  1.668046 (1.7299)  Time: 1.109s,  567.91/s  (1.122s,  561.60/s)  LR: 1.000e-05  Data: 0.001 (0.010)\n",
      "INFO:root:Train: 4 [ 600/6100 ( 10%)]  Loss:  5.161847 (5.2532)  Loss_kd:  0.348897 (0.3522)  Loss_ce:  1.672875 (1.7315)  Time: 1.122s,  561.64/s  (1.121s,  561.98/s)  LR: 1.000e-05  Data: 0.001 (0.009)\n",
      "INFO:root:Train: 4 [ 650/6100 ( 11%)]  Loss:  5.515724 (5.2541)  Loss_kd:  0.378260 (0.3523)  Loss_ce:  1.733124 (1.7309)  Time: 1.114s,  565.38/s  (1.121s,  562.22/s)  LR: 1.000e-05  Data: 0.001 (0.008)\n",
      "INFO:root:Train: 4 [ 700/6100 ( 11%)]  Loss:  5.045218 (5.2521)  Loss_kd:  0.330011 (0.3522)  Loss_ce:  1.745103 (1.7302)  Time: 1.114s,  565.50/s  (1.120s,  562.45/s)  LR: 1.000e-05  Data: 0.001 (0.008)\n",
      "INFO:root:Train: 4 [ 750/6100 ( 12%)]  Loss:  5.125058 (5.2494)  Loss_kd:  0.342945 (0.3520)  Loss_ce:  1.695606 (1.7293)  Time: 1.112s,  566.51/s  (1.120s,  562.72/s)  LR: 1.000e-05  Data: 0.001 (0.007)\n",
      "INFO:root:Train: 4 [ 800/6100 ( 13%)]  Loss:  5.452793 (5.2484)  Loss_kd:  0.347408 (0.3520)  Loss_ce:  1.978710 (1.7287)  Time: 1.112s,  566.48/s  (1.119s,  562.93/s)  LR: 1.000e-05  Data: 0.001 (0.007)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train: 4 [ 850/6100 ( 14%)]  Loss:  5.072076 (5.2473)  Loss_kd:  0.340963 (0.3519)  Loss_ce:  1.662448 (1.7280)  Time: 1.113s,  566.26/s  (1.119s,  563.11/s)  LR: 1.000e-05  Data: 0.001 (0.007)\n",
      "INFO:root:Train: 4 [ 900/6100 ( 15%)]  Loss:  5.174829 (5.2469)  Loss_kd:  0.344904 (0.3519)  Loss_ce:  1.725788 (1.7276)  Time: 1.112s,  566.74/s  (1.119s,  563.24/s)  LR: 1.000e-05  Data: 0.001 (0.006)\n",
      "INFO:root:Train: 4 [ 950/6100 ( 16%)]  Loss:  5.225054 (5.2461)  Loss_kd:  0.336219 (0.3519)  Loss_ce:  1.862860 (1.7271)  Time: 1.111s,  566.98/s  (1.118s,  563.38/s)  LR: 1.000e-05  Data: 0.001 (0.006)\n",
      "INFO:root:Train: 4 [1000/6100 ( 16%)]  Loss:  5.257072 (5.2443)  Loss_kd:  0.353004 (0.3518)  Loss_ce:  1.727031 (1.7264)  Time: 1.112s,  566.35/s  (1.118s,  563.49/s)  LR: 1.000e-05  Data: 0.001 (0.006)\n",
      "INFO:root:Train: 4 [1050/6100 ( 17%)]  Loss:  5.356981 (5.2464)  Loss_kd:  0.358711 (0.3519)  Loss_ce:  1.769875 (1.7273)  Time: 1.117s,  563.84/s  (1.118s,  563.63/s)  LR: 1.000e-05  Data: 0.001 (0.006)\n",
      "INFO:root:Train: 4 [1100/6100 ( 18%)]  Loss:  4.949638 (5.2469)  Loss_kd:  0.333676 (0.3520)  Loss_ce:  1.612880 (1.7272)  Time: 1.114s,  565.66/s  (1.118s,  563.75/s)  LR: 1.000e-05  Data: 0.001 (0.005)\n",
      "INFO:root:Train: 4 [1150/6100 ( 19%)]  Loss:  5.574809 (5.2479)  Loss_kd:  0.375770 (0.3521)  Loss_ce:  1.817104 (1.7274)  Time: 1.114s,  565.68/s  (1.117s,  563.84/s)  LR: 1.000e-05  Data: 0.001 (0.005)\n",
      "INFO:root:Train: 4 [1200/6100 ( 20%)]  Loss:  5.159890 (5.2481)  Loss_kd:  0.348820 (0.3520)  Loss_ce:  1.671691 (1.7277)  Time: 1.113s,  566.15/s  (1.117s,  563.95/s)  LR: 1.000e-05  Data: 0.001 (0.005)\n",
      "INFO:root:Train: 4 [1250/6100 ( 20%)]  Loss:  5.132038 (5.2471)  Loss_kd:  0.340332 (0.3520)  Loss_ce:  1.728720 (1.7275)  Time: 1.113s,  566.02/s  (1.117s,  564.04/s)  LR: 1.000e-05  Data: 0.001 (0.005)\n",
      "INFO:root:Train: 4 [1300/6100 ( 21%)]  Loss:  5.423451 (5.2471)  Loss_kd:  0.369708 (0.3519)  Loss_ce:  1.726376 (1.7277)  Time: 1.112s,  566.44/s  (1.117s,  564.11/s)  LR: 1.000e-05  Data: 0.001 (0.005)\n",
      "INFO:root:Train: 4 [1350/6100 ( 22%)]  Loss:  5.039230 (5.2459)  Loss_kd:  0.337235 (0.3518)  Loss_ce:  1.666883 (1.7276)  Time: 1.112s,  566.39/s  (1.117s,  564.18/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 4 [1400/6100 ( 23%)]  Loss:  5.059365 (5.2466)  Loss_kd:  0.346035 (0.3519)  Loss_ce:  1.599011 (1.7277)  Time: 1.112s,  566.61/s  (1.117s,  564.25/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 4 [1450/6100 ( 24%)]  Loss:  5.089520 (5.2470)  Loss_kd:  0.343231 (0.3519)  Loss_ce:  1.657207 (1.7282)  Time: 1.121s,  562.19/s  (1.116s,  564.30/s)  LR: 1.000e-05  Data: 0.005 (0.004)\n",
      "INFO:root:Train: 4 [1500/6100 ( 25%)]  Loss:  5.195751 (5.2475)  Loss_kd:  0.358436 (0.3519)  Loss_ce:  1.611388 (1.7281)  Time: 1.112s,  566.32/s  (1.116s,  564.35/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 4 [1550/6100 ( 25%)]  Loss:  5.247221 (5.2476)  Loss_kd:  0.359303 (0.3520)  Loss_ce:  1.654195 (1.7279)  Time: 1.113s,  566.11/s  (1.116s,  564.40/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 4 [1600/6100 ( 26%)]  Loss:  5.302424 (5.2478)  Loss_kd:  0.367027 (0.3519)  Loss_ce:  1.632155 (1.7286)  Time: 1.113s,  565.98/s  (1.116s,  564.46/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 4 [1650/6100 ( 27%)]  Loss:  5.328904 (5.2484)  Loss_kd:  0.353590 (0.3519)  Loss_ce:  1.793005 (1.7290)  Time: 1.112s,  566.41/s  (1.116s,  564.51/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 4 [1700/6100 ( 28%)]  Loss:  4.934262 (5.2485)  Loss_kd:  0.335879 (0.3520)  Loss_ce:  1.575474 (1.7289)  Time: 1.114s,  565.76/s  (1.116s,  564.55/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 4 [1750/6100 ( 29%)]  Loss:  5.218982 (5.2487)  Loss_kd:  0.353922 (0.3519)  Loss_ce:  1.679765 (1.7294)  Time: 1.110s,  567.44/s  (1.116s,  564.60/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 4 [1800/6100 ( 30%)]  Loss:  5.460093 (5.2487)  Loss_kd:  0.353342 (0.3519)  Loss_ce:  1.926670 (1.7294)  Time: 1.110s,  567.53/s  (1.116s,  564.63/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 4 [1850/6100 ( 30%)]  Loss:  5.350848 (5.2481)  Loss_kd:  0.354172 (0.3519)  Loss_ce:  1.809128 (1.7291)  Time: 1.113s,  566.26/s  (1.116s,  564.67/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 4 [1900/6100 ( 31%)]  Loss:  5.288177 (5.2483)  Loss_kd:  0.357010 (0.3519)  Loss_ce:  1.718077 (1.7291)  Time: 1.114s,  565.69/s  (1.116s,  564.71/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 4 [1950/6100 ( 32%)]  Loss:  5.479113 (5.2491)  Loss_kd:  0.369550 (0.3520)  Loss_ce:  1.783618 (1.7293)  Time: 1.113s,  566.20/s  (1.116s,  564.75/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 4 [2000/6100 ( 33%)]  Loss:  5.179087 (5.2490)  Loss_kd:  0.350543 (0.3520)  Loss_ce:  1.673657 (1.7293)  Time: 1.110s,  567.72/s  (1.115s,  564.78/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 4 [2050/6100 ( 34%)]  Loss:  5.381666 (5.2494)  Loss_kd:  0.368077 (0.3520)  Loss_ce:  1.700891 (1.7290)  Time: 1.112s,  566.51/s  (1.115s,  564.81/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 4 [2100/6100 ( 34%)]  Loss:  5.467055 (5.2499)  Loss_kd:  0.368870 (0.3520)  Loss_ce:  1.778357 (1.7294)  Time: 1.113s,  565.80/s  (1.115s,  564.83/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 4 [2150/6100 ( 35%)]  Loss:  5.375253 (5.2489)  Loss_kd:  0.361085 (0.3520)  Loss_ce:  1.764405 (1.7288)  Time: 1.112s,  566.54/s  (1.115s,  564.85/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 4 [2200/6100 ( 36%)]  Loss:  4.875151 (5.2487)  Loss_kd:  0.331879 (0.3520)  Loss_ce:  1.556358 (1.7289)  Time: 1.114s,  565.35/s  (1.115s,  564.87/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 4 [2250/6100 ( 37%)]  Loss:  4.921217 (5.2490)  Loss_kd:  0.332211 (0.3520)  Loss_ce:  1.599102 (1.7287)  Time: 1.113s,  566.01/s  (1.115s,  564.87/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 4 [2300/6100 ( 38%)]  Loss:  5.108529 (5.2490)  Loss_kd:  0.339014 (0.3520)  Loss_ce:  1.718390 (1.7288)  Time: 1.110s,  567.49/s  (1.115s,  564.90/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 4 [2350/6100 ( 39%)]  Loss:  5.399700 (5.2487)  Loss_kd:  0.356343 (0.3520)  Loss_ce:  1.836274 (1.7289)  Time: 1.110s,  567.75/s  (1.115s,  564.92/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 4 [2400/6100 ( 39%)]  Loss:  5.231943 (5.2490)  Loss_kd:  0.353229 (0.3520)  Loss_ce:  1.699652 (1.7289)  Time: 1.113s,  565.90/s  (1.115s,  564.94/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 4 [2450/6100 ( 40%)]  Loss:  5.189229 (5.2484)  Loss_kd:  0.341452 (0.3520)  Loss_ce:  1.774710 (1.7286)  Time: 1.110s,  567.66/s  (1.115s,  564.96/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 4 [2500/6100 ( 41%)]  Loss:  5.397751 (5.2480)  Loss_kd:  0.368996 (0.3520)  Loss_ce:  1.707790 (1.7282)  Time: 1.114s,  565.74/s  (1.115s,  564.98/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 4 [2550/6100 ( 42%)]  Loss:  5.352236 (5.2476)  Loss_kd:  0.351583 (0.3520)  Loss_ce:  1.836407 (1.7280)  Time: 1.113s,  566.17/s  (1.115s,  565.00/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 4 [2600/6100 ( 43%)]  Loss:  5.399915 (5.2478)  Loss_kd:  0.361248 (0.3520)  Loss_ce:  1.787438 (1.7283)  Time: 1.112s,  566.34/s  (1.115s,  565.03/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 4 [2650/6100 ( 43%)]  Loss:  5.093488 (5.2471)  Loss_kd:  0.346393 (0.3519)  Loss_ce:  1.629559 (1.7279)  Time: 1.109s,  568.21/s  (1.115s,  565.04/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 4 [2700/6100 ( 44%)]  Loss:  5.198773 (5.2469)  Loss_kd:  0.342135 (0.3519)  Loss_ce:  1.777426 (1.7279)  Time: 1.113s,  566.18/s  (1.115s,  565.05/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 4 [2750/6100 ( 45%)]  Loss:  5.124543 (5.2466)  Loss_kd:  0.350080 (0.3519)  Loss_ce:  1.623738 (1.7279)  Time: 1.113s,  565.79/s  (1.115s,  565.07/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 4 [2800/6100 ( 46%)]  Loss:  5.260678 (5.2467)  Loss_kd:  0.352245 (0.3519)  Loss_ce:  1.738232 (1.7278)  Time: 1.113s,  565.99/s  (1.115s,  565.09/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 4 [2850/6100 ( 47%)]  Loss:  5.220765 (5.2463)  Loss_kd:  0.357425 (0.3519)  Loss_ce:  1.646518 (1.7276)  Time: 1.113s,  566.00/s  (1.115s,  565.10/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train: 4 [2900/6100 ( 48%)]  Loss:  5.134595 (5.2465)  Loss_kd:  0.342725 (0.3519)  Loss_ce:  1.707349 (1.7277)  Time: 1.113s,  566.02/s  (1.115s,  565.12/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 4 [2950/6100 ( 48%)]  Loss:  5.019041 (5.2467)  Loss_kd:  0.339299 (0.3519)  Loss_ce:  1.626051 (1.7278)  Time: 1.114s,  565.72/s  (1.115s,  565.14/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 4 [3000/6100 ( 49%)]  Loss:  5.359919 (5.2469)  Loss_kd:  0.357968 (0.3519)  Loss_ce:  1.780239 (1.7280)  Time: 1.113s,  566.15/s  (1.115s,  565.16/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 4 [3050/6100 ( 50%)]  Loss:  5.241621 (5.2469)  Loss_kd:  0.356843 (0.3519)  Loss_ce:  1.673189 (1.7281)  Time: 1.113s,  566.25/s  (1.115s,  565.17/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 4 [3100/6100 ( 51%)]  Loss:  5.131267 (5.2473)  Loss_kd:  0.340612 (0.3519)  Loss_ce:  1.725148 (1.7283)  Time: 1.113s,  566.00/s  (1.115s,  565.18/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [3150/6100 ( 52%)]  Loss:  5.122848 (5.2472)  Loss_kd:  0.339276 (0.3519)  Loss_ce:  1.730092 (1.7282)  Time: 1.113s,  565.94/s  (1.115s,  565.20/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [3200/6100 ( 52%)]  Loss:  5.391411 (5.2477)  Loss_kd:  0.353937 (0.3519)  Loss_ce:  1.852041 (1.7283)  Time: 1.114s,  565.77/s  (1.115s,  565.22/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [3250/6100 ( 53%)]  Loss:  5.389849 (5.2471)  Loss_kd:  0.360617 (0.3519)  Loss_ce:  1.783683 (1.7280)  Time: 1.110s,  567.37/s  (1.115s,  565.23/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [3300/6100 ( 54%)]  Loss:  5.525525 (5.2471)  Loss_kd:  0.358579 (0.3519)  Loss_ce:  1.939738 (1.7280)  Time: 1.113s,  566.11/s  (1.115s,  565.24/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [3350/6100 ( 55%)]  Loss:  5.339456 (5.2472)  Loss_kd:  0.354585 (0.3519)  Loss_ce:  1.793610 (1.7281)  Time: 1.113s,  566.25/s  (1.115s,  565.26/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [3400/6100 ( 56%)]  Loss:  5.001795 (5.2473)  Loss_kd:  0.338793 (0.3519)  Loss_ce:  1.613867 (1.7281)  Time: 1.115s,  565.16/s  (1.115s,  565.27/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [3450/6100 ( 57%)]  Loss:  5.422044 (5.2469)  Loss_kd:  0.366608 (0.3519)  Loss_ce:  1.755966 (1.7278)  Time: 1.109s,  567.91/s  (1.114s,  565.29/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [3500/6100 ( 57%)]  Loss:  5.230345 (5.2467)  Loss_kd:  0.348360 (0.3519)  Loss_ce:  1.746742 (1.7278)  Time: 1.113s,  565.89/s  (1.114s,  565.29/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [3550/6100 ( 58%)]  Loss:  5.146295 (5.2463)  Loss_kd:  0.345542 (0.3519)  Loss_ce:  1.690877 (1.7277)  Time: 1.112s,  566.80/s  (1.114s,  565.31/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [3600/6100 ( 59%)]  Loss:  5.456303 (5.2459)  Loss_kd:  0.355285 (0.3518)  Loss_ce:  1.903450 (1.7277)  Time: 1.122s,  561.31/s  (1.114s,  565.31/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [3650/6100 ( 60%)]  Loss:  5.262174 (5.2459)  Loss_kd:  0.346733 (0.3518)  Loss_ce:  1.794845 (1.7277)  Time: 1.113s,  565.95/s  (1.114s,  565.32/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [3700/6100 ( 61%)]  Loss:  5.176859 (5.2461)  Loss_kd:  0.348960 (0.3519)  Loss_ce:  1.687259 (1.7276)  Time: 1.113s,  565.84/s  (1.114s,  565.33/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [3750/6100 ( 61%)]  Loss:  5.287414 (5.2464)  Loss_kd:  0.347143 (0.3519)  Loss_ce:  1.815987 (1.7277)  Time: 1.113s,  565.85/s  (1.114s,  565.34/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [3800/6100 ( 62%)]  Loss:  5.221929 (5.2462)  Loss_kd:  0.354603 (0.3519)  Loss_ce:  1.675903 (1.7276)  Time: 1.114s,  565.41/s  (1.114s,  565.34/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [3850/6100 ( 63%)]  Loss:  5.350018 (5.2457)  Loss_kd:  0.364265 (0.3518)  Loss_ce:  1.707365 (1.7273)  Time: 1.114s,  565.52/s  (1.114s,  565.34/s)  LR: 1.000e-05  Data: 0.002 (0.002)\n",
      "INFO:root:Train: 4 [3900/6100 ( 64%)]  Loss:  5.283406 (5.2461)  Loss_kd:  0.348172 (0.3519)  Loss_ce:  1.801683 (1.7275)  Time: 1.113s,  565.81/s  (1.114s,  565.34/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [3950/6100 ( 65%)]  Loss:  5.432075 (5.2466)  Loss_kd:  0.352637 (0.3519)  Loss_ce:  1.905703 (1.7279)  Time: 1.112s,  566.31/s  (1.114s,  565.35/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [4000/6100 ( 66%)]  Loss:  5.404501 (5.2467)  Loss_kd:  0.353327 (0.3519)  Loss_ce:  1.871228 (1.7280)  Time: 1.116s,  564.76/s  (1.114s,  565.36/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [4050/6100 ( 66%)]  Loss:  4.980914 (5.2466)  Loss_kd:  0.336193 (0.3519)  Loss_ce:  1.618987 (1.7279)  Time: 1.114s,  565.36/s  (1.114s,  565.37/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [4100/6100 ( 67%)]  Loss:  5.238564 (5.2466)  Loss_kd:  0.360323 (0.3519)  Loss_ce:  1.635337 (1.7279)  Time: 1.114s,  565.45/s  (1.114s,  565.36/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [4150/6100 ( 68%)]  Loss:  5.244905 (5.2471)  Loss_kd:  0.349622 (0.3519)  Loss_ce:  1.748689 (1.7280)  Time: 1.111s,  566.90/s  (1.114s,  565.36/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [4200/6100 ( 69%)]  Loss:  5.264059 (5.2471)  Loss_kd:  0.353000 (0.3519)  Loss_ce:  1.734059 (1.7281)  Time: 1.113s,  566.21/s  (1.114s,  565.36/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [4250/6100 ( 70%)]  Loss:  5.346607 (5.2472)  Loss_kd:  0.355148 (0.3519)  Loss_ce:  1.795127 (1.7281)  Time: 1.112s,  566.40/s  (1.114s,  565.36/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [4300/6100 ( 71%)]  Loss:  5.175210 (5.2476)  Loss_kd:  0.356094 (0.3519)  Loss_ce:  1.614272 (1.7283)  Time: 1.116s,  564.50/s  (1.114s,  565.37/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [4350/6100 ( 71%)]  Loss:  5.283849 (5.2480)  Loss_kd:  0.363214 (0.3520)  Loss_ce:  1.651705 (1.7285)  Time: 1.115s,  565.27/s  (1.114s,  565.38/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [4400/6100 ( 72%)]  Loss:  5.361024 (5.2481)  Loss_kd:  0.357255 (0.3520)  Loss_ce:  1.788471 (1.7284)  Time: 1.114s,  565.43/s  (1.114s,  565.38/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [4450/6100 ( 73%)]  Loss:  5.266598 (5.2479)  Loss_kd:  0.355857 (0.3520)  Loss_ce:  1.708029 (1.7282)  Time: 1.117s,  564.06/s  (1.114s,  565.38/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [4500/6100 ( 74%)]  Loss:  5.271915 (5.2481)  Loss_kd:  0.355506 (0.3520)  Loss_ce:  1.716856 (1.7283)  Time: 1.113s,  565.92/s  (1.114s,  565.38/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [4550/6100 ( 75%)]  Loss:  5.104761 (5.2481)  Loss_kd:  0.329579 (0.3520)  Loss_ce:  1.808968 (1.7283)  Time: 1.113s,  566.01/s  (1.114s,  565.39/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [4600/6100 ( 75%)]  Loss:  5.282888 (5.2480)  Loss_kd:  0.349640 (0.3520)  Loss_ce:  1.786490 (1.7282)  Time: 1.113s,  566.09/s  (1.114s,  565.39/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [4650/6100 ( 76%)]  Loss:  5.342595 (5.2483)  Loss_kd:  0.358275 (0.3520)  Loss_ce:  1.759842 (1.7284)  Time: 1.113s,  566.26/s  (1.114s,  565.40/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [4700/6100 ( 77%)]  Loss:  5.255777 (5.2489)  Loss_kd:  0.350424 (0.3520)  Loss_ce:  1.751538 (1.7287)  Time: 1.110s,  567.75/s  (1.114s,  565.40/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [4750/6100 ( 78%)]  Loss:  5.275925 (5.2488)  Loss_kd:  0.349284 (0.3520)  Loss_ce:  1.783090 (1.7287)  Time: 1.115s,  565.15/s  (1.114s,  565.40/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [4800/6100 ( 79%)]  Loss:  5.352726 (5.2489)  Loss_kd:  0.358359 (0.3520)  Loss_ce:  1.769132 (1.7287)  Time: 1.114s,  565.39/s  (1.114s,  565.40/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [4850/6100 ( 80%)]  Loss:  5.106965 (5.2487)  Loss_kd:  0.352488 (0.3520)  Loss_ce:  1.582084 (1.7287)  Time: 1.109s,  568.12/s  (1.114s,  565.41/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [4900/6100 ( 80%)]  Loss:  5.130452 (5.2489)  Loss_kd:  0.348440 (0.3520)  Loss_ce:  1.646051 (1.7288)  Time: 1.113s,  566.05/s  (1.114s,  565.41/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train: 4 [4950/6100 ( 81%)]  Loss:  5.277558 (5.2489)  Loss_kd:  0.349736 (0.3520)  Loss_ce:  1.780201 (1.7287)  Time: 1.114s,  565.52/s  (1.114s,  565.41/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [5000/6100 ( 82%)]  Loss:  5.042574 (5.2487)  Loss_kd:  0.346263 (0.3520)  Loss_ce:  1.579946 (1.7286)  Time: 1.112s,  566.45/s  (1.114s,  565.41/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [5050/6100 ( 83%)]  Loss:  5.231630 (5.2483)  Loss_kd:  0.363357 (0.3520)  Loss_ce:  1.598065 (1.7284)  Time: 1.112s,  566.78/s  (1.114s,  565.41/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [5100/6100 ( 84%)]  Loss:  5.419349 (5.2480)  Loss_kd:  0.362193 (0.3520)  Loss_ce:  1.797424 (1.7283)  Time: 1.113s,  566.21/s  (1.114s,  565.42/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [5150/6100 ( 84%)]  Loss:  5.575677 (5.2484)  Loss_kd:  0.378404 (0.3520)  Loss_ce:  1.791632 (1.7285)  Time: 1.114s,  565.65/s  (1.114s,  565.42/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [5200/6100 ( 85%)]  Loss:  5.363556 (5.2484)  Loss_kd:  0.359102 (0.3520)  Loss_ce:  1.772537 (1.7286)  Time: 1.113s,  566.24/s  (1.114s,  565.41/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [5250/6100 ( 86%)]  Loss:  5.118263 (5.2484)  Loss_kd:  0.329931 (0.3520)  Loss_ce:  1.818952 (1.7285)  Time: 1.125s,  559.90/s  (1.114s,  565.42/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [5300/6100 ( 87%)]  Loss:  5.213666 (5.2488)  Loss_kd:  0.343138 (0.3520)  Loss_ce:  1.782291 (1.7289)  Time: 1.114s,  565.58/s  (1.114s,  565.42/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [5350/6100 ( 88%)]  Loss:  5.469537 (5.2489)  Loss_kd:  0.362395 (0.3520)  Loss_ce:  1.845590 (1.7289)  Time: 1.114s,  565.78/s  (1.114s,  565.43/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [5400/6100 ( 89%)]  Loss:  5.164097 (5.2489)  Loss_kd:  0.349558 (0.3520)  Loss_ce:  1.668520 (1.7290)  Time: 1.113s,  565.86/s  (1.114s,  565.43/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [5450/6100 ( 89%)]  Loss:  5.279897 (5.2487)  Loss_kd:  0.350768 (0.3520)  Loss_ce:  1.772221 (1.7289)  Time: 1.110s,  567.67/s  (1.114s,  565.44/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "/home/cutz/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "INFO:root:Train: 4 [5500/6100 ( 90%)]  Loss:  5.163076 (5.2486)  Loss_kd:  0.341427 (0.3520)  Loss_ce:  1.748801 (1.7289)  Time: 1.117s,  564.25/s  (1.114s,  565.44/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [5550/6100 ( 91%)]  Loss:  4.995078 (5.2485)  Loss_kd:  0.345441 (0.3520)  Loss_ce:  1.540663 (1.7289)  Time: 1.114s,  565.77/s  (1.114s,  565.43/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [5600/6100 ( 92%)]  Loss:  5.234014 (5.2487)  Loss_kd:  0.353555 (0.3520)  Loss_ce:  1.698461 (1.7290)  Time: 1.113s,  565.85/s  (1.114s,  565.43/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [5650/6100 ( 93%)]  Loss:  5.148017 (5.2488)  Loss_kd:  0.346710 (0.3520)  Loss_ce:  1.680916 (1.7289)  Time: 1.113s,  565.84/s  (1.114s,  565.43/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [5700/6100 ( 93%)]  Loss:  5.482841 (5.2492)  Loss_kd:  0.365784 (0.3520)  Loss_ce:  1.825005 (1.7289)  Time: 1.113s,  565.81/s  (1.114s,  565.43/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [5750/6100 ( 94%)]  Loss:  5.140977 (5.2492)  Loss_kd:  0.331548 (0.3520)  Loss_ce:  1.825501 (1.7290)  Time: 1.112s,  566.37/s  (1.114s,  565.43/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [5800/6100 ( 95%)]  Loss:  5.006711 (5.2493)  Loss_kd:  0.339383 (0.3520)  Loss_ce:  1.612877 (1.7289)  Time: 1.113s,  566.11/s  (1.114s,  565.44/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [5850/6100 ( 96%)]  Loss:  5.105163 (5.2492)  Loss_kd:  0.349673 (0.3520)  Loss_ce:  1.608436 (1.7288)  Time: 1.114s,  565.37/s  (1.114s,  565.44/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [5900/6100 ( 97%)]  Loss:  5.495106 (5.2492)  Loss_kd:  0.371523 (0.3520)  Loss_ce:  1.779877 (1.7289)  Time: 1.113s,  565.93/s  (1.114s,  565.44/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [5950/6100 ( 98%)]  Loss:  5.174834 (5.2497)  Loss_kd:  0.343675 (0.3521)  Loss_ce:  1.738085 (1.7291)  Time: 1.117s,  563.81/s  (1.114s,  565.44/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [6000/6100 ( 98%)]  Loss:  5.216951 (5.2496)  Loss_kd:  0.353867 (0.3521)  Loss_ce:  1.678278 (1.7291)  Time: 1.113s,  565.96/s  (1.114s,  565.45/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [6050/6100 ( 99%)]  Loss:  5.366942 (5.2497)  Loss_kd:  0.355560 (0.3521)  Loss_ce:  1.811345 (1.7292)  Time: 1.113s,  566.05/s  (1.114s,  565.45/s)  LR: 1.000e-05  Data: 0.001 (0.002)\n",
      "INFO:root:Train: 4 [6099/6100 (100%)]  Loss:  5.162290 (5.2498)  Loss_kd:  0.339236 (0.3521)  Loss_ce:  1.769926 (1.7292)  Time: 1.457s,  432.47/s  (1.114s,  565.42/s)  LR: 1.000e-05  Data: 0.348 (0.002)\n",
      "INFO:root:Test: [   0/239]  Time: 6.633s (6.633s,   31.66/s)  Loss:  0.5108 (0.5108)  Acc@1:  88.095 ( 88.095)  Acc@5:  97.619 ( 97.619)\n",
      "INFO:root:Test: [  10/239]  Time: 0.332s (0.908s,  231.25/s)  Loss:  0.9686 (0.6200)  Acc@1:  77.619 ( 85.541)  Acc@5:  93.810 ( 97.143)\n",
      "INFO:root:Test: [  20/239]  Time: 0.331s (0.633s,  331.93/s)  Loss:  0.4709 (0.7223)  Acc@1:  91.429 ( 82.676)  Acc@5:  98.095 ( 96.417)\n",
      "INFO:root:Test: [  30/239]  Time: 0.324s (0.534s,  393.14/s)  Loss:  0.5314 (0.6750)  Acc@1:  89.048 ( 84.209)  Acc@5:  96.190 ( 96.452)\n",
      "INFO:root:Test: [  40/239]  Time: 0.326s (0.484s,  433.69/s)  Loss:  0.7786 (0.6634)  Acc@1:  82.857 ( 84.576)  Acc@5:  94.762 ( 96.469)\n",
      "INFO:root:Test: [  50/239]  Time: 0.327s (0.454s,  462.94/s)  Loss:  0.6569 (0.6786)  Acc@1:  83.810 ( 84.108)  Acc@5:  96.190 ( 96.536)\n",
      "INFO:root:Test: [  60/239]  Time: 0.326s (0.433s,  484.89/s)  Loss:  0.3528 (0.6818)  Acc@1:  93.333 ( 83.841)  Acc@5:  99.048 ( 96.659)\n",
      "INFO:root:Test: [  70/239]  Time: 0.329s (0.419s,  501.35/s)  Loss:  0.6480 (0.6861)  Acc@1:  87.143 ( 83.763)  Acc@5:  95.714 ( 96.680)\n",
      "INFO:root:Test: [  80/239]  Time: 0.327s (0.408s,  515.10/s)  Loss:  0.4866 (0.6701)  Acc@1:  91.429 ( 84.262)  Acc@5:  97.619 ( 96.784)\n",
      "INFO:root:Test: [  90/239]  Time: 0.334s (0.399s,  526.01/s)  Loss:  1.0505 (0.6742)  Acc@1:  73.810 ( 84.092)  Acc@5:  94.286 ( 96.797)\n",
      "INFO:root:Test: [ 100/239]  Time: 0.328s (0.392s,  535.54/s)  Loss:  0.9197 (0.6957)  Acc@1:  77.619 ( 83.588)  Acc@5:  93.810 ( 96.535)\n",
      "INFO:root:Test: [ 110/239]  Time: 0.325s (0.387s,  543.08/s)  Loss:  1.7309 (0.7307)  Acc@1:  60.476 ( 82.733)  Acc@5:  84.286 ( 96.126)\n",
      "INFO:root:Test: [ 120/239]  Time: 0.324s (0.382s,  549.60/s)  Loss:  1.3950 (0.7702)  Acc@1:  63.810 ( 81.755)  Acc@5:  89.524 ( 95.679)\n",
      "INFO:root:Test: [ 130/239]  Time: 0.327s (0.378s,  555.68/s)  Loss:  0.8594 (0.7889)  Acc@1:  79.048 ( 81.290)  Acc@5:  96.190 ( 95.500)\n",
      "INFO:root:Test: [ 140/239]  Time: 0.324s (0.374s,  560.96/s)  Loss:  1.2039 (0.7959)  Acc@1:  75.238 ( 81.226)  Acc@5:  90.476 ( 95.407)\n",
      "INFO:root:Test: [ 150/239]  Time: 0.336s (0.372s,  565.21/s)  Loss:  1.6458 (0.8161)  Acc@1:  65.238 ( 80.870)  Acc@5:  84.762 ( 95.109)\n",
      "INFO:root:Test: [ 160/239]  Time: 0.335s (0.369s,  569.19/s)  Loss:  1.1545 (0.8305)  Acc@1:  71.429 ( 80.464)  Acc@5:  91.429 ( 95.007)\n",
      "INFO:root:Test: [ 170/239]  Time: 0.337s (0.367s,  572.92/s)  Loss:  0.9417 (0.8427)  Acc@1:  77.619 ( 80.245)  Acc@5:  93.810 ( 94.912)\n",
      "INFO:root:Test: [ 180/239]  Time: 0.326s (0.364s,  576.14/s)  Loss:  0.8950 (0.8537)  Acc@1:  81.905 ( 80.018)  Acc@5:  92.857 ( 94.757)\n",
      "INFO:root:Test: [ 190/239]  Time: 0.327s (0.363s,  579.00/s)  Loss:  1.0312 (0.8637)  Acc@1:  79.048 ( 79.830)  Acc@5:  90.952 ( 94.580)\n",
      "INFO:root:Test: [ 200/239]  Time: 0.327s (0.361s,  581.71/s)  Loss:  1.1501 (0.8801)  Acc@1:  74.286 ( 79.420)  Acc@5:  92.381 ( 94.390)\n",
      "INFO:root:Test: [ 210/239]  Time: 0.324s (0.359s,  584.16/s)  Loss:  1.7295 (0.8892)  Acc@1:  60.000 ( 79.183)  Acc@5:  83.333 ( 94.281)\n",
      "INFO:root:Test: [ 220/239]  Time: 0.325s (0.358s,  586.73/s)  Loss:  0.6913 (0.8966)  Acc@1:  81.905 ( 79.002)  Acc@5:  97.619 ( 94.234)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Test: [ 230/239]  Time: 0.324s (0.356s,  589.12/s)  Loss:  1.8873 (0.8967)  Acc@1:  56.190 ( 78.969)  Acc@5:  85.714 ( 94.257)\n",
      "INFO:root: * Acc@1 78.986 (21.014) Acc@5 94.306 (5.694)\n",
      "INFO:root:Current checkpoints:\n",
      " ('./output/train/20200625-133839-tf_efficientnet_b1-240/checkpoint-4.pth.tar', 78.986)\n",
      " ('./output/train/20200625-133839-tf_efficientnet_b1-240/checkpoint-3.pth.tar', 78.962)\n",
      " ('./output/train/20200625-133839-tf_efficientnet_b1-240/checkpoint-1.pth.tar', 78.926)\n",
      " ('./output/train/20200625-133839-tf_efficientnet_b1-240/checkpoint-2.pth.tar', 78.916)\n",
      "\n",
      "INFO:root:Train: 5 [   0/6100 (  0%)]  Loss:  4.968460 (4.9685)  Loss_kd:  0.330562 (0.3306)  Loss_ce:  1.662840 (1.6628)  Time: 6.240s,  100.96/s  (6.240s,  100.96/s)  LR: 1.000e-05  Data: 4.359 (4.359)\n",
      "INFO:root:Train: 5 [  50/6100 (  1%)]  Loss:  5.155859 (5.2383)  Loss_kd:  0.350301 (0.3505)  Loss_ce:  1.652851 (1.7333)  Time: 1.115s,  564.79/s  (1.228s,  513.03/s)  LR: 1.000e-05  Data: 0.002 (0.087)\n",
      "INFO:root:Train: 5 [ 100/6100 (  2%)]  Loss:  5.251490 (5.2505)  Loss_kd:  0.338187 (0.3515)  Loss_ce:  1.869622 (1.7359)  Time: 1.112s,  566.42/s  (1.172s,  537.52/s)  LR: 1.000e-05  Data: 0.001 (0.044)\n",
      "INFO:root:Train: 5 [ 150/6100 (  2%)]  Loss:  5.359313 (5.2435)  Loss_kd:  0.352053 (0.3510)  Loss_ce:  1.838788 (1.7333)  Time: 1.114s,  565.60/s  (1.153s,  546.19/s)  LR: 1.000e-05  Data: 0.001 (0.030)\n",
      "INFO:root:Train: 5 [ 200/6100 (  3%)]  Loss:  5.303878 (5.2479)  Loss_kd:  0.356010 (0.3515)  Loss_ce:  1.743779 (1.7331)  Time: 1.111s,  567.22/s  (1.143s,  550.95/s)  LR: 1.000e-05  Data: 0.001 (0.023)\n",
      "INFO:root:Train: 5 [ 250/6100 (  4%)]  Loss:  5.520042 (5.2475)  Loss_kd:  0.365903 (0.3516)  Loss_ce:  1.861015 (1.7314)  Time: 1.113s,  566.12/s  (1.138s,  553.84/s)  LR: 1.000e-05  Data: 0.001 (0.018)\n",
      "INFO:root:Train: 5 [ 300/6100 (  5%)]  Loss:  5.428417 (5.2472)  Loss_kd:  0.362694 (0.3518)  Loss_ce:  1.801477 (1.7294)  Time: 1.113s,  566.07/s  (1.133s,  555.83/s)  LR: 1.000e-05  Data: 0.001 (0.015)\n",
      "INFO:root:Train: 5 [ 350/6100 (  6%)]  Loss:  5.227232 (5.2509)  Loss_kd:  0.348710 (0.3520)  Loss_ce:  1.740131 (1.7309)  Time: 1.110s,  567.48/s  (1.131s,  557.00/s)  LR: 1.000e-05  Data: 0.001 (0.013)\n",
      "INFO:root:Train: 5 [ 400/6100 (  7%)]  Loss:  5.317565 (5.2538)  Loss_kd:  0.355200 (0.3521)  Loss_ce:  1.765564 (1.7327)  Time: 1.113s,  566.11/s  (1.129s,  558.04/s)  LR: 1.000e-05  Data: 0.001 (0.012)\n",
      "INFO:root:Train: 5 [ 450/6100 (  7%)]  Loss:  5.292540 (5.2481)  Loss_kd:  0.345586 (0.3518)  Loss_ce:  1.836679 (1.7303)  Time: 1.114s,  565.44/s  (1.127s,  558.81/s)  LR: 1.000e-05  Data: 0.001 (0.011)\n",
      "INFO:root:Train: 5 [ 500/6100 (  8%)]  Loss:  5.084063 (5.2500)  Loss_kd:  0.337680 (0.3518)  Loss_ce:  1.707258 (1.7318)  Time: 1.117s,  563.77/s  (1.126s,  559.35/s)  LR: 1.000e-05  Data: 0.001 (0.010)\n",
      "INFO:root:Train: 5 [ 550/6100 (  9%)]  Loss:  5.171750 (5.2516)  Loss_kd:  0.349853 (0.3519)  Loss_ce:  1.673223 (1.7321)  Time: 1.112s,  566.33/s  (1.125s,  559.88/s)  LR: 1.000e-05  Data: 0.001 (0.009)\n",
      "INFO:root:Train: 5 [ 600/6100 ( 10%)]  Loss:  5.388289 (5.2555)  Loss_kd:  0.353937 (0.3521)  Loss_ce:  1.848921 (1.7344)  Time: 1.113s,  566.25/s  (1.124s,  560.34/s)  LR: 1.000e-05  Data: 0.001 (0.008)\n",
      "INFO:root:Train: 5 [ 650/6100 ( 11%)]  Loss:  5.184591 (5.2544)  Loss_kd:  0.349204 (0.3521)  Loss_ce:  1.692553 (1.7339)  Time: 1.123s,  561.10/s  (1.124s,  560.74/s)  LR: 1.000e-05  Data: 0.001 (0.008)\n",
      "INFO:root:Train: 5 [ 700/6100 ( 11%)]  Loss:  5.162416 (5.2531)  Loss_kd:  0.356818 (0.3520)  Loss_ce:  1.594233 (1.7329)  Time: 1.110s,  567.36/s  (1.123s,  561.06/s)  LR: 1.000e-05  Data: 0.001 (0.007)\n",
      "INFO:root:Train: 5 [ 750/6100 ( 12%)]  Loss:  5.220481 (5.2530)  Loss_kd:  0.349850 (0.3520)  Loss_ce:  1.721980 (1.7334)  Time: 1.114s,  565.75/s  (1.122s,  561.38/s)  LR: 1.000e-05  Data: 0.001 (0.007)\n",
      "INFO:root:Train: 5 [ 800/6100 ( 13%)]  Loss:  5.196517 (5.2521)  Loss_kd:  0.340424 (0.3520)  Loss_ce:  1.792278 (1.7322)  Time: 1.112s,  566.29/s  (1.122s,  561.66/s)  LR: 1.000e-05  Data: 0.001 (0.006)\n",
      "INFO:root:Train: 5 [ 850/6100 ( 14%)]  Loss:  5.329626 (5.2529)  Loss_kd:  0.364226 (0.3521)  Loss_ce:  1.687362 (1.7322)  Time: 1.112s,  566.55/s  (1.121s,  561.93/s)  LR: 1.000e-05  Data: 0.001 (0.006)\n",
      "INFO:root:Train: 5 [ 900/6100 ( 15%)]  Loss:  5.327242 (5.2531)  Loss_kd:  0.355137 (0.3521)  Loss_ce:  1.775871 (1.7323)  Time: 1.112s,  566.37/s  (1.121s,  562.16/s)  LR: 1.000e-05  Data: 0.001 (0.006)\n",
      "INFO:root:Train: 5 [ 950/6100 ( 16%)]  Loss:  5.097052 (5.2528)  Loss_kd:  0.344069 (0.3520)  Loss_ce:  1.656365 (1.7326)  Time: 1.110s,  567.69/s  (1.120s,  562.38/s)  LR: 1.000e-05  Data: 0.001 (0.006)\n",
      "INFO:root:Train: 5 [1000/6100 ( 16%)]  Loss:  5.371504 (5.2523)  Loss_kd:  0.356742 (0.3520)  Loss_ce:  1.804084 (1.7324)  Time: 1.113s,  565.90/s  (1.120s,  562.53/s)  LR: 1.000e-05  Data: 0.001 (0.005)\n",
      "INFO:root:Train: 5 [1050/6100 ( 17%)]  Loss:  5.295361 (5.2536)  Loss_kd:  0.349487 (0.3521)  Loss_ce:  1.800496 (1.7324)  Time: 1.115s,  564.97/s  (1.120s,  562.68/s)  LR: 1.000e-05  Data: 0.002 (0.005)\n",
      "INFO:root:Train: 5 [1100/6100 ( 18%)]  Loss:  5.228362 (5.2541)  Loss_kd:  0.348563 (0.3522)  Loss_ce:  1.742731 (1.7325)  Time: 1.113s,  565.88/s  (1.119s,  562.82/s)  LR: 1.000e-05  Data: 0.001 (0.005)\n",
      "INFO:root:Train: 5 [1150/6100 ( 19%)]  Loss:  5.198080 (5.2546)  Loss_kd:  0.349568 (0.3522)  Loss_ce:  1.702398 (1.7326)  Time: 1.113s,  565.81/s  (1.119s,  562.97/s)  LR: 1.000e-05  Data: 0.001 (0.005)\n",
      "INFO:root:Train: 5 [1200/6100 ( 20%)]  Loss:  5.283475 (5.2533)  Loss_kd:  0.359052 (0.3521)  Loss_ce:  1.692958 (1.7320)  Time: 1.116s,  564.71/s  (1.119s,  563.08/s)  LR: 1.000e-05  Data: 0.002 (0.005)\n",
      "INFO:root:Train: 5 [1250/6100 ( 20%)]  Loss:  5.320823 (5.2517)  Loss_kd:  0.359865 (0.3520)  Loss_ce:  1.722171 (1.7312)  Time: 1.113s,  565.88/s  (1.119s,  563.18/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 5 [1300/6100 ( 21%)]  Loss:  5.135786 (5.2520)  Loss_kd:  0.344051 (0.3520)  Loss_ce:  1.695272 (1.7316)  Time: 1.113s,  565.80/s  (1.118s,  563.26/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 5 [1350/6100 ( 22%)]  Loss:  5.396658 (5.2521)  Loss_kd:  0.364599 (0.3520)  Loss_ce:  1.750669 (1.7318)  Time: 1.113s,  565.85/s  (1.118s,  563.35/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 5 [1400/6100 ( 23%)]  Loss:  5.346253 (5.2521)  Loss_kd:  0.357168 (0.3521)  Loss_ce:  1.774568 (1.7314)  Time: 1.114s,  565.52/s  (1.118s,  563.45/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 5 [1450/6100 ( 24%)]  Loss:  5.403742 (5.2512)  Loss_kd:  0.355245 (0.3520)  Loss_ce:  1.851293 (1.7307)  Time: 1.114s,  565.58/s  (1.118s,  563.53/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 5 [1500/6100 ( 25%)]  Loss:  5.254200 (5.2506)  Loss_kd:  0.350746 (0.3520)  Loss_ce:  1.746743 (1.7307)  Time: 1.114s,  565.50/s  (1.118s,  563.59/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 5 [1550/6100 ( 25%)]  Loss:  5.168577 (5.2505)  Loss_kd:  0.349409 (0.3520)  Loss_ce:  1.674490 (1.7308)  Time: 1.110s,  567.69/s  (1.118s,  563.67/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 5 [1600/6100 ( 26%)]  Loss:  5.177627 (5.2502)  Loss_kd:  0.344330 (0.3520)  Loss_ce:  1.734322 (1.7306)  Time: 1.115s,  564.82/s  (1.118s,  563.73/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 5 [1650/6100 ( 27%)]  Loss:  5.116984 (5.2499)  Loss_kd:  0.349032 (0.3519)  Loss_ce:  1.626664 (1.7305)  Time: 1.118s,  563.74/s  (1.117s,  563.79/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 5 [1700/6100 ( 28%)]  Loss:  5.138526 (5.2496)  Loss_kd:  0.342355 (0.3519)  Loss_ce:  1.714974 (1.7305)  Time: 1.114s,  565.54/s  (1.117s,  563.86/s)  LR: 1.000e-05  Data: 0.001 (0.004)\n",
      "INFO:root:Train: 5 [1750/6100 ( 29%)]  Loss:  5.262671 (5.2493)  Loss_kd:  0.345026 (0.3519)  Loss_ce:  1.812413 (1.7302)  Time: 1.110s,  567.41/s  (1.117s,  563.91/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 5 [1800/6100 ( 30%)]  Loss:  5.130385 (5.2495)  Loss_kd:  0.346470 (0.3519)  Loss_ce:  1.665680 (1.7303)  Time: 1.113s,  565.93/s  (1.117s,  563.95/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 5 [1850/6100 ( 30%)]  Loss:  5.179138 (5.2492)  Loss_kd:  0.342237 (0.3519)  Loss_ce:  1.756772 (1.7302)  Time: 1.114s,  565.73/s  (1.117s,  564.00/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train: 5 [1900/6100 ( 31%)]  Loss:  5.346860 (5.2495)  Loss_kd:  0.361856 (0.3519)  Loss_ce:  1.728296 (1.7305)  Time: 1.114s,  565.74/s  (1.117s,  564.05/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 5 [1950/6100 ( 32%)]  Loss:  5.256540 (5.2489)  Loss_kd:  0.352992 (0.3519)  Loss_ce:  1.726617 (1.7302)  Time: 1.114s,  565.42/s  (1.117s,  564.09/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 5 [2000/6100 ( 33%)]  Loss:  5.332098 (5.2488)  Loss_kd:  0.361255 (0.3519)  Loss_ce:  1.719545 (1.7299)  Time: 1.113s,  566.07/s  (1.117s,  564.14/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 5 [2050/6100 ( 34%)]  Loss:  5.034050 (5.2484)  Loss_kd:  0.340233 (0.3519)  Loss_ce:  1.631719 (1.7296)  Time: 1.114s,  565.54/s  (1.117s,  564.18/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 5 [2100/6100 ( 34%)]  Loss:  5.248077 (5.2490)  Loss_kd:  0.345843 (0.3519)  Loss_ce:  1.789647 (1.7298)  Time: 1.115s,  564.93/s  (1.117s,  564.22/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 5 [2150/6100 ( 35%)]  Loss:  5.345593 (5.2495)  Loss_kd:  0.350604 (0.3519)  Loss_ce:  1.839556 (1.7301)  Time: 1.112s,  566.57/s  (1.117s,  564.26/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 5 [2200/6100 ( 36%)]  Loss:  5.188330 (5.2496)  Loss_kd:  0.339424 (0.3520)  Loss_ce:  1.794091 (1.7299)  Time: 1.113s,  566.08/s  (1.116s,  564.29/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 5 [2250/6100 ( 37%)]  Loss:  5.266996 (5.2497)  Loss_kd:  0.352547 (0.3520)  Loss_ce:  1.741526 (1.7298)  Time: 1.111s,  566.97/s  (1.116s,  564.33/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n",
      "INFO:root:Train: 5 [2300/6100 ( 38%)]  Loss:  5.209201 (5.2498)  Loss_kd:  0.351214 (0.3520)  Loss_ce:  1.697063 (1.7299)  Time: 1.114s,  565.53/s  (1.116s,  564.35/s)  LR: 1.000e-05  Data: 0.001 (0.003)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, num_epochs):\n",
    "    if args.distributed:\n",
    "        train_loader.sampler.set_epoch(epoch)\n",
    "\n",
    "    train_metrics = train_epoch(\n",
    "        epoch, model_g, model_raw, model_ns, train_loader, optimizer, train_loss_fn, gan_loss_fn, args,\n",
    "        lr_scheduler=lr_scheduler, saver=saver, output_dir=output_dir,\n",
    "        use_amp=use_amp, model_ema=model_ema)\n",
    "\n",
    "    eval_metrics = val_epoch(model_raw, model_g, val_loader, validate_loss_fn, args)\n",
    "\n",
    "    if model_ema is not None and not args.model_ema_force_cpu:\n",
    "        if args.distributed and args.dist_bn in ('broadcast', 'reduce'):\n",
    "            distribute_bn(model_ema, args.world_size, args.dist_bn == 'reduce')\n",
    "\n",
    "\n",
    "    if lr_scheduler is not None:\n",
    "        # step LR for next epoch\n",
    "        lr_scheduler.step(epoch + 1, eval_metrics[eval_metric])\n",
    "        \n",
    "    update_summary(\n",
    "        epoch, train_metrics, eval_metrics, os.path.join(output_dir, 'summary.csv'),\n",
    "        write_header=best_metric is None)\n",
    "\n",
    "    if saver is not None:\n",
    "    # save proper checkpoint with eval metric\n",
    "        save_metric = eval_metrics[eval_metric]\n",
    "        best_metric, best_epoch = saver.save_checkpoint(\n",
    "            model_g, optimizer, args,\n",
    "            epoch=epoch, model_ema=model_ema, metric=save_metric, use_amp=use_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
