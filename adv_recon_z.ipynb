{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torchsummary\n",
    "import glob\n",
    "import time\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "from timm.data import Dataset, create_loader, resolve_data_config,  FastCollateMixup, mixup_batch, AugMixDataset\n",
    "from timm.models import create_model, resume_checkpoint, convert_splitbn_model, apply_test_time_pool\n",
    "from timm.utils import *\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy, JsdCrossEntropy\n",
    "from timm.optim import create_optimizer\n",
    "from timm.scheduler import create_scheduler\n",
    "from munch import Munch\n",
    "import yaml\n",
    "import sys\n",
    "from gd import Generator\n",
    "from transformer import Attention\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# from dataset.imagenet import get_dataloader_sample\n",
    "# from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from apex import amp\n",
    "# from apex.parallel import DistributedDataParallel as DDP\n",
    "# from apex.parallel import convert_syncbn_model\n",
    "has_apex = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device  True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = '0,1,2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device \" , use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training with a single process on 4 GPUs.\n"
     ]
    }
   ],
   "source": [
    "with open('config/train.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "args = Munch(config)\n",
    "args.prefetcher = not args.no_prefetcher\n",
    "args.distributed = False\n",
    "args.device = 'cuda'\n",
    "args.world_size = 3\n",
    "args.rank = 0\n",
    "logging.info('Training with a single process on %d GPUs.' % args.num_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.distributed:\n",
    "    args.num_gpu = 1\n",
    "    args.device = 'cuda:%d' % args.local_rank\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    torch.distributed.init_process_group(backend='nccl', init_method='env://', rank=args.rank, world_size=args.world_size)\n",
    "    args.world_size = torch.distributed.get_world_size()\n",
    "    args.rank = torch.distributed.get_rank()\n",
    "    assert args.rank >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb204049d70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(args.seed + args.rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ns = timm.create_model('tf_efficientnet_b1_ns', pretrained=True)\n",
    "model_ns = model_ns.cuda()\n",
    "model_ns = torch.nn.DataParallel(model_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_raw = timm.create_model('tf_efficientnet_b1', pretrained=True)\n",
    "model_raw = model_raw.cuda()\n",
    "model_raw = torch.nn.DataParallel(model_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_g = Generator(args, img_size=240, max_conv_dim=256)\n",
    "model_g = model_g.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_att = Attention(args)\n",
    "model_att = model_att.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = create_optimizer(args, model_g)\n",
    "optimizer_att = create_optimizer(args, model_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "use_amp = False\n",
    "if has_apex and args.amp:\n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level='O1')\n",
    "    model_raw =  amp.initialize(model_raw)\n",
    "    model_ns = amp.initialize(model_ns)\n",
    "    use_amp = True\n",
    "if args.local_rank == 0:\n",
    "    logging.info('NVIDIA APEX {}. AMP {}.'.format(\n",
    "        'installed' if has_apex else 'not installed', 'on' if use_amp else 'off'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally resume from a checkpoint\n",
    "resume_state = {}\n",
    "resume_epoch = None\n",
    "if args.resume:\n",
    "    resume_state, resume_epoch = resume_checkpoint(model_g, args.resume)\n",
    "if resume_state and not args.no_resume_opt:\n",
    "    if 'optimizer' in resume_state:\n",
    "        if args.local_rank == 0:\n",
    "            logging.info('Restoring Optimizer state from checkpoint')\n",
    "        optimizer.load_state_dict(resume_state['optimizer'])\n",
    "    if use_amp and 'amp' in resume_state and 'load_state_dict' in amp.__dict__:\n",
    "        if args.local_rank == 0:\n",
    "            logging.info('Restoring NVIDIA AMP state from checkpoint')\n",
    "        amp.load_state_dict(resume_state['amp'])\n",
    "del resume_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_g = torch.nn.DataParallel(model_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/media/data2/dataset/imagenet/train'\n",
    "val_dir = '/media/data2/dataset/imagenet/val'\n",
    "data_config = resolve_data_config(vars(args), model=model_g, verbose=args.local_rank == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_aug_splits = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.distributed:\n",
    "    if args.sync_bn:\n",
    "        assert not args.split_bn\n",
    "        try:\n",
    "            if has_apex:\n",
    "                model = convert_syncbn_model(model)\n",
    "            else:\n",
    "                model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "            if args.local_rank == 0:\n",
    "                logging.info(\n",
    "                    'Converted model to use Synchronized BatchNorm. WARNING: You may have issues if using '\n",
    "                    'zero initialized BN layers (enabled by default for ResNets) while sync-bn enabled.')\n",
    "        except Exception as e:\n",
    "            logging.error('Failed to enable Synchronized BatchNorm. Install Apex or Torch >= 1.1')\n",
    "    if has_apex:\n",
    "        model = DDP(model, delay_allreduce=True)\n",
    "    else:\n",
    "        if args.local_rank == 0:\n",
    "            logging.info(\"Using torch DistributedDataParallel. Install NVIDIA Apex for Apex DDP.\")\n",
    "        model = DDP(model, device_ids=[args.local_rank])  # can use device str in Torch >= 1.1\n",
    "    # NOTE: EMA model does not need to be wrapped by DDP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler, num_epochs = create_scheduler(args, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_state = {}\n",
    "resume_epoch = None\n",
    "start_epoch = 0\n",
    "if args.start_epoch is not None:\n",
    "    # a specified start_epoch will always override the resume epoch\n",
    "    start_epoch = args.start_epoch\n",
    "elif resume_epoch is not None:\n",
    "    start_epoch = resume_epoch\n",
    "if lr_scheduler is not None and start_epoch > 0:\n",
    "    lr_scheduler.step(start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.local_rank == 0:\n",
    "    logging.info('Scheduled epochs: {}'.format(num_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_dir)\n",
    "val_dataset = Dataset(val_dir, load_bytes=False, class_map='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_count = sum([m.numel() for m in model_g.parameters()])\n",
    "logging.info('Model created, param count: %d' % (param_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collate_fn = None\n",
    "if args.prefetcher and args.mixup > 0:\n",
    "    assert not num_aug_splits  # collate conflict (need to support deinterleaving in collate mixup)\n",
    "    collate_fn = FastCollateMixup(args.mixup, args.smoothing, args.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_raw, test_time_pool = apply_test_time_pool(model_raw, data_config, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_loader(\n",
    "        train_dataset,\n",
    "        input_size=data_config['input_size'],\n",
    "        batch_size=args.batch_size,\n",
    "        is_training=True,\n",
    "        use_prefetcher=args.prefetcher,\n",
    "        re_prob=args.reprob,\n",
    "        re_mode=args.remode,\n",
    "        re_count=args.recount,\n",
    "        re_split=args.resplit,\n",
    "        color_jitter=args.color_jitter,\n",
    "        auto_augment=args.aa,\n",
    "        num_aug_splits=num_aug_splits,\n",
    "        interpolation=args.train_interpolation,\n",
    "        mean=data_config['mean'],\n",
    "        std=data_config['std'],\n",
    "        num_workers=args.workers,\n",
    "        distributed=args.distributed,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=args.pin_mem,\n",
    "        use_multi_epochs_loader=args.use_multi_epochs_loader\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_pct = 1.0 if test_time_pool else data_config['crop_pct']\n",
    "val_loader = create_loader(\n",
    "    val_dataset,\n",
    "    input_size=data_config['input_size'],\n",
    "    batch_size=args.batch_size,\n",
    "    is_training=False,\n",
    "    use_prefetcher=args.prefetcher,\n",
    "    interpolation=data_config['interpolation'],\n",
    "    mean=data_config['mean'],\n",
    "    std=data_config['std'],\n",
    "    num_workers=args.workers,\n",
    "    crop_pct=crop_pct,\n",
    "    pin_memory=args.pin_mem,\n",
    "    tf_preprocessing=args.tf_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.jsd:\n",
    "    assert num_aug_splits > 1  # JSD only valid with aug splits set\n",
    "    train_loss_fn = JsdCrossEntropy(num_splits=num_aug_splits, smoothing=args.smoothing)\n",
    "    validate_loss_fn = nn.CrossEntropyLoss()\n",
    "elif args.mixup > 0.:\n",
    "    # smoothing is handled with mixup label transform\n",
    "    train_loss_fn = SoftTargetCrossEntropy()\n",
    "    validate_loss_fn = nn.CrossEntropyLoss()\n",
    "elif args.smoothing:\n",
    "    train_loss_fn = LabelSmoothingCrossEntropy(smoothing=args.smoothing)\n",
    "    validate_loss_fn = nn.CrossEntropyLoss()\n",
    "else:\n",
    "    train_loss_fn = nn.CrossEntropyLoss()\n",
    "    validate_loss_fn = train_loss_fn\n",
    "\n",
    "crd_loss_fn = CRDLoss(args).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric = args.eval_metric\n",
    "best_metric = None\n",
    "best_epoch = None\n",
    "saver = None\n",
    "output_dir = ''\n",
    "if args.local_rank == 0:\n",
    "    output_base = args.output if args.output else './output'\n",
    "    exp_name = '-'.join([\n",
    "        datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    "        args.model,\n",
    "        str(data_config['input_size'][-1])\n",
    "    ])\n",
    "    output_dir = get_outdir(output_base, 'train', exp_name)\n",
    "    decreasing = True if eval_metric == 'loss' else False\n",
    "    saver = CheckpointSaver(checkpoint_dir=output_dir, decreasing=decreasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ema = None\n",
    "if args.model_ema:\n",
    "    # Important to create EMA model after cuda(), DP wrapper, and AMP but before SyncBN and DDP wrapper\n",
    "    model_ema = ModelEma(\n",
    "        model,\n",
    "        decay=args.model_ema_decay,\n",
    "        device='cpu' if args.model_ema_force_cpu else '',\n",
    "        resume=args.resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(epoch, model_g, model_raw, model_ns, model_att, loader, optimizer, optimizer_att, loss_fn, crd_loss_fn, args,\n",
    "               lr_scheduler=None, saver=None, output_dir='', use_amp=False, model_ema=None):\n",
    "\n",
    "    batch_time_m = AverageMeter()\n",
    "    data_time_m = AverageMeter()\n",
    "    losses_m = AverageMeter()\n",
    "    losses_g = AverageMeter()\n",
    "    losses_ce = AverageMeter()\n",
    "    losses_kd = AverageMeter()\n",
    "    \n",
    "    model_g.train()\n",
    "    model_ns.eval()\n",
    "    model_raw.eval()\n",
    "\n",
    "    real, fake = 1, 0\n",
    "    \n",
    "    end = time.time()\n",
    "    last_idx = len(loader) - 1\n",
    "    num_updates = epoch * len(loader)\n",
    "    for batch_idx, (inputs, target) in enumerate(loader):\n",
    "        last_batch = batch_idx == last_idx\n",
    "        data_time_m.update(time.time() - end)\n",
    "        z = torch.randn(args.batch_size, 1, 15, 15, device='cuda')\n",
    "        g_out = model_g(z)\n",
    "        inputs, target = inputs.cuda(), target.cuda()\n",
    "        \n",
    "        # KD train\n",
    "        inputs_z = inputs + g_out\n",
    "        output, traj_raw = model_raw(inputs_z)\n",
    "        with torch.no_grad():\n",
    "            out_ns, traj_ns = model_ns(inputs)\n",
    "            out_ns = out_ns.detach()\n",
    "            \n",
    "        output = model_att(inputs_z, output)\n",
    "        \n",
    "        p_s = F.log_softmax(output/args.T, dim=1)\n",
    "        p_t = F.softmax(out_ns/args.T, dim=1)\n",
    "        loss_kd = F.kl_div(p_s, p_t, size_average=False) * (args.T ** 2) / output.shape[0]\n",
    "        \n",
    "        # CE train\n",
    "        loss_ce = loss_fn(output, target)\n",
    "        \n",
    "        # overall loss\n",
    "        loss = args.lambda_kd * loss_kd + args.lambda_ce * loss_ce\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_att.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_att.step()\n",
    "        \n",
    "        if not args.distributed:\n",
    "#             losses_d.update(loss_d.item(), inputs.size(0))\n",
    "#             losses_g.update(loss_g.item(), inputs.size(0))\n",
    "            losses_kd.update(loss_kd.item(), inputs.size(0))\n",
    "            losses_ce.update(loss_ce.item(), inputs.size(0))\n",
    "            losses_m.update(loss.item(), inputs.size(0))\n",
    "\n",
    "        if model_ema is not None:\n",
    "            model_ema.update(model)\n",
    "        num_updates += 1\n",
    "\n",
    "        batch_time_m.update(time.time() - end)\n",
    "        if last_batch or batch_idx % args.log_interval == 0:\n",
    "            lrl = [param_group['lr'] for param_group in optimizer.param_groups]\n",
    "            lr = sum(lrl) / len(lrl)\n",
    "\n",
    "            if args.distributed:\n",
    "                reduced_loss = reduce_tensor(loss.data, args.world_size)\n",
    "                losses_m.update(reduced_loss.item(), inputs.size(0))\n",
    "\n",
    "            if args.local_rank == 0:\n",
    "                logging.info(\n",
    "                    'Train: {} [{:>4d}/{} ({:>3.0f}%)]  '\n",
    "                    'Loss: {loss.val:>9.6f} ({loss.avg:>6.4f})  '\n",
    "#                     'Loss_d: {loss_d.val:>9.6f} ({loss_d.avg:>6.4f})  '\n",
    "#                     'Loss_g: {loss_g.val:>9.6f} ({loss_g.avg:>6.4f})  '\n",
    "                    'Loss_kd: {loss_kd.val:>9.6f} ({loss_kd.avg:>6.4f})  '\n",
    "                    'Loss_ce: {loss_ce.val:>9.6f} ({loss_ce.avg:>6.4f})  '\n",
    "                    'Time: {batch_time.val:.3f}s, {rate:>7.2f}/s  '\n",
    "                    '({batch_time.avg:.3f}s, {rate_avg:>7.2f}/s)  '\n",
    "                    'LR: {lr:.3e}  '\n",
    "                    'Data: {data_time.val:.3f} ({data_time.avg:.3f})'.format(\n",
    "                        epoch,\n",
    "                        batch_idx, len(loader),\n",
    "                        100. * batch_idx / last_idx,\n",
    "                        loss=losses_m,\n",
    "#                         loss_d=losses_d,\n",
    "#                         loss_g=losses_g,\n",
    "                        loss_kd=losses_kd,\n",
    "                        loss_ce=losses_ce,\n",
    "                        batch_time=batch_time_m,\n",
    "                        rate=inputs.size(0) * args.world_size / batch_time_m.val,\n",
    "                        rate_avg=inputs.size(0) * args.world_size / batch_time_m.avg,\n",
    "                        lr=lr,\n",
    "                        data_time=data_time_m))\n",
    "\n",
    "                if args.save_images and output_dir:\n",
    "                    torchvision.utils.save_image(\n",
    "                        inputs_z,\n",
    "                        os.path.join(output_dir, 'train-batch-%d.jpg' % batch_idx),\n",
    "                        padding=0,\n",
    "                        normalize=True)\n",
    "\n",
    "        if saver is not None and args.recovery_interval and (\n",
    "                last_batch or (batch_idx + 1) % args.recovery_interval == 0):\n",
    "            saver.save_recovery(\n",
    "                model, optimizer, args, epoch, model_ema=model_ema, use_amp=use_amp, batch_idx=batch_idx)\n",
    "\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step_update(num_updates=num_updates, metric=losses_m.avg)\n",
    "\n",
    "        end = time.time()\n",
    "        # end for\n",
    "\n",
    "    if hasattr(optimizer, 'sync_lookahead'):\n",
    "        optimizer.sync_lookahead()\n",
    "\n",
    "    return OrderedDict([('loss', losses_m.avg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_epoch(model_raw, model, val_loader, criterion, args):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    model_raw.eval()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # warmup, reduce variability of first batch time, especially for comparing torchscript vs non\n",
    "        end = time.time()\n",
    "        for i, (inputs, target) in enumerate(val_loader):\n",
    "            if args.no_prefetcher:\n",
    "                target = target.cuda()\n",
    "                inputs = inputs.cuda()\n",
    "            z = torch.randn(inputs.shape[0], 1, 15, 15, device='cuda')\n",
    "            \n",
    "            out = model(z)\n",
    "            # synthesizing input + generator\n",
    "            inputs_out = inputs + out\n",
    "            # compute output\n",
    "            output, foward_list = model_raw(inputs_out)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output.data, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), inputs.size(0))\n",
    "            top1.update(acc1.item(), inputs.size(0))\n",
    "            top5.update(acc5.item(), inputs.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % args.log_freq == 0:\n",
    "                logging.info(\n",
    "                    'Test: [{0:>4d}/{1}]  '\n",
    "                    'Time: {batch_time.val:.3f}s ({batch_time.avg:.3f}s, {rate_avg:>7.2f}/s)  '\n",
    "                    'Loss: {loss.val:>7.4f} ({loss.avg:>6.4f})  '\n",
    "                    'Acc@1: {top1.val:>7.3f} ({top1.avg:>7.3f})  '\n",
    "                    'Acc@5: {top5.val:>7.3f} ({top5.avg:>7.3f})'.format(\n",
    "                        i, len(val_loader), batch_time=batch_time,\n",
    "                        rate_avg=inputs.size(0) / batch_time.avg,\n",
    "                        loss=losses, top1=top1, top5=top5))\n",
    "\n",
    "    results = OrderedDict(\n",
    "        top1=round(top1.avg, 4), top1_err=round(100 - top1.avg, 4),\n",
    "        top5=round(top5.avg, 4), top5_err=round(100 - top5.avg, 4),\n",
    "        param_count=round(param_count / 1e6, 2),\n",
    "        img_size=data_config['input_size'][-1],\n",
    "        cropt_pct=crop_pct,\n",
    "        interpolation=data_config['interpolation'])\n",
    "\n",
    "    logging.info(' * Acc@1 {:.3f} ({:.3f}) Acc@5 {:.3f} ({:.3f})'.format(\n",
    "       results['top1'], results['top1_err'], results['top5'], results['top5_err']))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(start_epoch, num_epochs):\n",
    "    if args.distributed:\n",
    "        train_loader.sampler.set_epoch(epoch)\n",
    "\n",
    "    train_metrics = train_epoch(\n",
    "        epoch, model_g, model_raw, model_ns, model_att, train_loader, optimizer, optimizer_att, train_loss_fn, crd_loss_fn, args,\n",
    "        lr_scheduler=lr_scheduler, saver=saver, output_dir=output_dir,\n",
    "        use_amp=use_amp, model_ema=model_ema)\n",
    "\n",
    "    eval_metrics = val_epoch(model_raw, model_g, val_loader, validate_loss_fn, args)\n",
    "\n",
    "    if model_ema is not None and not args.model_ema_force_cpu:\n",
    "        if args.distributed and args.dist_bn in ('broadcast', 'reduce'):\n",
    "            distribute_bn(model_ema, args.world_size, args.dist_bn == 'reduce')\n",
    "\n",
    "\n",
    "    if lr_scheduler is not None:\n",
    "        # step LR for next epoch\n",
    "        lr_scheduler.step(epoch + 1, eval_metrics[eval_metric])\n",
    "        \n",
    "    update_summary(\n",
    "        epoch, train_metrics, eval_metrics, os.path.join(output_dir, 'summary.csv'),\n",
    "        write_header=best_metric is None)\n",
    "\n",
    "    if saver is not None:\n",
    "    # save proper checkpoint with eval metric\n",
    "        save_metric = eval_metrics[eval_metric]\n",
    "        best_metric, best_epoch = saver.save_checkpoint(\n",
    "            model_g, optimizer, args,\n",
    "            epoch=epoch, model_ema=model_ema, metric=save_metric, use_amp=use_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
